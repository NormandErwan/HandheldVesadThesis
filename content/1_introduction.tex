La réalité augmentée (RA) est une \textquote{technique [\dots] consistant à superposer en temps réel des images virtuelles [\dots] à des images issues du monde réel [\dots]}. \citep{OQLFRA2017}, c'est-à-dire générer des objets virtuels en trois dimensions (3D) combinés avec l'environnement réel d'un utilisateur, donnant l'illusion que le virtuel coexiste avec le réel. Ainsi la RA permet d'\emph{augmenter la perception} du réel et permet d'\emph{augmenter les interactions} possibles d'un utilisateur avec son environnement \citep{Azuma1997}. La RA peut toucher tous les sens humains, mais est principalement utilisée pour le sens visuel.

\figureLayoutETS{HoloLens}{%
  \subfigureETS[0.2]{HoloLens_1}{Affichage d'un modèle 3D dans la pièce.}%
  \figurehspace%
  \subfigureETS[0.2]{HoloLens_2}{Les applications prennent généralement la forme de fenêtres virtuelles que l'utilisateur place sur un mur.}%
}{
  Illustrations publicitaires du visiocasque de RA Microsoft HoloLens.\\
  Tiré de \cite{Microsoft2018}.
}

Les deux précédentes années ont été très importantes pour la RA. Microsoft a provoqué beaucoup d'intérêt en proposant en 2016 avec le HoloLens (\url{https://www.microsoft.com/hololens}) un visiocasque de RA portable aux performances bien supérieures à celle de ses concurrents \figrefp{HoloLens}. Puis, en 2017, Google et Apple ont permis de concevoir des applications de RA sur les milliards de téléphones intelligents Android et iOS dans le monde avec leurs plateformes de développement ARCore (\url{https://developers.google.com/ar/}) et ARKit (\url{https://developer.apple.com/arkit/}). Couplé aux annonces pour 2018 des visiocasques Magic Leap (\url{https://www.magicleap.com/}), North Star (\url{https://developer.leapmotion.com/northstar/}) et Meta 2 (\url{https://www.metavision.com/}), le marché de la RA est promis à devenir très important dans les années à venir.

\figureETS[0.9]{GartnerHypeCycle2017}{
  Courbe d'intérêt pour les nouvelles technologies, présenté en fonction du temps, en cinq phases. La RA est dans la phase trois du \textquote{gouffre des désillusions}, la RV dans la phase quatre de la \textquote{pente de l'illumination}.\\
  Adapté de \cite{GartnerHypeCurve2017}.
}

La RA reste cependant une technologie encore peu connue et techniquement moins mature que la réalité virtuelle (RV). Elle est tout de même particulièrement prometteuse et va probablement profondément transformer nos quotidiens personnels et professionnels dans les cinq à dix prochaines années \figrefp{GartnerHypeCycle2017}, comme ont pu le faire les téléphones intelligents à la fin des années 2000 \citep{Chaffey2018}. La RA nous accompagnera en construisant des interfaces humain-machines (IHM) naturelles avec nos ordinateurs, téléphones et objets connectés. Cette vision est également partagée par des entreprises importantes dans les secteurs de la RV et la RA comme Unity : \textquote{We believe [augmented reality] should be human and object centric, and use the world as a device} \citep{UnityFutureMRPartIII2017}.
% + \cite{UnityFutureMRPartII2017} pour montrer un exemple

Ainsi, comme pour les interfaces graphiques des ordinateurs dans les années 1990 ou celles des téléphones intelligents dans les années 2000, nous nous interrogeons sur la forme qu'aurait une IHM d'un système d'exploitation utilisant de la RA. En ce sens, nous pensons alors intéressant de combiner les téléphones intelligents avec des visiocasques de RA. Ces deux technologies sont en effet mobiles mais présentent des caractéristiques d'IHM différentes qui semblent complémentaires :
\begin{enumerate}
  \item Les téléphones intelligents sont de plus en plus puissants et possèdent des écrans haute définition mais ont atteint une limite de taille physique d'écran pour pouvoir être tenus dans la main. Leurs utilisateurs bénéficieraient d'un plus grand écran pour d'utiliser plusieurs applications simultanément, de naviguer parmi de nombreux fichiers ou photos, ou encore de visualiser de grandes cartes ou des photos haute-résolution.
  \item Les visiocasques de RA permettent d'entourer un utilisateur de nombreux et grands écrans virtuels \citep{Ens2014}. Cependant, 
  les techniques d'interactions sont encore peu étudiées en RA \citep{Piumsomboon2013}, tandis qu'elles sont bien maîtrisées pour les écrans tactiles \citep{Wobbrock2009}. En outre, les interactions en l'air avec la main à travers des interfaces intangibles (\textquote{flottant en l'air}) est difficile \citep{Chan2010} et fatiguant \citep{Hincapie-Ramos2014}, comparé aux interactions avec un écran tactile qui se font sur une surface physique stable.
\end{enumerate}
\medskip

% Touch fonctionne car naive physics dans les interactions (contenu réagit comme si on poussait un objet physique avec le doigt + intertie), feedback haptique, précision de quelques mm, espaces de visu et interac sont alignés
% https://doi.org/10.1109/MMUL.2006.69
% page 2: tu as écris que "les interactions en l’air avec la main à travers des interfaces intangibles (« flottant en l’air ») est difficile ... et fatiguant ..., comparé aux interactions avec un écran tactile qui se font sur une surface physique stable."  J'aimerais que tu élabores un peu: on s'intéresse surtout aux interactions (en particulier, le pointage) à *main nue* (donc sans souris, et sans contrôleur).  Pourquoi est-ce que ces interactions sont difficiles et fatigantes avec la RA ?  Il y a plusieurs raisons: la main / le doigt n'est pas stabilisé par une surface physique, et a tendance à trembler, ce qui limite sa précision.  Il y a aussi une difficulté à bien détecter et localiser les mains dans l'espace, surtout si la main est en partie cachée par rapport aux caméras sur le visiocasque.  Et c'est fatiguant car rien n'appuie le bras.  Par contre, avec un smartphone, la main peut-être stabilisée par le bord de l'appareil, servant alors de point de pivot, et même sans ce pivot, c'est le bout du doigt qui touche l'écran, ce qui se détecte de façon très fiable et donne automatiquement un retour haptique à l'utilisateur confirmant que le toucher s'est fait avec succès.  De plus, avec le smartphone, le retour visuel de très haute résolution et la stabilité accrue au doigt permet aux utilisateurs de pointer avec une précision d'environ 2-3mm.
% pages 2-3: tu devrais parler un peu plus de l'avantage de combiner smartphone et RA.  En particulier, parler du fait qu'on a plus d'espace pour le output, et que le input peut se faire sur le smartphone (ce qui est plus stable, précise, et habituelle) ou bien dans l'espace autour (ce qui est plus directe et peut-être plus intuitif) ou les deux.  Donc, ça représente une solution intéressante / prometteuse, mais il y a des questions ouvertes: quelle taille est la meilleure à donner au VESAD?  Comment placer le contenu virtuel autour du smartphone? Quel mode de input est mieux?  On doit donc étudier la stratégie VESAD pour commencer à répondre à ces questions. L'étude qui sera présentée va comparer les deux modes de input de façon expérimentale et permettre de tenter des réponses à ces questions.  Je te laisse reformuler tout ça à ta façon, mais tu vois un peu comment élaborer et convaincre le lecteur que c'est un sujet important qui vaut la peine d'être étudié.  Ça serait idéal de retrouver ce genre de discussion en résumé dans l'introduction, et encore (avec un peu plus de détails, plus de références) à la fin du chapitre 1, pour motiver l'étude du VESAD.
% Input on the phone has the advantage that the physical surface of the phone stabilizes the finger, making input more precise, enabling reliable detection of touch events, and where the Fitts' index of performance is theoretically higher because the fingers, rather than the arms, are involved. However, mid-air input is more direct, possibly more intuitive, and may benefit from the user performing coordinated, simultaneous motions of both arms (e.g., moving hands in opposite directions so that the non-dominant hand ``pulls'' a target closer to the dominant hand that is reaching toward the target).
% 3D interaction is more physically-demanding and might hinder user tasks by increasing the required dexterity. Compare for example the act of selecting an object using a mouse pointer to that of grasping a 3D object in free space. Mouse movement involves small, fast muscles whereas grasping often requires a complex arm movement involving larger and slower muscles [23, 48]. \cite{Argelaguet2013}
% Input on the phone has the advantage that the physical surface of the phone stabilizes the finger, making input more precise, enabling reliable detection of touch events, and where the Fitts' index of performance is theoretically higher because the fingers, rather than the arms, are involved. However, mid-air input is more direct, possibly more intuitive, and may benefit from the user performing coordinated, simultaneous motions of both arms (e.g., moving hands in opposite directions so that the non-dominant hand ``pulls'' a target closer to the dominant hand that is reaching toward the target).
% TODO: maj la problématique également

\figureETS{HandheldVESADMidAirInArOut}{
  Photomontage d'une vue à la troisième personne de notre tâche expérimentale, dans la condition \condition{VESAD} : une grille est affichée sur l'écran physique du téléphone et sur une fenêtre virtuelle située autour formant ainsi un unique écran étendu.
}

Nous proposons alors de concevoir un prototype de téléphone intelligent dont l'écran est étendu par RA et de l'évaluer expérimentalement par rapport à un téléphone non étendu. Nous appelons l'IHM de ce prototype \texten{Virtuality Extended Screen-Aligned Display} (VESAD) : une fenêtre virtuelle est affichée en RA, placée autour de l'écran du téléphone. Cela donne à l'utilisateur le sentiment d'un seul écran étendu de la taille de celui d'un ordinateur mais tenu en main et donc mobile \figrefp{HandheldVESADMidAirInArOut}.

Après notre revue de littérature et la définition de notre problématique au \autoref{ch:litterature}, nous explorons le concept de notre prototype au \autoref{ch:concept}, puis nous exposons son développement au \autoref{ch:methodology}. Nous menons ensuite une évaluation expérimentale comparant différents usages du VESAD face à un téléphone seul sur la tâche de classification de \cite{Liu2014} au \autoref{ch:experiment} : nous y exposons sa conception ainsi que nos résultats. Enfin, nous discutons nos résultats et révisons notre concept au \autoref{ch:discussion}.