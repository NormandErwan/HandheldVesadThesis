\begin{sommaire}{mot-clé1, mot-clé2}
Expliquer rapidement projet (ce que j'ai fait) et pourquoi : comparaison de techniques d'interactions, de sélection et de mouvement de contenu 3D, projeté en RA autour d'un appareil mobile tenu en main, aligné sur le même plan de l'écran de cet appareil mobile (+ HMD RA video + librairie RA pour Unity)
\end{sommaire}

\begin{abstract}{Titre en anglais}{keyword1, keyword2}
  TODO: abstract de l'article à reprendre\\
  We propose using augmented reality to extend the screen of a smartphone beyond its physical limits with a virtual surface that is co-planar with the phone and that follows as the phone is moved.We call this extension a VESAD, or Virtually Extended Screen-Aligned Display.We illustrate and describe several ways that a VESAD could be usedto complement the physical screen of a phone,and describe two novel interaction techniques:one where the user performs a quick rotation of the phone to switchthe information shown in the VESAD,and another called ``slide-and-hang'' whereby the user can detacha VESAD and leave it hanging in mid-air, using the phoneto establish the initial position and orientation of the virtual window.We also report an experiment that compared three interfacesused for an abstract classification task:the first using only a smartphone,the second using the phone for input but with a VESAD for output,and the third where the user performed input in mid-air on the VESAD (as detectedby a Leap Motion).The second user interface was found to be superior in time andselection count (a metric of mistakes committed by users)and was also subjectively preferred over the other two interfaces.This demonstrates the added value of a VESAD for output over a phone's physical screen,and also demonstrates that input on the phone's screen was betterthan input in mid-air in our experiment.
\end{abstract}