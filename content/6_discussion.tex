\chapter{Discussion}
\label{ch:discussion}

\section{Discussion des résultats}
\label{sec:discussion_results}

Dans l'ensemble, nos résultats indiquent que le \condition{VESAD tactile} a été la meilleure des trois IHMs. Elle a tout d'abord été la plus rapide, avec le plus petit temps de complétion ($\approx \SI{62}{\s}$), en particulier quand la tâche était maîtrisée des participants ($\approx \SI{42}{\s}$). Elle a ensuite été largement préférée des participants, et jugé la plus performante. Enfin, elle a été la plus performante dans le classement : d'une part, car les participants utilisaient en moyenne une seule sélection et un seul zoom par disque à classer et, d'autre part, car le temps passé avec un disque sélectionné beaucoup plus court qu'avec les autres IHMs. Ce n'est guère étonnant, car le \condition{VESAD tactile} bénéficie à la fois d'un grand affichage et d'interactions stables et précises sur l'écran tactile.

Il est facile de comparer le \condition{VESAD tactile} et le \condition{Téléphone}, car les techniques d'interactions étant les mêmes, seule change la taille de l'écran. Nous avons en effet observé que les participants s'habituaient très vite à fusionner l'affichage sur l'écran tactile avec l'affichage virtuel autour du téléphone. La différence importante de temps de complétion entre ces deux IHMs va donc dans le sens des résultats \cite{Raedle2014}, qui avaient mis en évidence qu'une tâche de navigation dans un grand document devenait difficile avec un écran plus petit que celui d'une tablette (\SI{23.5x13.2}{\cm}). En revanche, cette différence contraste avec ceux de \cite{Grubert2015}, qui avaient mesuré, dans une tâche de navigation, qu'une montre intelligente à l'écran étendu performait moins qu'un téléphone seul. Cependant, leur implémentation de l'écran étendu jouait en sa défaveur : le plan virtuel était bien aligné mais vu comme \SI{2.5}{\m} en arrière de la montre, en plus d'un champ de vision limité du visiocasque (\SI{30.5x17.2}{\degree}), d'un écart de résolution entre l'écran et le visiocasque et d'une latence importante entre les deux affichages \figrefp{Grubert2015_5}. Contrairement à \citeauthor{Grubert2015}, le \condition{VESAD tactile} a surpassé le \condition{Téléphone} dans notre étude. Ainsi, il nous semble qu'un VESAD bien conçu et implémenté est plus performant que l'écran seul.

\figureETS[0.5]{Grubert2015_5}{
  Démonstration de la montre à écran étendu de \cite{Grubert2015} (condition SWRef), similaire à notre technique \condition{VESAD tactile}.\\
  Adapté de \cite{Grubert2015Video}, à \SI{2}{\minute} \SI{4}{\second}.
}

En outre, nous avons observé des tactiques similaires de sélection des disques avec le \condition{VESAD tactile} et le \condition{Téléphone}. Une première tactique consiste à zoomer suffisamment la grille pour pouvoir lire le texte sur les disques et à parcourir toutes les cellules de la grille jusqu'à trouver celle correspondant au disque sélectionné. \cite{Raedle2014} avaient également remarqué ces mouvements de \textquote{\texten{scanning}} \figrefp{Raedle2014_3} avec les tailles d'écrans correspondant à la tablette et au téléphone, quand les participants découvraient le document ; ces similitudes entre nos défilements statiques et leurs défilements physiques et dynamiques sont intéressantes. La seconde tactique est similaire a celle qui avait été décrite par \cite{Guiard2004} pour les IHMs Pan+Zoom sur ordinateurs : (i) un dé-zoom pour repérer une cible ou la placer dans la vue, (ii) suivi de zooms et défilement pour la rendre assez grosse pour finalement (iii) la sélectionner \figrefp{Guiard2004_8}. Les participants de notre expérience effectuaient ce mouvement pour lire le texte des disques rouges ou des cellules. Cependant, \cite{Guiard2004} indiquaient à juste titre que la première phase n'était pas nécessaire si la difficulté était assez faible, ce que nous avons vu être souvent le cas pour le \condition{VESAD tactile}. Certains participants profitait en effet du grand écran et la résolution suffisante pour le laisser zoomé et seulement le défiler pour atteindre les disques ou cellules. Cela est en accord avec les mouvements observés par \cite{Raedle2014} quand les participants connaissaient le document (en avait une carte mentale) \figrefp{Raedle2014_4}.

\figureLayoutETS{Raedle2014Movements}{%
  \subfigureETS[0.18]{Raedle2014_3}{Mouvements de \textquote{\texten{scanning}} lors des premiers essais (exploration du document).}%
  \figurehspace%
  \subfigureETS[0.18]{Raedle2014_4}{Mouvements lors des derniers essais (le document est maintenant connu et mémorisé par le participant).}%
}{
  Mouvements (en bleu) face à l'affichage mural d'un participant avec l'écran de la taille (en haut) d'une tablette ou (en bas) d'un téléphone. Les points rouges sont les cibles à atteindre.\\
  Tiré de \cite{Raedle2014}.
}

\figureETS[0.5]{Guiard2004_8}{
  Séquence d'actions typique pour atteindre une cible avec une IHM Pan+Zoom sur un ordinateur : l'utilisateur dézoome pour la repérer, puis zoome et défile vers cette cible pour pouvoir la pointer.\\
  Tiré de \cite{Guiard2004}.
}

L'écran étendu est donc un vrai avantage pour les utilisateurs. À techniques d'interactions égales, le \condition{VESAD tactile} a été 30\% plus rapide que le \condition{Téléphone}, avec deux fois moins de zooms. Les participants ont également jugé le \condition{Téléphone} mentalement plus exigeant que les deux autres techniques. Il est intéressant de noter qu'il n'y a eu aucune différence entre ces deux IHMs en termes de défilements. Notre première hypothèse est donc non supportée par nos résultats : le téléphone seul n'a pas été le moins performant des trois IHMs testées.

Pourtant, plusieurs participants ont expliqué que le \condition{VESAD} leur semblait l'IHM avec le plus de potentiel. Nous les avons souvent vu tenter spontanément de toucher la grille la première fois qu'il ont vu l'écran étendu. De plus, ils se sont jugés aussi performants qu'avec le \condition{Téléphone} et l'ont un peu plus préféré que ce dernier. Ils l'ont aussi trouvé moins exigeant mentalement que le \condition{Téléphone}, ce qui indique que l'écran étendu donnait un avantage. Quelques participants ont aussi fait remarquer qu'ils préféraient toucher directement une cible sur l'écran virtuel plutôt que devoir la déplacer sur l'écran tactile avec le \condition{VESAD tactile}. Notre deuxième hypothèse est donc supportée : les utilisateurs préfèrent l'écran étendu au téléphone seul.

Malgré tout, le \condition{VESAD} a été le moins performant. Cela est dû d'une part au suivi de la main avec le Leap Motion qui manquait de stabilité et de précision. L'implémentation de meilleures techniques pourrait résoudre ce problème, par exemple \cite{Taylor2016}. D'autre part, nos techniques d'interactions pour le défilement et le zoom avec le \condition{VESAD} n'étaient pas bien conçues, car il s'est avéré difficile de faire un déplacement précis de la main le long d'un plan virtuel. La comparaison avec les autres IHMs est donc difficile, car les techniques d'interactions que nous avons proposé jouent en sa défaveur. Pourtant, la littérature a montré que la sélection d'une cible avec une main virtuelle était plus difficile que sur une surface tangible \citep{Chan2010, Jones2012, Argelaguet2013}. Les mauvaises notes sur l'exigence physique, la frustration ainsi que les longs temps passés avec un item sélectionné semblent aller dans ce sens. On peut donc tout de même estimer que nos notre troisième hypothèse soit supportée : avec un téléphone à écran étendu, les interactions sur l'écran tactile sont plus performantes qu'une main virtuelle.

Toutefois, notre expérience comporte plusieurs limites. Premièrement, nous avons mal contrôlé la difficulté de notre tâche. Nous n'avons en effet pas pu mesurer de différence entre les différences conditions de \variable{TAILLE} et la \variable{DISTANCE}, contrairement à \cite{Liu2014}. Cela limite nos conclusions, car il aurait été intéressant de voir l'effet de ces quatre différents \textquote{niveaux} de difficulté sur la performance des trois IHMs. Nous avions dans notre étude pilote prévu 15 disques à classer au lieu de cinq et des tailles de texte beaucoup plus petites, qui s'étaient révélées impraticables avec le \condition{VESAD}. Nous avons alors placé trop proches nos deux conditions de \variable{TAILLE}. En outre, nous avons directement utilisé les valeurs \variable{DISTANCE} de la tâche de \citeauthor{Liu2014}. Il aurait été plus sage de faire une ou deux itérations supplémentaires pour tester la validité de nos configurations de la difficulté. Deuxièmement, nous l'avons décrit, le mauvais suivi de la main des participants et la mauvaise conception des techniques de navigation avec la main virtuelle ont défavorisé le \condition{VESAD}, qui a été l'\variable{IHM} la moins performante des trois IHMs évaluées.

Troisièmement, nous avons malheureusement faire un compromis sur la densité visuelle de notre visiocasque pour avoir un large champ de vision, nous avons dû utiliser un visiocasque de RA vidéo. Si cela a désavantagé le \condition{Téléphone}, nous avons cependant maintenu constants la latence, la densité visuelle, le champ de vision et le poids sur la tête des participants en faisant utiliser le visiocasque pour chaque \variable{IHM}, contrairement à \cite{Grubert2015}. Ces variables parasites contrôlées, nos comparaisons entre le \condition{Téléphone} et les deux autres IHMs ont alors une meilleure validité.

De manière plus générale, on peut voir l'utilisation nécessaire d'un visiocasque comme une limite. Nous avons en effet utilisé un visiocasque de RA vidéo, impliquant une vision dégradée (latence et densité visuelle) de l'environnement réel. Toutefois, grâce aux développements récents et importants dans l'industrie \autorefp{ch:introduction}, nous anticipons un usage répandu à l'avenir de visiocasques de RA optiques plus légers, performants et avec large champ de vision. Ce type de visiocasque a l'avantage de ne pas dégrader la vision de l'environnement réel. Il est possible qu'un meilleur visiocasque change nos résultats, mais il nous semble que cette étude expérimentale supporte que certaines tâches bénéficieraient d'un écran étendu.


\section{Conception d'une IHM pour un VESAD}
\label{sec:discussion_design}

Avant la conception d'une IHM, nous pensons crucial que le VESAD soit d'abord bien implémenté, c'est-à-dire avoir : (1) un excellent suivi avec 6 DoFs de l'écran physique à étendre, (2) un bon alignement entre l'écran virtuel et l'écran physique et (3) une synchronisation sans latence entre les deux écrans pour donner l'illusion d'un seul écran étendu. Notre bibliothèque de RA ArucoUnity répond à ces deux premières problématique en utilisant du suivi de marqueur. Plusieurs participants nous ont cependant indiqué d'améliorer le dernier point. En outre, il nous semble important d'utiliser un visiocasque avec un grand champ de vision pour voir complètement l'écran étendu. Enfin, un visiocasque avec une bonne densité visuelle est préférable.

\figureETS[0.5]{Ens2014_3}{
  Démontration du Personal Cockpit : un ensemble de fenêtres 2D positionnées selon une sphère autour de l'utilisateur.\\
  Adapté de \cite{Ens2014Video}.
}

Pendant la conception de l'IHM pour un écran étendu, il est essentiel de \emph{penser l'interface à travers la technique d'interaction} utilisée. En effet, comme l'ont très bien souligné \cite{Ens2014}, le temps et les erreurs de pointage augmentent pour les cibles plus lointaines en utilisant une main virtuelle. Cela a également été le cas avec le \condition{VESAD tactile} : les participants devaient effectuer beaucoup de défilements et zooms pour amener une cible sur l'écran. Sur un écran tactile seul ou avec une souris sur un écran de PC, l'espace de visualisation est facilement accessible, quand il dépasse facilement celui d'interaction avec un VESAD. Des techniques comme Go-Go permettent d'atténuer ce problème pour la main virtuelle en agrandissant l'espace d'interaction accessible par un gain sur les mouvements de la main \figrefp{Argelaguet2013GoGo}. \citeauthor{Ens2014} suggèrent de positionner des fenêtres virtuelles à équidistance de l'utilisateur dans une disposition sphérique \figrefp{Ens2014_3}. Cette idée serait intéressante à explorer pour un VESAD : nous avons observé plusieurs participants tourner le téléphone pour rapprocher une cible. Une autre approche est d'utiliser des pointeurs virtuels \citep{Argelaguet2013}.

\figureLayoutETS{Argelaguet2013GoGo}{%
  \subfigureETS[0.15]{Argelaguet2013_2}{Avec une technique de main virtuelle classique, seuls les objets à portée de main sont sélectionnables.}%
  \figurehspace%
  \subfigureETS[0.15]{Argelaguet2013_3}{La technique Go-Go propose de rediriger les mouvements de la main vers un espace de sélection plus grand.}%
}{
  Illustration de la technique Go-Go par rapport à une technique de main virtuelle.\\
  Adapté de \cite{Argelaguet2013}.
}

\figureLayoutETS{HandheldVESADZones}{%
  \subfigureETS[0.2]{HandheldVESADZones_1}{Interactions avec une main virtuelle, les interactions se font du côté de la main ne tenant pas le téléphone et éventuellement au-dessus et en dessous de l'écran physique.}%
  \figurehspace%
  \subfigureETS[0.2]{HandheldVESADZones_2}{Interactions via l'écran tactile : la partie virtuelle autour reste accessible par défilements.}%
}{
  Une IHM pour un téléphone à écran étendu contient des zones d'interactions (en vert), des zones pour les interactions moins fréquentes (en jaune) et des zones uniquement dédiée à la visualisation (en blanc).
}

Ainsi, nous recommandons de \emph{favoriser les interactions seulement dans des zones facilement accessibles}, que nous résumons avec la \figref{HandheldVESADZones} : les zones blanches sont à réserver seulement pour l'affichage, les vertes sont les plus facilement accessibles tandis que les jaunes, plus difficiles d'accès, sont à réserver pour les interactions peu fréquentes. Ainsi, avec une main virtuelle est utilisée, l'interface est plutôt asymétrique \figrefp{HandheldVESADZones_1} : elle est alignée avec le téléphone qui est tenu avec une main tandis que les interactions se font avec l'autre main ; dès lors, quand le téléphone est tenu de la main gauche, l'espace d'interaction se trouve sur sa droite (et inversement). En outre, nous déconseillons les interactions du côté de la main tenant le téléphone (à gauche de la main gauche pour un droitier) qui demandent de croiser les mains. Par exemple, nous améliorons notre basculement d'affichage wrist \figrefp{HandheldVESADApp}, en plaçant les applications sélectionnables à droite du téléphone, à portée de la main \figrefp{HandheldVESADApps3}. À l'inverse, quand c'est l'écran tactile qui est utilisée, par exemple quand le téléphone est tenu à deux mains ou si un utilisateur préfère utiliser une seule main, l'interface est symétrique \figrefp{HandheldVESADZones_2} : l'écran tactile est bien sûr accessible, ainsi que l'espace immédiatement autour, via des défilements.

\figureETS[0.4]{HandheldVESADApps3}{
  Remaniement de wrist \figrefp{HandheldVESADMap} : les applications sur lesquelles basculer sont placées à droite du téléphone, facilement sélectionnables. Les notifications sont placées au-dessus de l'écrans, car elles sont peu accédées.
}

Enfin, tout comme la disposition d'un site web doit s'adapter (\texten{responsiveness}) à la taille d'écran des différents appareils qui peuvent y accéder (par exemple : téléphone intelligent, tablette, ordinateur), \emph{une IHM pour un VESAD doit s'adapter à différents scénarios d'interaction}. Ainsi, la navigation physique avec une main virtuelle et la navigation virtuelle via l'écran tactile doivent toutes deux être supportées, au choix de l'utilisateur. De plus, la disposition du contenu doit s'adapter dynamiquement au contexte d'utilisation (comment est tenu le téléphone) et au type d'interaction utilisé.

%Several users wished that they could pan and zoom in the \condition{VESAD} technique without having to switch modes through a menu, similar to pinch-to-zoom on status quo phone interfaces. 

%Le leap capture en continue vs le touch qui fonctionne sur le principe du bouton : est-ce que le leap n'est pas mieux faire pour les interactions naturelles avec des objets tels que notre vie de tous les jours ? Remarque : un téléphone fait partie de notre vie de tous les jours, on peut le simuler en 3d avec interactions. Donc il faut surtout améliorer la précision du tracking.
%Donc contrairement au tactile où il faut toucher l'écran pour agir dessus, il faut mettre des boites d'interaction autour des objets pour le leap, comme proposé par Grasp Shell. Parce que le tracking est pas fiable à 100\%, fonctionne mal avec la reprojection perspective de l'ovrvision et le doigt n'ayant pas de support physique sur lequel s'arrêter pour appuyer, il y a des mouvements involontraires pour tenir une position en l'air et un intervalle d'erreur quand le doigt veut toucher une cible 3D (même avec de la stéréoscopie et de la parallaxe).
%Quand on veut combiner le leap et le tactile, il faut penser à désactiver cette boite : sinon on actionne la boite avec le leap avant de toucher le téléphone.

%Pour LeapIn, on utilise un long press plutôt qu'un tap. La règle est simple à comprendre, mais pas toutes les conditions : ne sais pas vraiment combien de temps doit rester, ni quand le chrono démarre, ou s'arrête si une erreur (si on déplace trop le doigt). Il serait bon d'utiliser un simple cercle qui chargerai autour du doigt, comme les interactions gaze. C'est simple, facilement compréhensible et répond au problème.
%Pour le LeapIn, faire plus intelligent que bloquer toutes les interactions après une sélection ou un déplacement : on peut vouloir sélectionner, reste le long de la grille et s'arrêter là où on veut déplacer l'item. = pouvoir faire un vrai drag n drop
%Pour LeapIn le côté non dominant est horrible à interagir car croiser les mains, étendre le bras, mauvais tracking, l'autre main peut bloquer.

%LeapMotion2018 : multiplexage spatial avec une zone pour manipuler, laissant le reste seulement sélectionable + multiplexage temporel doigt : pincement pour manipuler (geste H2 de \cite{Piumsomboon2013}), pointer avec le doigt pour sélectionner (geste H11 de \cite{Piumsomboon2013}). Ce travail est intéressant car il montre des experts qui conçoivent une IHM de RA avec une main virtuelle pour des fenêtres en 2D et travaillant avec tous les jours. Cela correspond à mener des évaluations informelles sur un prototype dans une étude pilote \citep{Duenser2008}, et donne donc de bonnes pistes de conceptions d'IHM de RA à évaluer plus formellement.
% Slide to hang avec le pinch

%\figureLayoutETS{LeapMotion2018}{%
  %\subfigureETS[0.23]{LeapMotion2018_1}{La zone au-dessus d'une fenêtre	virtuelle permet de la manipuler.}%
  %\figurehspace%
  %\subfigureETS[0.23]{LeapMotion2018_2}{La manipulation est activée par un pincement sur le haut de la fenêtre virtuelle.}%
  %\figurehspace%
  %\subfigureETS[0.23]{LeapMotion2018_3}{Le reste de la fenêtre réagit seulement aux sélections par pointage d'un doigt.}%
%}{
%  Démontration de l'IHM du visiocasque de RA North Star.\\
%  Adapté de \cite{LeapMotion2018}.
%}


%\section{Directions futures}
%\label{sec:discussion_future}

%Mettre les directions futures et les recommendations : évaluer les scénarios du \autoref{ch:concept} au regard des résultats.

%Unfortunately, despite our use of off-the-shelf sensing technology (Leap Motion), the sensing of the finger position was not always reliable. Better hand-tracking techniques \cite{Taylor2016} could improve this in the future.

%how to determine the size of the display zone (we used arbitrarily 

%How can we do the pan and zoom gestures in 3D? Or they always need to be done on a physical surface (track-pad ideas for \condition{VESAD tactile})? Grasp-Shell found that vocal commands were better that mid-air interaction technique for scaling tasks 3D object in AR (but mid-air were better for translation and rotation tasks).

%Refaire expérience avec technique d'interaction à la hololens et peephole + comparer main virtuelle et pointeur virtuel quand on passe la fenêtre virtuelle en floating

%Refaire l'expérience de wedge avec téléphone seul, wedge, phone touch+ar, mid-air+ar, phone+mid-air+ar

%multi-apps + Tâche de commutation d'affichages

%bureau en realité augmentée

%Dans le cadre Ethereal Planes : rester avec des fenêtres 2D mais à organiser en 3D (data mountain)

%Tester les applications : Google Maps, multi-application (comme le Personal Cockpit)

%Interaction pour le multi écran / écran étendu : vise avec regard, qui donne l'intention, (ou tête à défaut, voir l'étude pursuit target \citep{Esteves2017}) et agit avec le doigt. Serait bien pour scroller sur une app sur l'écran étendu (car on a vu que difficile de pan avec le doigt). Citer les article utilisation du regard sur les table de travail pour select les outils

%Nous n'étudions que Zooming, car c'est le plus courant sur les appareils mobiles. Or on compare les techniques d'interactions de notre solution à un mobile seul. Il aurait été intéressant cependant, dans une deuxième expérimentation, de comparer ces techniques de visualization sur notre solution versus sur un appareil mobile seul.

%Future work could include improvements to the \condition{VESAD} technique with better sensing of mid-air finger positions, adding haptic feedback
%with a hand-worn device to let the user know when they are in contact with the VESAD plane, or comparing direct touch with allowing the user to point at locations on the VESAD using the HMD's view vector (similar to how the HoloLens allows users to aim at targets). A variant of the \condition{VESAD} technique could also be developed where the phone acts like a touchpad that can reach the entire surface of the VESAD using an appropriate gain or cursor acceleration function.

%TODO evaluate the layout in fig 19,
%determine best extents of margins zones,
%experiment with ways to automatically and manually switch handedness
%and double- and single-handed modes.

%TODO
%compare \condition{VESAD} with trackpad interaction technique (the phone screen is mapped to the VESAD entire view) and with a cursor controlled by the gaze (the phone screen is used to interact as a "big button": the actions are done where the cursor is, and interactions can be done with finger anywhere on the phone screen

%TODO
%Compare with peephole displays,
%compare with pointing with head (like HoloLens),
%try accelerated physical navigation,
%try accelerated virtual navigation.
%Nous avons observé que les participants utilisaient également de la navigation physique avec toutes les techniques en rapprochant le téléphone du visage : ce mouvement semblait plus rapide et précis qu'effectuer un zoom avec l'écran tactile -> détecter ses mouvements avec le visiocasque et concevoir une technique d'interaction ? Par ex, faire un "vrai" zoom (mise à l'échelle) du contenu du téléphone en même temps que le mouvement ? Ce serait comme mettre un gain à ce mouvement de zoom physique (sinon c'est 1:1). Ce serait à étudier.