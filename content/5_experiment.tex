\chapter{Étude expérimentale}
\label{ch:experiment}

\section{Tâche expérimentale}
\label{sec:experiment_task}

\subsection{Description}
\label{subsec:experiment_task_description}

On souhaite évaluer dans cette expérience les avantages d'un téléphone dont l'écran étendu par un visiocasque de RA à large champ de vision, ainsi que comparer deux techniques d'interaction : navigation et pointage avec l'écran tactile ou avec une main virtuelle.

Plusieurs tâches auraient pu convenir à cette expérience. Comme le VESAD est une technique relativement nouvelle et peu étudiée \citep{Grubert2015}, et la technique d'interaction de la main virtuelle peu maîtrisée \citep{Argelaguet2013, Piumsomboon2013}, nous avons besoin d'une tâche fondamentale demandant de la navigation, dont des zooms, et des sélections \citep{Bowman2004}. Nous avons alors envisagé une tâche de pointage de Fitts \citep{Soukoreff2004, Berge2014}, où l'utilisateur doit chercher et sélectionner des cibles, de navigation dans un large document, comme une carte \citep{Baudisch2002, Raedle2014}, ou encore un scénario de multi-tâches où le participant doit travailler avec plusieurs fenêtres \citep{Czerwinski2003, Ens2014}.

Nous avons finalement décidé de répliquer la tâche de classification de \cite{Liu2014} : sa validité externe est plus importante (plus réaliste) qu'une pure tâche de pointage, demande beaucoup de navigations et de reconstruction mentale comme un large document tout en demandant de sélectionner et manipuler le contenu, enfin est plus facile à implémenter et à contrôler qu'un scénario multi-tâches. Cette tâche consistait en une grille de plusieurs cellules contenant des disques \figrefp{Liu2014}. Quelques disques étant mal classés, les participants devaient les déplacer dans la bonne cellule, avec des disques de même type. Une lettre de petite taille inscrite en leur centre permettait de connaître leur type et les disques mal classés étaient colorés en rouge : cela facilitait la recherche et équilibrait avec le temps consacré au classement. Une tâche plus réaliste demanderai d'examiner en détail chaque disque pour savoir les classer (\citeauthor{Liu2014} prennent l'exemple de catégoriser les articles d'une conférence). Enfin, les déplacements se faisaient par un pointage vers le disque puis une sélection par un bouton, puis un second pointage et sélection dans la cellule. Le but de la tâche peut être résumé au participants avec la consigne de [traduction ]\textquote{tout mettre en vert} \citep{Liu2014}.

Notre grille comporte $3 \times 5$ cellules rectangulaires, pouvant chacune en contenir six maximum. Elle est générée aléatoirement à chaque nouvel essai, avec cinq disques par cellules dont au moins quatre correctement classés, et cinq disques mal classés dans la grille \figrefp{TaskGrid}. Il y a 15 cellules $\times$ 5 disques/cellule $=$ 75 disques au total dans la grille. Au début de chaque essai (pour toutes les conditions), elle est affiché à l'échelle, la taille d'une cellule étant celle de l'écran du téléphone que nous avons utilisé \autorefp{sec:experiment_material}. Ainsi, la grille a une forme approximativement carrée.

\figureETS[0.55]{TaskGrid}{
  La grille de notre tâche expérimentale au début d'un essai dans la condition \variable{TAILLE}=\condition{Grand}.
}

La tâche de \cite{Liu2014} opérationnalise une tâche d'allocation de ressources (par exemple, chaque catégorie a une capacité limitée). Le texte y est alors une variable indépendante importante. N'étudiant pas cette problématique, nous avons décidé de d'utiliser plus simplement une seule lettre par cellule, de A à O. Chaque disque \textquote{appartient} donc à une cellule et ne peut y être correctement classé que dans celle-ci. Nous colorons également les items correctement classés en vert et mal-classés en rouge. Nous colorons en outre un disque sélectionné en bleu \figrefp{ExperimentPhoneInArOut}. De sorte qu'en participant doit lire la lettre d'un disque vert pour savoir le type de la cellule.

Nous avons placé le code source de l'expérience en ligne (\url{https://github.com/NormandErwan/MasterThesisExperiment}), sous la licence libre BSD-3, pour qu'il pouvoir être reproduit ou réutilisé au besoin. Nous l'avons développé et testé pour Unity 2017.


\section{Plan expérimental}
\label{sec:experiment_design}

\figureLayoutETS{ExperimentTechniques}{%
  \subfigureETS{ExperimentPhoneOnly}{Condition \condition{Téléphone}}%
  \figurehspace%
  \subfigureETS{ExperimentPhoneInArOut}{Condition \condition{VESAD tactile}.}%
  \figurehspace%
  \subfigureETS{ExperimentMidAirInArOut}{Condition \condition{VESAD}.}%
}{
  La grille de notre tâche expérimentale pour chaque \variable{TECHNIQUE}. Pour \condition{VESAD tactile}, la main de l'utilisateur est cachée par l'écran étendu et un disque est sélectionné (en bleu). Pour \condition{VESAD}, une sphère blanche indique la position repérée de l'index de l'utilisateur, une croix sur la grille est la projection de cette sphère et un segment noir les relie ; ils deviennent bleus quand la sphère touche la grille.
}

Nous avons manipulé simultanément les variables indépendantes suivantes :
\begin{itemize}
  \item \variable{TECHNIQUE} : l'IHM évaluée, soit :
  \begin{itemize}
    \item \condition{Téléphone} : affichage et interactions seulement sur le téléphone \figrefp{ExperimentPhoneOnly} ;
    \item \condition{VESAD tactile} : affichage sur l'écran étendu et interactions sur le téléphone \figrefp{ExperimentPhoneInArOut} ;
    \item \condition{VESAD} : affichage sur l'écran étendu et interactions dans la partie virtuelle de l'écran avec une main virtuelle \figrefp{ExperimentMidAirInArOut}.
  \end{itemize}
  \item \variable{TAILLE} : la taille du texte des disques :
  \begin{itemize}
    \item \condition{Grand} : \SI{12}{\pt}, soit \SI{4.22x4.22}{\mm} ou 12\% du diamètre du disque ;
    \item \condition{Petit} : \SI{10}{\pt}, soit \SI{3.51x3.51}{\mm} ou 10\% du diamètre du disque.
  \end{itemize}
  \item \variable{DISTANCE} : la distance moyenne des disques à classer avec leurs cellule respectives :
  \begin{itemize}
    \item \condition{Proche} : entre 1,25 et 1,45 ;
    \item \condition{Loin} : entre 2,5 et 2,75.
  \end{itemize}
  \item \variable{GROUPE} : l'ordre de passage des techniques \autorefp{tab:experiment_groups}.
\end{itemize}
\medskip

La variable indépendante \variable{TECHNIQUE} combine les deux affichages et les deux techniques d'interactions. La combinaison affichage sur le téléphone seul et interactions avec une main virtuelle ne nous intéressait pas. \cite{Jones2012} l'ont d'ailleurs déjà été évaluée contre le téléphone seul \autorefp{subsec:litterature_ar_hci_interactions}.

La \variable{TAILLE} et la \variable{DISTANCE} nous permettent de contrôler la difficulté de la tâche. En réduisant la \variable{TAILLE} de la lettre dans chaque disque, on impose au participant d'effectuer des zooms plus importants pour les lire, ce qui l'empêche alors de voir beaucoup de disques à la fois. En augmentant la \variable{DISTANCE}, on impose plus de recherches au participant pour trouver la cellule correspondant à un disque à classer. Dans les deux cas, on lui demande un effort de mémoire plus important.

Comme \citeauthor{Liu2014}, nous utilisons la distance euclidienne pour calculer la \variable{DISTANCE} entre un disque mal classé et sa cellule respective. Nous considérons dans le calcul qu'une cellule fait une unité de largeur et une unité de hauteur : il y a donc une distance de 1 entre deux cellules adjacentes. La variable indépendante donne alors le nombre de cellules d'écart entre un disque mal classé et sa cellule respective, par exemple entre 2,5 et 2,75 cellules d'écart en moyenne pour la condition \condition{Loin}. Les valeurs que nous utilisons sont celles de \cite{Liu2014}. À la génération de la grille, on vérifie qu'elle respecte la condition courante, autrement on en régénère une nouvelle. Nous avions mené une étude pilote avec trois participants, demandant de classer dix disques avec de plus petites tailles de texte. Cependant, cette configuration rendu les essais particulièrement éprouvants et longs à compléter. C'est pourquoi nous avons réduit le nombre de disques à classer et augmenté la taille du texte (tout en la gardant suffisamment petite pour que les participants aient besoin de zoomer).

Notre plan expérimental est quasi complet. Les variables indépendantes \variable{TECHNIQUE}, \variable{TAILLE} et \variable{DISTANCE} sont croisées : les participants passent à travers toutes conditions. Cependant, pour contrôler un effet d'apprentissage parasite à travers les techniques, les participants sont partagés en trois \variable{GROUPE} emboîtés : chaque groupe passe à travers les conditions \variable{TECHNIQUE} dans un ordre différent, suivant un carré latin $3 \times 3$ \autorefp{tab:experiment_groups}. L'ordre de passage de la \variable{TAILLE} et de la \variable{DISTANCE} est par contre fixe : du plus simple (avec les conditions \condition{Grand} et \condition{Proche}), au plus difficile (\condition{Petit} et \condition{Loin}). Nous avons donc mesuré 12 participants $\times$ 3 techniques $\times$ 2 distances $\times$ 2 tailles = 144 observations. Pour réduire la variabilité de nos résultats, chaque participant a répété deux essais par condition, que nous avons ensuite moyennés pour avoir une observation par participant, et non par essai \cite{p. 24, Dragicevic2016}.

\begin{tableETS}{tab:experiment_groups}{Ordre de passage pour chaque \variable{GROUPE} de chaque \variable{TECHNIQUE} suivant un carré latin.}
  \begin{tabular}{| c | c | c | c |}
    \hline
    \textbf{Groupe} & \textbf{Technique 1} & \textbf{Technique 2} & \textbf{Technique 3}\\
    \hline
    1 & \condition{Téléphone} & \condition{VESAD tactile} & \condition{VESAD} \\
    \hline
    2 & \condition{VESAD tactile} & \condition{VESAD} & \condition{Téléphone} \\
    \hline
    3 & \condition{VESAD} & \condition{Téléphone} & \condition{VESAD tactile} \\
    \hline
  \end{tabular}
\end{tableETS}

Enfin, les utilisateurs ont porté le visiocasque de RA \autorefp{ch:methodology} dans toutes les conditions, même dans la condition \condition{Téléphone} qui ne bénéficie pas de la RA, pour garder identique le poids porté sur la tête ainsi que la même résolution et latence de l'image.


\section{Conception de techniques d'interactions pour le VESAD}
\label{sec:experiment_interactions}

In all three techniques, the user performed pick-and-drop actions to move mis-classified items into their correct container. Each pick-and-drop action was initiated by selecting an item and later selecting the container to drop it in. The user could also pan and zoom the entire grid.

Each trial required the user to correctly classify all 5 items that were initially mis-classified. When an item was dropped to an incorrect container, it was counted as an error, but users still had to successfully classify all 5 items.

With the \condition{Téléphone} and \condition{VESAD tactile} techniques, selecting an item or a container was done with a tap on the phone's screen that had to last less than \SI{500}{\ms}; panning was done by pressing and dragging a single finger; and zooming was done with two fingers using the status quo pinch-to-zoom gesture.

With \condition{VESAD tactile}, the user directly pointed at targets, but this could only be done on the portion of the grid visible within the phone's screen. To select a target item or target container outside the phone's screen, the user first had to pan the target into the phone's screen (or zoom out enough to make the target visible on the phone's screen).

In all techniques, panning responded with a 1:1 gain, as if the grid was a sheet of paper moving under the friction of the finger tip.

With the \condition{VESAD} condition, zoom could not be done with two fingers as the positions of two fingers in mid-air could not be reliably detected. Instead, 3 modal buttons were displayed along the bottom of the phone's screen \figrefp{ExperimentMidAirInArOut}. Users were instructed to press these buttons with the thumb of their non-dominant hand (the hand holding the phone) to switch to Select, Pan, or Zoom mode. After switching to any of these modes, the index of the the user's dominant hand could then touch down on the VESAD's virtual plane to intersect with it. Selecting an item or a container required switching to Select mode with the non-dominant hand, and then performing a \texten{long press} (longer than \SI{500}{\ms}) with the dominant hand on the VESAD. Panning or zooming required switching to Pan or Zoom mode with the non-dominant hand, and then pressing and dragging with the dominant hand on the VESAD's plane. Zooming was centered on the center of the phone, not of the grid, as the index dragged in and out from the phone to zoom.

Note that, in the \condition{VESAD} condition, the modal buttons displayed along the bottom of the phone's screen were small enough that a complete container with 6 items was still visible with no occlusion on the phone's screen.

In the \condition{VESAD tactile} and \condition{VESAD} conditions, the virtual content in the VESAD was rendered on top of the frames captured by the HMD's front-facing cameras. This resulted in incorrect depth occlusion cues, namely, the dominant hand was occluded by the items which are theoretically \texten{behind} the hand \figrefp{ExperimentMidAirInArOut}. We mitigated this problem in two ways: first, the empty space within each container was transparent and the items were semi-transparent to allow the hand to remain partially visible, and second, the projected position of the dominant hand's finger on the VESAD was shown with a line segment and a black cross. None of the participants complained about the occlusion of the hand by the VESAD. This is somewhat like \cite[Figure 3c]{Piumsomboon2014} where participants of a pilot study preferred a reconstructed hand drawn semi-transparently over virtual objects as much as correct occlusion of the hand with virtual objects.

Lee2013 : Augmented Reality systems exploit the cognitive benefits of co-locating 3D visualizations with direct input in a real environment, using optical combiners [8, 6, 5]. This makes it possible to enable unencumbered 3D input to directly interact with situated 3D graphics in mid-air [5, 9]. -> 5 ref HoloDesk : defense au mid-air pour dire que naturel colocate display et input, interagir directement avec des affichages 3D en l'air (comme sur un écran tactile)
Cite \cite{Chan2010} as justification for the projected finger position on the plane

zoom centré sur le téléphone et non sur la grille : The focus point is generally coincident with the center of the view, more rarely with the cursor position. \cite{Guiard2004}


\section{Matériel}
\label{sec:experiment_material}

Nous avons bien évidemment utilisé notre visiocasque de RA, conçut avec un large champs de vision pour cette expérience et décrit au \autoref{ch:methodology}. Pour le faire fonctionner, nous avons utilisé un ordinateur de bureau sous Windows 10, avec un processeur Intel Core i5 7400 (\SI[product-units = single]{4x3.0}{\GHz}), \SI{8}{\giga\byte} DDR4 de mémoire vive, une carte graphique NVIDIA GeForce GTX 1060 de \SI{6}{\giga\byte}. Pour le téléphone, nous avons utilisé un Xiaomi Redmi Note 4 : sous Android 7, il est récent et léger, à faible prix et possède une bonne puissance de calcul ainsi qu'écran \SI{1920x1080}{\px} de \SI{5.5}{\inch}. Le suivi du télephone était fait grâce à notre bibliothèque de RA ArucoUnity \autoref{sec:aruco_unity} avec trois marqueurs imprimés sur une planche rigide fixée à l'arrière du téléphone \figrefp{ExperimentSmartphone}.

\figureETS[0.3]{ExperimentSmartphone}{
  Le téléphone était suivi avec 6 DoFs par des marqueurs grâce à ArucoUnity.
}

Pour la localisation des mains nous avons utilisé un Leap Motion : c'est un dispositif peu dispendieux, particulièrement utilisé pour concevoir des IHMs avec une main virtuelle pour les visiocasques de RV et très bien intégré avec les moteurs de jeu Unity et Unreal Egine. Nous l'avons fixé la face avant du visiocasque sous la caméra \figrefp{ArRift_1}, et se connecte simplement au PC par USB 3.0.

Enfin, nous avons développé la bibliothèque DevicesSyncUnity pour synchroniser le visiocasque avec le téléphone (\url{https://github.com/NormandErwan/DevicesSyncUnity}). Basée sur la bibliothèque de mise en réseau haut-niveau UNet, fournie avec Unity, elle nous permet de facilement synchroniser les IHMs sur le visiocasque et sur le téléphone en fonction les actions de l'utilisateur, donnant le sentiment d'interagir avec un seul appareil. Il existe une latence perceptible de quelques centièmes de seconde, mais aucun participant n'en a fait la remarque.


\section{Procédure de l'expérience}
\label{sec:experiment_procedure}

Nous avons tout d'abord demandé à chaque participant de lire soigneusement une copie imprimée du formulaire d'information et de consentement, en répondant à leurs questions. Nous avons ensuite ré-expliqué à l'oral les points les plus essentiels : pour qui est faite la recherche, le déroulé de l'expérience, la tâche, la garantie de l'anonymat de leurs données, enfin la possibilité de prendre une pause, de quitter l'expérience ou de demander la suppression de leurs données n'importe quand. Si la personne souhaitait participer, nous lui demandions de signer le formulaire d'information et de consentement, lui en proposions une copie, et lui faisions remplir le pré-questionnaire.

Nous faisions ensuite tester le visiocasque au participant, d'abord en mode RV, en utilisant l'écran d'accueil de l'Oculus, car moins succeptible de provoquer des nausées : il n'y a aucune latence perceptible dans ce mode et une meilleure densité visuelle de l'image \autorefp{subsec:solution_discusion}. Puis en activant les caméras, nous demandions au participant de regarder autour de lui et de bouger ses mains pour s'habituer à la latence et à la dynamique plus restreinte de l'image (des ombres vues par l'\oe il humains sont totalement noires dans le visiocasque, comme on peut le voir sur la \autoref{ExperimentPhoneOnly}). Le participant démarrait alors les essais. Il y avait, pour chaque technique, un essai d'entraînement au début (pas de consignes données et aucune mesures) et une pause obligatoire à la fin. L'ensemble des essais durait environ 50 minutes.

Une fois les essais terminés, nous faisions remplir le post-questionnaire pour recueillir les mesures subjectives, ainsi que le formulaire de compensation et leur donnions 20\$ en échange de leur participation.

Les deux formulaires et les deux questionnaires que nous avons présentés aux participants sont à l'\appendixref{experiment_forms}.


\section{Participants}
\label{sec:experiment_participants}

Nous avons recruté 16 personnes volontaires pour participer à l'expérience parmi notre entourage. Cependant, nous travaillons avec les données de 12 d'entre eux : il y a eu des erreurs de mesures pour deux d'entre elle, et deux personnes ont arrêtés l'expérience après l'entrainement, le visiocasque leur donnant des nausées.

Ces 12 participants, dont trois femmes, étaient agés entre 18 et 49 ans (deux au dessus de 25 ans). Tous avaient une vision normale ou portaient un dispositif de correction de vision ; une personne a dit ne pas savoir distinguer  les couleurs pastels mais a été capable, lors de l'entrainement, de reconnaître les éléments à classer sur la grille. Dix étaient droitier et deux gauchers. Huits d'entre eux avaient déjà utilisé un visiocasque de RV, dont un avaait déjà utilisé plusieurs visiocasques de RA. Tous utilisent tous les jours un ordinateur dont huits utilisent régulièrement des logiciels avec un environment 3D.


\section{Mesures}
\label{sec:experiment_measures}

Toutes nos données mesurées ainsi que nos analyses sont disponibles en ligne (\url{https://github.com/NormandErwan/HandheldVesadAnalysis}), dans le domaine public (\url{http://unlicense.org}).

Pré-questionnaire

Comme nous avons synchronisé les IHMs du téléphone et du visiocasque, nous avons effectué les mesures des essais seulement  
Mesures :
\begin{itemize}
  \item Temps total : \condition{VESAD tactile} > \condition{Téléphone} > \condition{VESAD} : imprécisions interactions sur \condition{VESAD} vs. grand espace et précision touch sur \condition{VESAD tactile} (donc moins besoin de zoomer/dezoomer)
  \item Erreurs, nombre de sélections, nombre de déselections : \condition{VESAD} > \condition{Téléphone} > \condition{VESAD tactile} : imprécisions interactions sur \condition{VESAD} vs. grand espace et précision touch sur \condition{VESAD tactile}
  \item Pan count, time, distance : \condition{Téléphone} > (\condition{VESAD tactile} = \condition{VESAD}) : si on voit un espace plus grand, moins de drags et plus efficaces
  \item Zoom count, time, distance : \condition{Téléphone} > (\condition{VESAD tactile} = \condition{VESAD}) : si on voit un espace plus grand, moins de zooms et plus efficaces
  \item Head phone distane : (\condition{VESAD tactile} = \condition{VESAD}) > \condition{Téléphone} : pour mieux voir les lettres qui sont loins du téléphone
\end{itemize}

Two kinds of mistakes could happen during trials. First, a user could select an item and attempt to drop it in an incorrect container. This was counted toward the number of errors for the trial. Second, a user could select one item, and while searching for the container to drop it in, they might decide to select a different item (possibly because they forgot the letter of the first item), causing their previous selection to be canceled. This was not counted toward errors, but was counted toward the total number of selections. Because there were 5 mis-classified items to move during each trial, selections was at least 5 in each trial, and in general, selections = 5 + errors + (number of times the user canceled a selection). Hence, errors is a more conservative measure of classification errors, whereas selections includes both kinds of mistakes.

Notre post-questionnaire est principalement inspiré du NASA TLX \citep{}
Post-questionnaire, inspiré du NASA TLX (enlevé charge physique, mais ajouté facilité de compréhension (pour évaluer l'intuitif))
\begin{itemize}
  \item facilité de compréhension : \condition{VESAD} est plus difficile à comprendre et demande un temps d'essai
  \item charge mentale : notre tâche demande de la recherche, de l'observation, de la mémorisation et des décisions ; je pense que \condition{VESAD tactile} demande moins de charge mentale
  \item fatigue : \condition{VESAD} est la plus fatiguante car bras en l'air et longtemps car lent, \condition{VESAD tactile} la moins fatiguante car la plus rapide
  \item interagir rapidement : \condition{VESAD} le moins car imprécision + touche de l'intangible (pb de placement du doigt, quand c'est touché ou non, quand arrêter le touché), \condition{VESAD tactile} egal avec \condition{Téléphone} car interaction connue et maitrisé des participants
  \item performance (inclus erreurs en plus du temps) : je trouve intéressant que les participants puissent noter leur performance ressentie, pour la comparer avec leur temps et nombre d'erreurs ; les gens vont se sentir un peu moins bon sur \condition{VESAD}, un peu plus sur \condition{VESAD tactile}
  \item frustration : je trouve la technique \condition{VESAD} est très frustrante, la technique \condition{VESAD tactile} est la moins frustrante
  \item préférence : \condition{VESAD} > \condition{VESAD tactile} > \condition{Téléphone} car effet de nouveauté
\end{itemize}


\section{Résultats}
\label{sec:experiment_results}

\subsection{Temps de complétion}
\label{subsec:experiment_results_time}

On transforme tout d'abord les mesures de temps de complétion d'un essai avec un logarithmique népérien pour rendre leurs distributions approximativement normales et réduire l'influence des mesures extrêmes \citep[p. 25]{Dragicevic2016}. La \figref{tct_distributions_all} montre les distributions des temps mesurés et transformés. On vérifie ensuite la normalité des distributions avec le test de Shapiro-Wilk\footnote{L'hypothèse nulle testée est que la distribution suit la loi normale ; on attend donc une valeur-p supérieure à 0,05 pour ne pas la rejeter.} \citep{Wobbrock2016} pour chaque \variable{TECHNIQUE}, car c'est la variable indépendante nous importe le plus : elles sont normales pour les trois techniques \condition{Téléphone} ($W=0,98$ ; $p=0,76$), \condition{VESAD tactile} ($W=0,97$ ; $p=0,45$) et \condition{VESAD} ($W=0,97$ ; $p=0,45$). En outre, le test de Levene\footnote{L'hypothèse nulle testée est que les variances des distributions sont égales.} ($W=0,76$ ; $p=0,47$) nous permet de vérifier que leurs variances sont égales \citep{Wobbrock2016}.

\figureLayoutETS{tct_distributions_all}{%
  \parbox{0.9\textwidth}{%
    \centering%
    \subfigureETS[0.2]{tct_distributions}{Données mesurées.}%
    \\%
    \subfigureETS[0.2]{tct_distributions_log}{Données transformées avec le logarithme népérien.}%
  }
}{
  Histogrammes du temps de complétion d'un essai pour chaque \variable{TECHNIQUE}.
}

\begin{tableETS}{tab:tct_anova}{Résultats de l'ANOVA sur le temps de complétion pour toutes les variables indépendantes.}
  \begin{tabular}{| l | C{1.5cm} | C{1.5cm} | C{1.8cm} | c | c |}
    \hline \textbf{Effet} & \textbf{Somme des carrés} & \textbf{Degrés de liberté}\footnotemark & \textbf{Degrés de liberté de l'erreur}\footnotemark & \textbf{F} & \textbf{p} \\
    \hline \variable{TECHNIQUE} & 12,3 & 2 & 22 & 62,2 & \num{2e-19} \\
    \hline \variable{TAILLE} & 0,1 & 1 & 11 & 1,5 & \num{2e-1} \\
    \hline \variable{DISTANCE} & 0,03 & 1 & 11 & 0,3 & \num{6e-1} \\
    \hline \variable{GROUPE} & 2,1 & 2 & 22 & 10,8 & \num{5e-5} \\
    \hline \variable{TECHNIQUE}$\times$\variable{TAILLE} & 0,4 & 2 & 22 & 2,0 & \num{1e-1} \\
    \hline \variable{TECHNIQUE}$\times$\variable{DISTANCE} & 0,07 & 2 & 22 & 0,4 & \num{7e-1} \\
    \hline \variable{TAILLE}$\times$\variable{DISTANCE} & 0,3 & 1 & 11 & 2,9 & \num{9e-2} \\
    \hline \variable{TECHNIQUE}$\times$\variable{GROUPE} & 3,1 & 4 & 44 & 7,8 & \num{1e-5} \\
    \hline \variable{TECHNIQUE}$\times$\variable{TAILLE}$\times$\variable{DISTANCE} & 0,5 & 2 & 22 & 2,5 & \num{8e-2} \\
    \hline Résidus & 12,5 & 126 & & & \\
    \hline
  \end{tabular}
\end{tableETS}

On analyse alors l'effet de toutes les variables indépendantes sur le temps de complétion avec une analyse de variance (ANOVA). Nous pouvons utiliser ce test car les distributions testées sont normales, indépendantes et ont la même variance \citep{Wobbrock2016}. On utilise le modèle suivant : \variable{TEMPS} $\sim$ \variable{TECHNIQUE} $\times$ \variable{TAILLE} $\times$ \variable{DISTANCE} $+$ \variable{TECHNIQUE} $\times$ \variable{GROUPE}. Le \autoref{tab:tct_anova} donne les résultats : ainsi, les variables \variable{TECHNIQUE} ($F_{2,22}=62,2$ ; $p=$\numrel{2e-19}) et \variable{GROUPE} ($F_{2,22}=2,1$ ; $p=$\numrel{5e-5}), ainsi que leur interaction \variable{TECHNIQUE} $\times$ \variable{GROUPE} ($F_{4,44}=3,1$ ; $p=$\numrel{1e-5}) ont un effet significatif sur le temps de complétion.

On les compare alors deux-à-deux avec le test t de Student, avec une correction de Benjamini-Hochberg pour limiter le nombre de faux positifs \autorefp{subsec:litterature_ar_hci_evaluation}. Ce test suppose aussi la normalité, l'indépendance et une variance égale des distributions. Les résultats, au \autoref{tab:tct_ttest}, indiquent des différences significatives entre les trois techniques. On calcule alors les moyennes avec intervalles de confiances à 95\% sur les données transformée et y applique la fonction exponentielle. La \figref{tct} donne une donc une bonne preuve que les différences sont également importantes : le \condition{VESAD tactile} est plus rapide de \SI{22}{\s} (+33\%) que le \condition{Téléphone}, lui même plus rapide de \SI{49}{\s} (+36\%) que le \condition{VESAD}.

\footnotetext[4]{$Ddl = conditions - 1$.}
\footnotetext{$Ddl_{erreur} = Ddl \times (observations - 1)$.}

\begin{tableETS}{tab:tct_ttest}{Résultats de tests t sur toutes les paires de \variable{TECHNIQUE}.}
  \begin{tabular}{| c | c | c | c |}
    \hline \textbf{Technique 1} & \textbf{Technique 2} & \textbf{T} & \textbf{p} \\
    \hline \condition{Téléphone} & \condition{VESAD tactile} & \num{4.1} & \num{9e-5} \\
    \hline \condition{VESAD} & \condition{Téléphone} & \num{5.6} & \num{3e-5} \\
    \hline \condition{VESAD} & \condition{VESAD tactile} & \num{9.0} & \num{6e-14} \\
    \hline
  \end{tabular}
\end{tableETS}

\figureETS[0.65]{tct}{
  Temps de complétion moyens par essai pour chaque \variable{TECHNIQUE} (les barres d'erreurs montrent l'intervalle de confiance à 95\%).
}

Cependant, la \figref{tct_ordering} semble indiquer que le \variable{GROUPE} n'a pas d'effet important, mais seulement dans certaines conditions : les participants qui ont commencé avec le \condition{Téléphone} (\condition{Groupe 1}) ont été plus lents avec cette technique, tandis que ceux qui ont terminé avec \condition{VESAD tactile} (\condition{Groupe 3}) ont été plus rapide sur cette technique. Dans les autres conditions, il paraît ne pas avoir de différence entre les temps de complétion. Cela semble indiquer que, d'une part, il y a effectivement une courbe d'apprentissage avec cette tâche, en particulier quand les utilisateurs doivent reconstruire mentalement la grille, le \condition{Téléphone} en affichant une vue non entière. D'autre part, le \condition{VESAD tactile} semble être la technique la plus rapide quand la tâche est maîtrisée.

\figureETS[0.8]{tct_ordering}{
  Temps de complétion moyens (IC à 95\%) par essai pour chaque condition \variable{TECHNIQUE} $\times$ \variable{GROUPE}.
}

\subsection{Erreurs et sélections}
\label{subsec:experiment_results_errors}

On visualise tout d'abord les distributions des erreurs et du nombre de sélections. La \figref{selections_errors_distributions} donne une bonne indication qu'il y a corrélation entre erreurs et sélections pour chaque technique. Il semble également que les utilisateurs \condition{Téléphone} font plus de sélections, à erreurs égales, que sur les autres techniques.

\figureETS[0.75]{selections_errors_distributions}{
  Histogrammes et nuages de points des erreurs et du nombre de sélections par technique.
}

Les distributions des deux variables ne suivant pas une loi normale, nous utilisons des tests non-paramétrique \citep{Wobbrock2016}. On utilise alors le test de Kruskal-Wallis (avec une correction de Benjamini-Hochberg) pour vérifier les effets des variables indépendantes. Les résultats indiquent que seuls la \variable{TECHNIQUE} ($H = 15,1$ ; $p = 0,004$) et le \variable{GROUPE} ($H = 11,5$ ; $p = 0,01$) ont un effet significatif sur le nombre de sélections, mais que seul le \variable{GROUPE} ($H = 11,1$ ; $p = 0,01$) a un effet significatif sur les erreurs.

On compare alors deux-à-deux les différentes techniques pour le nombre de sélection avec le test de Wilcoxon-Mann-Whitney (avec une correction de Benjamini-Hochberg). Il y a des différences significatives entre pour les paires \{\condition{Téléphone}, \condition{VESAD tactile}\} ($p = 0.0006$) and \{\condition{Téléphone}, \condition{VESAD}\} ($p = 0.03$) pairs, mais pas pour la paire \{\condition{VESAD tactile}, \condition{VESAD}\} ($p = 0.06$). However, the \autoref{fig:mistakes} points that \condition{VESAD tactile} requires the less selections of the three techniques.

\figureLayoutETS{selections_errors}{%
  \subfigureETS[0.25]{selections}{Nombre moyen d'éléments sélectionnés.}%
  \figurehspace%
  \subfigureETS[0.25]{errors}{Nombre moyen d'erreurs (éléments qui ont été mal classés par le participant).}%
}{
  Sélections et erreurs moyennes (IC à 95\%) par essai pour chaque \variable{TECHNIQUE}.
}

The poor performance of \condition{Téléphone} in terms of selections agrees with our observation that, when using \condition{Téléphone}, users sometimes forgot what they had selected or changed their mind during the drop operation, increasing the number of selections. At the same time, the poor performance of \condition{VESAD} in terms of errors agrees with our observation that, with this technique, users sometimes dropped items in the wrong container, not voluntarily but because they were too zoomed out and/or the sensing limitations of the Leap Motion made it difficult to successfully aim at targets, especially when arms were crossed (i.e., the user was trying to drop an item on the opposite side of the arm holding the phone).

Finally, breaking Selections down by Ordering \figrefp{errors_ordering}, it appears that users committed more mistakes in the \condition{Téléphone} condition when that was the first condition they experienced (\condition{Group1}), suggesting that this technique was initially more prone to mistakes, possibly due to the limited screen size.

\figureLayoutETS{selections_errors_ordering}{%
  \subfigureETS[0.25]{selections_ordering}{Nombre moyen d'éléments sélectionnés.}%
  \figurehspace%
  \subfigureETS[0.25]{errors_ordering}{Nombre moyen d'erreurs.}%
}{
  Sélections et erreurs moyennes (IC à 95\%) par essai pour chaque condition \variable{TECHNIQUE} $\times$ \variable{GROUPE}.
}

\subsection{Navigation}
\label{subsec:experiment_results_navigation}

- Both for *PhoneInArOut* and *PhoneOnly*, participants used pans more than zooms : in count, in time and in distance.
- Participants were the most effective in **selection time** for *PhoneInArOut* (38.98±19.21 s) rather than for *PhoneOnly* (55.74±27.54 s). We observed that the screen size in *PhoneInArOut* helped to make decisions on items to select or where to drop the selected items.
- Participants used as much **pans** in *PhoneInArOut* as in *PhoneOnly* (~30±19). But it seems they were slightly more effective with in *PhoneInArOut* rather than *PhoneOnly* both in time (14.53±8.10 s / 17.12±10.66 s) and distance (1.09±0.76 m / 1.50±1.31 m). 
- Participants used less **zooms** in *PhoneInArOut* (7.14±6.19) rather than *PhoneOnly* (15.53±8.63). They were also more effective with zooms in *PhoneInArOut* rather than *PhoneOnly* both in time (6.70±6.83 s / 15.18±9.00 s) and distance (0.69±0.74 m / 2.11±1.99 m).
- In terms of **physical navigation**, the head-phone distance is the lowest for *PhoneInArOut* (1.57±1.37), the greatest for *MidAirInArOut* (6.12±5.05). *PhoneOnly* is between the two (3.18±3.55). In *MidAirInArOut*, participants moved in conjunction the hand and the phone to select the item: for items at the grid's extremities, it could be easier to rotate the phone to bring the item closer to the head. It seemed that people using both their hands were more effective. Also, both for *PhoneOnly* and *MidAirInArOut*, participants preferred to bring closer the phone if they had trouble to read an item's letter. *PhoneInArOut* required less head-phone movement because participants could let the grid zoomed in and do only pans and drag'n'drop with items to complete the task without many virtual zoom nor physical zoom.

To gain a deeper understanding of the source of differences between
the techniques, for each trial, we recorded the number of times that the user performed a pan or zoom, and the total time spent on these operations,
as well as the total physical distance (as measured projected onto the VESAD plane) traveled by the dominant hand's index finger (the Leap Motion was used to measure these distances, regardless of which \variable{TECHNIQUE} was in use).
% TODO Erwan: in PhoneOnly, there were 2 fingers for zooming, so how was distance calculated? : À chaque fois, je logais la distance totale de l'index seulement. J'utilisais sa position projetté sur la grille, pour que ce soit équivalent entre les trois conditions (on regarde comme l'index se déplace sur le plan de la grille). Donc pour le zoom à deux doigts sur le téléphone, on peut ne compter aucune distance si tout est fait pas le pouce... J'ai présupposé que les participants utiliseraient leur pouce et leur index en même temps pour le pinch to zoom. Je voulais finir vite l'implémentation pour être dans les temps

We similarly quantified the moments when an item was selected, in terms of time and distance, to quantify how much the user was performing pick-and-drop actions.
% TODO Erwan but what does distance mean in this case? Distance traveled by the dominant hand's finger? Only when in contact with the screen / VESAD? Or is it that when the finger would select a target container, you would add the distance from the item's current location to the recorded selection distance?
We also recorded how much head motion was performed, by finding the distance moved by the head (in any direction) with respect to the phone,
from frame to frame, and adding up all these displacements. The data are shown from \figrefp{navigation_time} to \figrefp{navigation_distance}.

\figureETS[0.8]{navigation_time}{
  The total time (per trial) spent with an item selected, or panning, or zooming. Note that these times could overlap.
}

\figureETS[0.9]{navigation_distance}{
  The total distance dragged or moved while (upper left) an item was selected, (upper right) panning, (lower left) zooming, and (lower right) total distance moved by the head with respect to the phone. All quantities are per trial.
}

A first question we consider is: how much virtual navigation (panning and zooming) versus physical navigation (moving the phone with respect to the head) was performed by users in each condition?
% OLD_ARGUMENT_ABOUT_AVOIDING_BIAS_AGAINST_PHONE Did users perform zooming with all techniques? This question is important for the following reason. Users wore the HMD in all conditions, even the \condition{Téléphone} condition, to have the same weight on their head and the same latency in visual feedback. However, as already explained, this pixelated the phone's screen below its normal angular resolution, requiring the user to zoom more than would be necessary in the \condition{Téléphone} condition if the user were not wearing an HMD. However, if the task is difficult enough that it requires zooming with all techniques, then theoretically there is no bias against \condition{Téléphone}: the reduced resolution should penalize all techniques and increase the amount of zooming by an equal amount across techniques.
Virtual navigation was more prominent in the first two techniques. \figrefp{navigation_count} shows that the number of pan and zoom operations for \condition{Téléphone} and \condition{VESAD tactile} was more than 5 per trial, implying that each item to be classified involved, on average, more than one pan and one zoom operation. With the \condition{VESAD} technique, the count is lower, however \figrefp{navigation_distance} (lower left) shows that this technique involved more \texten{physical} navigation as measured by head-phone motion. This can be explained by two observations made during the experiment. First, users often performed physical navigation with \condition{VESAD} to bring target containers closer to their dominant hand. Second, users also found it difficult to perform virtual navigation with \condition{VESAD} due to somewhat unreliable sensing with the Leap Motion. 
% TODO Erwan: actually, we don't know if the head motion was more forward-backward or sideways; if we had more time, it would be good to compute these two components separately. If the motion is mostly sideways, then maybe the text was big enough to see without zooming, which would bias the experiment against PhoneOnly
%Such physical navigation was also possible with the \condition{VESAD tactile} technique, but with that technique, we instead see more zoom operations (\autoref{fig:navCount}) that with \MidAirInArOut, i.e. more virtual navigation rather than physical navigation. In summary, all three techniques required at least some minimal zooming or physical navigation.  because the text labels were too small to read when zoomed out and held at arm's length.  This answers the first question.

\figureETS{navigation_count}{
  The total number of times (per trial) that a pan or zoom operation was performed.
}

A second question is: What was the main weakness of the \condition{VESAD} technique? This technique performed well, compared to the others, in terms of panning and zooming, requiring few of these operations as measured by distance, time, and count. However, \condition{VESAD} also has the worst selection distance \figrefp{navigation_distance} (upper left), indicating the users moved their dominant more when performing pick-and-drop operations to move items to containers. This is an inherent problem with direct input techniques: the user's arm must perform larger motions to touch content directly. User feedback indicates that motions requiring them to cross there arms, to drop an item on the other side of the non-dominant arm, were tiring or awkward. An added problem is the lack of a physical surface that is touched to stabilize the finger's motion during dragging and to provide non-visual feedback. The use of a Leap Motion was also not as reliable for sensing finger position as the phone's touchscreen.

A third question: what explains the smaller TCT with the \condition{VESAD tactile} technique compared to \condition{Téléphone}? \figrefp{navigation_time} shows that \condition{VESAD tactile} required somewhat less time for zooming and slightly less for panning, but the differences are insufficient to explain the difference in total time. We also see that \condition{VESAD tactile} resulted in much less selection time than \condition{Téléphone}. Since most of the difference in time was not spent panning nor zooming, we suspect it was simply easier to find each target container in the \condition{VESAD tactile} because of the increased display area.

\subsection{Évaluations des participants}
\label{subsec:experiment_results_evaluations}

Users rated the three techniques according to 6 criteria on Likert scales (\textit{Voir} \figref{ranks_distributions} et \figref{ranks}) and also gave a ranking for overall Preference \figrefp{preferences}. A Kruskal-Wallis test (Benjamini–Hochberg correction) on each criterion checked for significant differences due to \variable{TECHNIQUE}. Five of the criteria were significantly affected by \variable{TECHNIQUE}: Easy to Understand ($p<0.01$), Mentally Easy to Use ($p<0.01$), Subjective Speed ($p<0.05$), Subjective Performance ($p<0.01$), and overall Preference ($p<0.01$), whereas Physically Easy to Use and Frustration were not significantly affected.

We then used pairwise Mann-Whitney test (with Benjamini–Hochberg correction) for the appropriate criteria, finding the following:
\begin{itemize}
 \item Easy to Understand: \condition{Téléphone} is significantly better than \condition{VESAD} ($p<0.01$). This is not surprising, since the conditionvariable{Téléphone} technique is more familiar to users.
 \item Mentally Easy to Use: \condition{Téléphone} is significantly worse than \condition{VESAD tactile} ($p<0.01$) and \condition{VESAD} ($p<0.05$). This may be due to the limited screen size of the phone.
 \item Subjective Speed: \condition{VESAD tactile} was judged to be significantly faster than \condition{VESAD} ($p=0.05$). This may be due to the precision of the touch gestures and the extended view of the VESAD (so the gestures are more important that the size of the view, because it's not better that the PhoneOnly.
 \item Subjective Performance: \condition{VESAD tactile} is significantly better than \condition{Téléphone} ($p<0.01$) and \condition{VESAD} ($p<0.01$).
 \item Overall Preference: \condition{VESAD tactile} is significantly preferred over \condition{Téléphone} ($p<0.005$) and over \condition{VESAD} ($p<0.05$). 
\end{itemize}

\figureETS[0.9]{ranks_distributions}{
  Distributions des notes données par les participants à chaque technique. Une note élevée est meilleure ($5$ correspond à une faible frustration).
}

\figureETS[0.9]{ranks}{
  Notes moyennes des participants à chaque technique (les barres d'erreurs montrent l'intervalle de confiance à 95\%).
}

\figureETS[0.6]{preferences}{
  Distribution du classement donné par chaque participants aux techniques.
}

Users were also asked their opinion on various concept applications for VESADs. More than half the participants thought the extended map application \figrefp{HandheldVESADMap} would be useful, and all of them thought the multi-tasking support \figrefp{HandheldVESADApp} would be valuable.
%gave also their opinions about the following applications of the VESAD: an app with an extended view like a map (\autoref{fig:map}); multiple screens around the phone  (\autoref{fig:apps}); and notifications on top of the phone. Participants found in majority that the map app could benefit from the extended view. All of them said that the multiple screens could be very interesting, especially for multi-tasking. %But almost none of them found the notifications concept useful. Michael says: they were not shown the latest version of this.