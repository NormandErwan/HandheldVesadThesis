\chapter{Étude expérimentale}
\label{ch:experiment}

\section{Tâche expérimentale}
\label{sec:experiment_task}

\subsection{Description}
\label{subsec:experiment_task_description}

On souhaite évaluer dans cette expérience les avantages d'un téléphone dont l'écran étendu par un visiocasque de RA à large champ de vision, ainsi que comparer deux techniques d'interaction : navigation et pointage avec l'écran tactile ou avec une main virtuelle.

Plusieurs tâches auraient pu convenir à cette expérience. Comme le VESAD est une technique relativement nouvelle et peu étudiée \citep{Grubert2015}, et la technique d'interaction de la main virtuelle peu maîtrisée \citep{Argelaguet2013, Piumsomboon2013}, nous avons besoin d'une tâche fondamentale demandant de la navigation, dont des zooms, et des sélections \citep{Bowman2004}. Nous avons alors envisagé une tâche de pointage de Fitts \citep{Soukoreff2004, Berge2014}, où l'utilisateur doit chercher et sélectionner des cibles, de navigation dans un large document, comme une carte \citep{Baudisch2002, Raedle2014}, ou encore un scénario de multi-tâches où le participant doit travailler avec plusieurs fenêtres \citep{Czerwinski2003, Ens2014}.

Nous avons finalement décidé de répliquer la tâche de classification de \cite{Liu2014} : sa validité externe est plus importante (plus réaliste) qu'une pure tâche de pointage, demande beaucoup de navigations et de reconstruction mentale comme un large document tout en demandant de sélectionner et manipuler le contenu, enfin est plus facile à implémenter et à contrôler qu'un scénario multi-tâches. Cette tâche consistait en une grille de plusieurs cellules contenant des disques \figrefp{Liu2014}. Quelques disques étant mal classés, les participants devaient les déplacer dans la bonne cellule, avec des disques de même type. Une lettre de petite taille inscrite en leur centre permettait de connaître leur type et les disques mal classés étaient colorés en rouge : cela facilitait la recherche et équilibrait avec le temps consacré au classement. Une tâche plus réaliste demanderai d'examiner en détail chaque disque pour savoir les classer (\citeauthor{Liu2014} prennent l'exemple de catégoriser les articles d'une conférence). Enfin, les déplacements se faisaient par un pointage vers le disque puis une sélection par un bouton, puis un second pointage et sélection dans la cellule. Le but de la tâche peut être résumé au participants avec la consigne de [traduction ]\textquote{tout mettre en vert} \citep{Liu2014}.

Notre grille comporte $3 \times 5$ cellules rectangulaires, pouvant chacune contenir six disques maximum. La grille est générée aléatoirement à chaque nouvel essai, avec cinq disques par cellules dont au moins quatre correctement classés, et cinq disques mal classés au total dans la grille \figrefp{TaskGrid}. Il y a donc 15 cellules $\times$ 5 disques/cellule $=$ 75 disques dans la grille. Au début de chaque essai (pour toutes les conditions), elle est affiché à l'échelle, la taille d'une cellule étant celle de l'écran du téléphone que nous avons utilisé, soit \SI{68x121}{\mm} (un disque mesure \SI{33x33}{\mm}) \autorefp{sec:experiment_material}. Ainsi, la grille a une forme approximativement carrée.

\figureETS[0.55]{TaskGrid}{
  La grille de notre tâche expérimentale au début d'un essai dans la condition \variable{TAILLE}=\condition{Grand}.
}

La tâche de \cite{Liu2014} opérationnalise une tâche d'allocation de ressources (par exemple, chaque catégorie a une capacité limitée). Le texte y est alors une variable indépendante importante. N'étudiant pas cette problématique, nous avons décidé de d'utiliser plus simplement une seule lettre par cellule, de A à O. Chaque disque \textquote{appartient} donc à une cellule et ne peut y être correctement classé que dans celle-ci. Nous colorons également les items correctement classés en vert et mal-classés en rouge. Nous colorons en outre un disque sélectionné en bleu \figrefp{ExperimentPhoneInArOut}. De sorte qu'en participant doit lire la lettre d'un disque vert pour savoir le type de la cellule.

Nous avons placé le code source de l'expérience en ligne (\url{https://github.com/NormandErwan/MasterThesisExperiment}), sous la licence libre BSD-3, pour qu'il pouvoir être reproduit ou réutilisé au besoin. Nous l'avons développé et testé pour Unity 2017.


\section{Plan expérimental}
\label{sec:experiment_design}

\figureLayoutETS{ExperimentTechniques}{%
  \subfigureETS{ExperimentPhoneOnly}{Condition \condition{Téléphone}}%
  \figurehspace%
  \subfigureETS{ExperimentPhoneInArOut}{Condition \condition{VESAD tactile}.}%
  \figurehspace%
  \subfigureETS{ExperimentMidAirInArOut}{Condition \condition{VESAD}.}%
}{
  La grille de notre tâche expérimentale pour chaque \variable{TECHNIQUE}. Pour \condition{VESAD tactile}, la main de l'utilisateur est cachée par l'écran étendu et un disque est sélectionné (en bleu). Pour \condition{VESAD}, une sphère blanche indique la position repérée de l'index de l'utilisateur, une croix sur la grille est la projection de cette sphère et un segment noir les relie ; ils deviennent bleus quand la sphère touche la grille.
}

Nous avons manipulé simultanément les variables indépendantes suivantes :
\begin{itemize}
  \item \variable{TECHNIQUE} : l'IHM évaluée, soit :
  \begin{itemize}
    \item \condition{Téléphone} : affichage et interactions seulement sur le téléphone \figrefp{ExperimentPhoneOnly} ;
    \item \condition{VESAD tactile} : affichage sur l'écran étendu et interactions sur le téléphone \figrefp{ExperimentPhoneInArOut} ;
    \item \condition{VESAD} : affichage sur l'écran étendu et interactions dans la partie virtuelle de l'écran avec une main virtuelle \figrefp{ExperimentMidAirInArOut}.
  \end{itemize}
  \item \variable{TAILLE} : la taille du texte des disques :
  \begin{itemize}
    \item \condition{Grand} : \SI{12}{\pt}, soit \SI{4.22x4.22}{\mm} ou 12\% du diamètre du disque ;
    \item \condition{Petit} : \SI{10}{\pt}, soit \SI{3.51x3.51}{\mm} ou 10\% du diamètre du disque.
  \end{itemize}
  \item \variable{DISTANCE} : la distance moyenne des disques à classer avec leurs cellule respectives :
  \begin{itemize}
    \item \condition{Proche} : entre 1,25 et 1,45 ;
    \item \condition{Loin} : entre 2,5 et 2,75.
  \end{itemize}
  \item \variable{GROUPE} : l'ordre de passage des techniques \autorefp{tab:experiment_groups}.
\end{itemize}
\medskip

La variable indépendante \variable{TECHNIQUE} combine les deux affichages et les deux techniques d'interactions. La combinaison affichage sur le téléphone seul et interactions avec une main virtuelle ne nous intéressait pas. \cite{Jones2012} l'ont d'ailleurs déjà été évaluée contre le téléphone seul \autorefp{subsec:litterature_ar_hci_interactions}.

La \variable{TAILLE} et la \variable{DISTANCE} nous permettent de contrôler la difficulté de la tâche. En réduisant la \variable{TAILLE} de la lettre dans chaque disque, on impose au participant d'effectuer des zooms plus importants pour les lire, ce qui l'empêche alors de voir beaucoup de disques à la fois. En augmentant la \variable{DISTANCE}, on impose plus de recherches au participant pour trouver la cellule correspondant à un disque à classer. Dans les deux cas, on lui demande un effort de mémoire plus important.

Comme \citeauthor{Liu2014}, nous utilisons la distance euclidienne pour calculer la \variable{DISTANCE} entre un disque mal classé et sa cellule respective. Nous considérons dans le calcul qu'une cellule fait une unité de largeur et une unité de hauteur : il y a donc une distance de 1 entre deux cellules adjacentes. La variable indépendante donne alors le nombre de cellules d'écart entre un disque mal classé et sa cellule respective, par exemple entre 2,5 et 2,75 cellules d'écart en moyenne pour la condition \condition{Loin}. Les valeurs que nous utilisons sont celles de \cite{Liu2014}. À la génération de la grille, on vérifie qu'elle respecte la condition courante, autrement on en régénère une nouvelle. Nous avions mené une étude pilote avec trois participants, demandant de classer dix disques avec de plus petites tailles de texte. Cependant, cette configuration rendu les essais particulièrement éprouvants et longs à compléter. C'est pourquoi nous avons réduit le nombre de disques à classer et augmenté la taille du texte (tout en la gardant suffisamment petite pour que les participants aient besoin de zoomer).

Notre plan expérimental est quasi complet. Les variables indépendantes \variable{TECHNIQUE}, \variable{TAILLE} et \variable{DISTANCE} sont croisées : les participants passent à travers toutes conditions. Cependant, pour contrôler un effet d'apprentissage parasite à travers les techniques, les participants sont partagés en trois \variable{GROUPE} emboîtés : chaque groupe passe à travers les conditions \variable{TECHNIQUE} dans un ordre différent, suivant un carré latin $3 \times 3$ \autorefp{tab:experiment_groups}. L'ordre de passage de la \variable{TAILLE} et de la \variable{DISTANCE} est par contre fixe : du plus simple (avec les conditions \condition{Grand} et \condition{Proche}), au plus difficile (\condition{Petit} et \condition{Loin}). Nous avons donc mesuré 12 participants $\times$ 3 techniques $\times$ 2 distances $\times$ 2 tailles = 144 observations. Pour réduire la variabilité de nos résultats, chaque participant a répété deux essais par condition, que nous avons ensuite moyennés pour avoir une observation par participant, et non par essai \citep[p. 24]{Dragicevic2016}.

\begin{tableETS}{tab:experiment_groups}{Ordre de passage pour chaque \variable{GROUPE} de chaque \variable{TECHNIQUE} suivant un carré latin.}
  \begin{tabular}{| c | c | c | c |}
    \hline
    \textbf{Groupe} & \textbf{Technique 1} & \textbf{Technique 2} & \textbf{Technique 3}\\
    \hline
    1 & \condition{Téléphone} & \condition{VESAD tactile} & \condition{VESAD} \\
    \hline
    2 & \condition{VESAD tactile} & \condition{VESAD} & \condition{Téléphone} \\
    \hline
    3 & \condition{VESAD} & \condition{Téléphone} & \condition{VESAD tactile} \\
    \hline
  \end{tabular}
\end{tableETS}

Enfin, les utilisateurs ont porté le visiocasque de RA \autorefp{ch:methodology} dans toutes les conditions, même dans la condition \condition{Téléphone} qui ne bénéficie pas de la RA, pour garder identique le poids porté sur la tête ainsi que la même résolution et latence de l'image.


\section{Conception de techniques d'interactions pour le VESAD}
\label{sec:experiment_interactions}

In all three techniques, the user performed pick-and-drop actions to move mis-classified items into their correct container. Each pick-and-drop action was initiated by selecting an item and later selecting the container to drop it in. The user could also pan and zoom the entire grid.

Each trial required the user to correctly classify all 5 items that were initially mis-classified. When an item was dropped to an incorrect container, it was counted as an error, but users still had to successfully classify all 5 items.

With the \condition{Téléphone} and \condition{VESAD tactile} techniques, selecting an item or a container was done with a tap on the phone's screen that had to last less than \SI{500}{\ms}; panning was done by pressing and dragging a single finger; and zooming was done with two fingers using the status quo pinch-to-zoom gesture.

With \condition{VESAD tactile}, the user directly pointed at targets, but this could only be done on the portion of the grid visible within the phone's screen. To select a target item or target container outside the phone's screen, the user first had to pan the target into the phone's screen (or zoom out enough to make the target visible on the phone's screen).

In all techniques, panning responded with a 1:1 gain, as if the grid was a sheet of paper moving under the friction of the finger tip.

With the \condition{VESAD} condition, zoom could not be done with two fingers as the positions of two fingers in mid-air could not be reliably detected. Instead, 3 modal buttons were displayed along the bottom of the phone's screen \figrefp{ExperimentMidAirInArOut}. Users were instructed to press these buttons with the thumb of their non-dominant hand (the hand holding the phone) to switch to Select, Pan, or Zoom mode. After switching to any of these modes, the index of the the user's dominant hand could then touch down on the VESAD's virtual plane to intersect with it. Selecting an item or a container required switching to Select mode with the non-dominant hand, and then performing a \texten{long press} (longer than \SI{500}{\ms}) with the dominant hand on the VESAD. Panning or zooming required switching to Pan or Zoom mode with the non-dominant hand, and then pressing and dragging with the dominant hand on the VESAD's plane. Zooming was centered on the center of the phone, not of the grid, as the index dragged in and out from the phone to zoom.

Note that, in the \condition{VESAD} condition, the modal buttons displayed along the bottom of the phone's screen were small enough that a complete container with 6 items was still visible with no occlusion on the phone's screen.

In the \condition{VESAD tactile} and \condition{VESAD} conditions, the virtual content in the VESAD was rendered on top of the frames captured by the HMD's front-facing cameras. This resulted in incorrect depth occlusion cues, namely, the dominant hand was occluded by the items which are theoretically \texten{behind} the hand \figrefp{ExperimentMidAirInArOut}. We mitigated this problem in two ways: first, the empty space within each container was transparent and the items were semi-transparent to allow the hand to remain partially visible, and second, the projected position of the dominant hand's finger on the VESAD was shown with a line segment and a black cross. None of the participants complained about the occlusion of the hand by the VESAD. This is somewhat like \cite[Figure 3c]{Piumsomboon2014} where participants of a pilot study preferred a reconstructed hand drawn semi-transparently over virtual objects as much as correct occlusion of the hand with virtual objects.

Lee2013 : Augmented Reality systems exploit the cognitive benefits of co-locating 3D visualizations with direct input in a real environment, using optical combiners [8, 6, 5]. This makes it possible to enable unencumbered 3D input to directly interact with situated 3D graphics in mid-air [5, 9]. -> 5 ref HoloDesk : defense au mid-air pour dire que naturel colocate display et input, interagir directement avec des affichages 3D en l'air (comme sur un écran tactile)\cite{Chan2010} as justification for the projected finger position on the plane

zoom centré sur le téléphone et non sur la grille : The focus point is generally coincident with the center of the view, more rarely with the cursor position. \cite{Guiard2004}


\section{Matériel}
\label{sec:experiment_material}

Nous avons bien évidemment utilisé notre visiocasque de RA, conçut avec un large champs de vision pour cette expérience et décrit au \autoref{ch:methodology}. Pour le faire fonctionner, nous avons utilisé un ordinateur de bureau sous Windows 10, avec un processeur Intel Core i5 7400 (\SI[product-units = single]{4x3.0}{\GHz}), \SI{8}{\giga\byte} DDR4 de mémoire vive, une carte graphique NVIDIA GeForce GTX 1060 de \SI{6}{\giga\byte}. Pour le téléphone, nous avons utilisé un Xiaomi Redmi Note 4 : sous Android 7, il est récent et léger, à faible prix et possède une bonne puissance de calcul ainsi qu'écran \SI{1920x1080}{\px} de \SI{5.5}{\inch}. Le suivi du téléphone était fait grâce à notre bibliothèque de RA ArucoUnity \autoref{sec:aruco_unity} avec trois marqueurs imprimés sur une planche rigide fixée à l'arrière du téléphone \figrefp{ExperimentSmartphone}.

\figureETS[0.3]{ExperimentSmartphone}{
  Le téléphone était suivi avec 6 DoFs par des marqueurs grâce à ArucoUnity.
}

Pour la localisation des mains nous avons utilisé un Leap Motion : c'est un dispositif peu dispendieux, particulièrement utilisé pour concevoir des IHMs avec une main virtuelle pour les visiocasques de RV et très bien intégré avec les moteurs de jeu Unity et Unreal Egine. Nous l'avons fixé la face avant du visiocasque sous la caméra \figrefp{ArRift_1}, et se connecte simplement au PC par USB 3.0.

Enfin, nous avons développé la bibliothèque DevicesSyncUnity pour synchroniser le visiocasque avec le téléphone (\url{https://github.com/NormandErwan/DevicesSyncUnity}). Basée sur la bibliothèque de mise en réseau haut-niveau UNet, fournie avec Unity, elle nous permet de facilement synchroniser les IHMs sur le visiocasque et sur le téléphone en fonction les actions de l'utilisateur, donnant le sentiment d'interagir avec un seul appareil. Il existe une latence perceptible de quelques centièmes de seconde, mais aucun participant n'en a fait la remarque.


\section{Procédure de l'expérience}
\label{sec:experiment_procedure}

Nous avons tout d'abord demandé à chaque participant de lire soigneusement une copie imprimée du formulaire d'information et de consentement, en répondant à leurs questions. Nous avons ensuite ré-expliqué à l'oral les points les plus essentiels : pour qui est faite la recherche, le déroulé de l'expérience, la tâche, la garantie de l'anonymat de leurs données, enfin la possibilité de prendre une pause, de quitter l'expérience ou de demander la suppression de leurs données n'importe quand. Si la personne souhaitait participer, nous lui demandions de signer le formulaire d'information et de consentement, lui en proposions une copie, et lui faisions remplir le pré-questionnaire.

Nous faisions ensuite tester le visiocasque au participant, d'abord en mode RV, en utilisant l'écran d'accueil de l'Oculus, car moins susceptible de provoquer des nausées : il n'y a aucune latence perceptible dans ce mode et une meilleure densité visuelle de l'image \autorefp{subsec:solution_discusion}. Puis en activant les caméras, nous demandions au participant de regarder autour de lui et de bouger ses mains pour s'habituer à la latence et à la dynamique plus restreinte de l'image (des ombres vues par l'\oe il humains sont totalement noires dans le visiocasque, comme on peut le voir sur la \autoref{ExperimentPhoneOnly}). Nous donnions alors le téléphone dans la main dominante du participant pour qu'il puisse démarrer les essais. Il y avait, pour chaque technique, un essai d'entraînement au début (pas de consignes données et aucune mesures) et une pause obligatoire à la fin. L'ensemble des essais durait environ 50 minutes. Avant chaque essai, nous demandions au participant d'\textquote{aller le plus vite possible en faisant le moins d'erreurs possibles}. Nous lui précisions qu'une erreur était comptée seulement s'il déplaçait une disque dans une mauvaise cellule.

Une fois les essais terminés, nous faisions remplir le post-questionnaire pour recueillir les mesures subjectives, ainsi que le formulaire de compensation et leur donnions 20\$ en échange de leur participation.

L'\appendixref{experiment_forms} contient les deux formulaires et les deux questionnaires.


\section{Mesures}
\label{sec:experiment_measures}

Dans notre pré-questionnaire, nous demandions d'abord la catégorie d'âge (catégories de cinq ans), le sexe et les problèmes de vues éventuel du participant. Nous demandions ensuite leur main dominante et la main utilisant la souris : quelques participants gauchers utilisaient leur main droite avec la souris mais on préféré tenir le téléphone avec leur main gauche, après essais. Nous demandions enfin leur utilisation de l'ordinateur, de logiciels 3D et leurs expériences passées en VR et RA. Nous ne nous sommes pas servis de ces mesures dans nos analyses.

Nous avons effectué les mesures des essais seulement sur l'ordinateur, comme nous l'avions synchronisé avec le téléphone. Nous avons tout d'abord utilisé, comme principale mesures de la performance, le temps de complétion de chaque essai ainsi que le nombres d'erreurs (les disques placés dans une mauvaise cellule par le participant). Nous avons compté, en complément des erreurs, le nombre de disques sélectionnés pendant un essai : pendant sa recherche, un participant peut oublier le disque qu'il avait sélectionné ou décider de changer de disque à classer ; une sélection d'un nouveau disque désélectionne automatiquement le précédent, sans que ce soit compté comme une erreur (cela était précisé aux participants). Le nombre de sélection peut être résumé ainsi : sélections $=$ 5 disques à classer $+$ erreurs $+$ sélections annulées.

Nous avons en outre fait des mesures sur la navigation des participants lors des essais : le nombre de défilements et de zooms, ainsi que le temps passé et la distance parcourue durant ces opérations. Même si la main virtuelle était désactivée pour certaines techniques, nous suivions en continu la position de la main dominante, lors des essais ; la distance que nous avons enregistré est celle de la projection de l'index de la main sur la grille. C'est une mesure simple mais fonctionnelle et permettant de comparer les trois techniques. Nous avons également compté le temps passé avec un disque sélectionné, pour quantifier le temps de recherche. Enfin, nous avons enregistré la distance entre la tête et le téléphone pour mesurer la navigation physique.

Notre post-questionnaire nous a permis de relever des mesures subjectives, où nous nous sommes principalement inspiré du NASA TLX \cite{Rubio2004}. Nous avons supprimé la question sur la charge physique, que nous ne trouvions pas pertinente dans notre cas et ajouté une question sur la facilité de compréhension de l'IHM. A toutes ces questions, le participant évaluait chaque technique avec une échelle de Likert. Le participant devait ensuite classer par ordre de préférence les trois techniques. Enfin, nous avons présenté des scénarios d'application d'un téléphone à affichage étendu (carte de navigation, application multi-fenêtres et notifications en 3D) et recueilli leurs commentaires.

Nos hypothèses par rapport à l'ensemble de ces mesures sont :
\begin{itemize}
  \item Temps de complétion : le \condition{VESAD tactile} sera le plus rapide et le \condition{VESAD} le plus lent, car le suivi de la main est imprécis pour ce dernier, alors que le \condition{VESAD tactile} bénéficie à la fois d'un grand écran \citep{Liu2014} et d'interactions stables et précises sur l'écran \citep{Jones2012}.
  \item Erreurs et nombre de sélections : le \condition{VESAD} aura le plus d'erreurs, le \condition{VESAD tactile} en aura le moins, pour les mêmes raisons que le temps de complétion.
  \item Nombre, temps et distance des défilements et des zooms : le \condition{Téléphone} sera le moins efficace (plus de défilements et zooms, plus longtemps et plus long), mais il ne devrait pas avoir de différence importante entre les deux autres techniques bénéficiants du grand écrans \citep{Raedle2014}.
  \item Distance des mouvements tête-téléphone : le grand écran du \condition{VESAD tactile} et du \condition{VESAD} incitera à plus de navigation physique des participants, en particulier pour regarder les lettres des disques les plus éloignés du téléphone.
  \item Facilité de compréhension : le \condition{VESAD} sera un peu plus difficile à comprendre et demande un temps d'apprentissage plus long, car il comporte les nouveautés de l'écran étendu et du pointage avec une main virtuelle.
  \item Charge mentale : notre tâche demande de la recherche, de l'observation, de la mémorisation et des décisions ; je pense que \condition{VESAD tactile} demande moins de charge mentale
  \item fatigue : \condition{VESAD} est la plus fatiguante car bras en l'air et longtemps car lent, \condition{VESAD tactile} la moins fatiguante car la plus rapide
  \item interagir rapidement : \condition{VESAD} le moins car imprécision + touche de l'intangible (pb de placement du doigt, quand c'est touché ou non, quand arrêter le touché), \condition{VESAD tactile} egal avec \condition{Téléphone} car interaction connue et maitrisé des participants
  \item performance (inclus erreurs en plus du temps) : je trouve intéressant que les participants puissent noter leur performance ressentie, pour la comparer avec leur temps et nombre d'erreurs ; les gens vont se sentir un peu moins bon sur \condition{VESAD}, un peu plus sur \condition{VESAD tactile}
  \item frustration : je trouve la technique \condition{VESAD} est très frustrante, la technique \condition{VESAD tactile} est la moins frustrante
  \item préférence : \condition{VESAD} > \condition{VESAD tactile} > \condition{Téléphone} car effet de nouveauté
\end{itemize}


\section{Participants}
\label{sec:experiment_participants}

Nous avons recruté 16 personnes volontaires pour participer à l'expérience parmi notre entourage. Cependant, nous travaillons avec les données de 12 d'entre eux : il y a eu des erreurs de mesures pour deux d'entre elle, et deux personnes ont arrêtés l'expérience après l'entrainement, le visiocasque leur donnant des nausées.

Ces 12 participants, dont trois femmes, étaient âgés entre 18 et 49 ans (deux au dessus de 25 ans). Tous avaient une vision normale ou portaient un dispositif de correction de vision ; une personne a dit ne pas savoir distinguer les couleurs pastels mais a été capable, lors de l'entrainement, de reconnaître les éléments à classer sur la grille. Dix étaient droitier et deux gauchers. Huit d'entre eux avaient déjà utilisé un visiocasque de RV, dont un avait déjà utilisé plusieurs visiocasques de RA. Tous utilisent tous les jours un ordinateur dont huit utilisent régulièrement des logiciels avec un environnement 3D.


\section{Résultats}
\label{sec:experiment_results}

Toutes nos analyses sont disponibles en ligne (\url{https://github.com/NormandErwan/HandheldVesadAnalysis}), dans le domaine public (\url{http://unlicense.org}).

Toutes les barres d'erreurs dans nos figures montrent l'intervalle de confiance à 95\%. De même, quand nous reportons une valeur $X$, nous précisons son IC à 95\% ainsi : $X$ [$\text{IC}_{bas}$ ; $\text{IC}_{haut}$].

\subsection{Temps de complétion}
\label{subsec:experiment_results_time}

\figureLayoutETS{tct_distributions_all}{%
  \parbox{0.9\textwidth}{%
    \centering%
    \subfigureETS[0.2]{tct_distributions}{Données mesurées.}%
    \\%
    \subfigureETS[0.2]{tct_distributions_log}{Données transformées avec le logarithme népérien.}%
  }
}{
  Histogrammes du temps de complétion d'un essai pour chaque \variable{TECHNIQUE}.
}

On transforme tout d'abord les mesures de temps de complétion d'un essai avec un logarithmique népérien pour rendre leurs distributions approximativement normales et réduire l'influence des mesures extrêmes \citep[p. 25]{Dragicevic2016}. La \figref{tct_distributions_all} montre les distributions des temps mesurés et transformés. On vérifie ensuite la normalité des distributions avec le test de Shapiro-Wilk\footnote{L'hypothèse nulle testée est que la distribution suit la loi normale ; on attend donc une valeur-p supérieure à 0,05 pour ne pas la rejeter.} \citep{Wobbrock2016} pour chaque \variable{TECHNIQUE}, car c'est la variable indépendante nous importe le plus : elles sont normales pour les trois techniques \condition{Téléphone} ($W = \num{0.98}$ ; $p = \num{0.76}$), \condition{VESAD tactile} ($W = 0,97$ ; $p = \num{0.45}$) et \condition{VESAD} ($W = \num{0.97}$ ; $p = \num{0.45}$). En outre, le test de Levene\footnote{L'hypothèse nulle testée est que les variances des distributions sont égales.} ($W = \num{0.76}$ ; $p = \num{0.47}$) nous permet de vérifier que leurs variances sont égales \citep{Wobbrock2016}.

On analyse alors l'effet de toutes les variables indépendantes sur le temps de complétion avec une analyse de variance (ANOVA). Nous pouvons utiliser ce test car les distributions testées sont normales, indépendantes et ont la même variance \citep{Wobbrock2016}. On utilise le modèle suivant : \variable{TEMPS} $\sim$ \variable{TECHNIQUE} $\times$ \variable{TAILLE} $\times$ \variable{DISTANCE} $+$ \variable{TECHNIQUE} $\times$ \variable{GROUPE}. Le \autoref{tab:tct_anova} donne les résultats : ainsi, les variables \variable{TECHNIQUE} ($F_{2,22} = \num{62.2}$ ; $p = \num{2e-19}$) et \variable{GROUPE} ($F_{2,22} = \num{2.1}$ ; $p = \num{5e-5}$), ainsi que leur interaction \variable{TECHNIQUE} $\times$ \variable{GROUPE} ($F_{4,44} = \num{3.1}$ ; $p = \num{1e-5}$) ont un effet significatif sur le temps de complétion.

\begin{tableETS}{tab:tct_anova}{Résultats de l'ANOVA sur le temps de complétion pour toutes les variables indépendantes.}
  \begin{tabular}{| l | C{1.5cm} | C{1.5cm} | C{1.8cm} | c | c |}
    \hline \textbf{Effet} & \textbf{Somme des carrés} & \textbf{Degrés de liberté}\footnotemark & \textbf{Degrés de liberté de l'erreur}\footnotemark & \textbf{F} & \textbf{p} \\
    \hline \variable{TECHNIQUE} & 12,3 & 2 & 22 & 62,2 & \num{2e-19} \\
    \hline \variable{TAILLE} & 0,1 & 1 & 11 & 1,5 & \num{2e-1} \\
    \hline \variable{DISTANCE} & 0,03 & 1 & 11 & 0,3 & \num{6e-1} \\
    \hline \variable{GROUPE} & 2,1 & 2 & 22 & 10,8 & \num{5e-5} \\
    \hline \variable{TECHNIQUE}$\times$\variable{TAILLE} & 0,4 & 2 & 22 & 2,0 & \num{1e-1} \\
    \hline \variable{TECHNIQUE}$\times$\variable{DISTANCE} & 0,07 & 2 & 22 & 0,4 & \num{7e-1} \\
    \hline \variable{TAILLE}$\times$\variable{DISTANCE} & 0,3 & 1 & 11 & 2,9 & \num{9e-2} \\
    \hline \variable{TECHNIQUE}$\times$\variable{GROUPE} & 3,1 & 4 & 44 & 7,8 & \num{1e-5} \\
    \hline \variable{TECHNIQUE}$\times$\variable{TAILLE}$\times$\variable{DISTANCE} & 0,5 & 2 & 22 & 2,5 & \num{8e-2} \\
    \hline Résidus & 12,5 & 126 & & & \\
    \hline
  \end{tabular}
\end{tableETS}

\figureETS[0.575]{tct}{
  Temps de complétion moyens par essai pour chaque \variable{TECHNIQUE}.
}

On les compare alors deux-à-deux avec le test t de Student, avec une correction de Benjamini-Hochberg pour limiter le nombre de faux positifs \autorefp{subsec:litterature_ar_hci_evaluation}. Ce test suppose aussi la normalité, l'indépendance et une variance égale des distributions. Les résultats, au \autoref{tab:tct_ttest}, indiquent des différences significatives entre les trois techniques. On calcule alors les moyennes avec intervalles de confiances à 95\% sur les données transformée et y applique la fonction exponentielle. La \figref{tct} donne une donc une bonne preuve que les différences sont également importantes : le \condition{VESAD tactile} est plus rapide de \SI{22}{\s} (+33\%) que le \condition{Téléphone}, lui même plus rapide de \SI{49}{\s} (+36\%) que le \condition{VESAD}.

\footnotetext[4]{On calcule les degrés de liberté (ddl) d'une variable indépendante ainsi : $ddl = conditions - 1$.}
\footnotetext{On calcule les ddl de l'erreur pour une variable indépendante ainsi : $ddl_{erreur} = ddl \times (observations - 1)$.}

\begin{tableETS}{tab:tct_ttest}{Résultats de tests t sur toutes les paires de \variable{TECHNIQUE}.}
  \begin{tabular}{| c | c | c | c |}
    \hline \textbf{Technique 1} & \textbf{Technique 2} & \textbf{T} & \textbf{p} \\
    \hline \condition{Téléphone} & \condition{VESAD tactile} & \num{4.1} & \num{9e-5} \\
    \hline \condition{VESAD} & \condition{Téléphone} & \num{5.6} & \num{3e-5} \\
    \hline \condition{VESAD} & \condition{VESAD tactile} & \num{9.0} & \num{6e-14} \\
    \hline
  \end{tabular}
\end{tableETS}

\figureETS[0.7]{tct_ordering}{
  Temps de complétion moyens par essai pour chaque condition \variable{TECHNIQUE} $\times$ \variable{GROUPE}.
}

Cependant, la \figref{tct_ordering} semble indiquer que le \variable{GROUPE} n'a pas d'effet important, mais seulement dans certaines conditions : les participants qui ont commencé avec le \condition{Téléphone} (\condition{Groupe 1}) ont été plus lents avec cette technique, tandis que ceux qui ont terminé avec \condition{VESAD tactile} (\condition{Groupe 3}) ont été plus rapide sur cette technique. Dans les autres conditions, il paraît ne pas avoir de différence entre les temps de complétion. Cela semble indiquer que, d'une part, il y a effectivement une courbe d'apprentissage avec cette tâche, en particulier quand les utilisateurs doivent reconstruire mentalement la grille, le \condition{Téléphone} en affichant une vue non entière. D'autre part, le \condition{VESAD tactile} semble être la technique la plus rapide quand la tâche est maîtrisée.

\subsection{Erreurs et sélections}
\label{subsec:experiment_results_errors}

\figureETS[0.75]{selections_errors_distributions}{
  Histogrammes et nuages de points des erreurs et du nombre de sélections par technique.
}

On visualise tout d'abord les distributions des erreurs et du nombre de sélections. La \figref{selections_errors_distributions} donne une bonne indication qu'il y a corrélation entre erreurs et sélections pour chaque technique. Il semble également que les utilisateurs \condition{Téléphone} font plus de sélections, à erreurs égales, que sur les autres techniques.

Les distributions des deux variables ne suivant pas une loi normale, nous utilisons des tests non-paramétrique \citep{Wobbrock2016}. On utilise alors le test de Kruskal-Wallis (avec une correction de Benjamini-Hochberg) pour vérifier les effets des variables indépendantes. Les résultats indiquent que seuls la \variable{TECHNIQUE} ($H = \num{15.1}$ ; $p = \num{0.004}$) et le \variable{GROUPE} ($H = \num{11.5}$ ; $p = \num{0.01}$) ont un effet significatif sur le nombre de sélections, mais que seul le \variable{GROUPE} ($H = \num{11.1}$ ; $p = \num{0.01}$) a un effet significatif sur les erreurs. La \figref{errors} nous confirme que nous n'avons pas mesuré de différences importantes en terme d'erreurs pour la \variable{TECHNIQUE}.

\figureLayoutETS{selections_errors}{%
  \subfigureETS[0.25]{selections}{Nombre moyen d'éléments sélectionnés.}%
  \figurehspace%
  \subfigureETS[0.25]{errors}{Nombre moyen d'erreurs (éléments qui ont été mal classés par le participant).}%
}{
  Sélections et erreurs moyennes par essai pour chaque \variable{TECHNIQUE}.
}

Pour mieux comprendre l'effet sur le nombre de sélection, on compare deux-à-deux les conditions \variable{TECHNIQUE} avec le test de Wilcoxon-Mann-Whitney (avec une correction de Benjamini-Hochberg). Les résultats indiquent qu'il y a des différences significatives entre pour les paires \{\condition{Téléphone}, \condition{VESAD tactile}\} ($p = \num{6e-4}$) et \{\condition{Téléphone}, \condition{VESAD}\} ($p = \num{0.03}$), mais pas pour la paire \{\condition{VESAD tactile}, \condition{VESAD}\} ($p = \num{0.06}$). La \figref{selections} nous confirme que le \condition{Téléphone} demande le plus de sélections, soit \num{8.18} [\num{7.42} ; \num{9.06}] en moyenne, et que le \condition{VESAD tactile} en demande le moins, soit \num{6.31} [\num{5.97} ; \num{6.66}] en moyenne, mais cette différence est peu importante.

\figureLayoutETS{selections_errors_ordering}{%
  \parbox{.71\textwidth}{%
    \centering%
    \subfigureETS[0.25]{selections_ordering}{Nombre moyen d'éléments sélectionnés.}%
    \\%
    \subfigureETS[0.25]{errors_ordering}{Nombre moyen d'erreurs.}%
  }%
}{
  Sélections et erreurs moyennes par essai pour chaque condition \variable{TECHNIQUE} $\times$ \variable{GROUPE}.
}

Comme pour le temps de complétion, il semble que le \variable{GROUPE} n'a un effet important que dans certaines conditions \figref{selections_errors_ordering} : le \condition{Groupe 1} semble avoir commis un plus d'erreurs et effectué plus de sélections en commençant avec le \condition{Téléphone}, tandis que le \condition{Groupe 3} a fait un peu moins d'erreurs et sélections en terminant avec le \condition{VESAD tactile}. Les autres conditions \variable{TECHNIQUE} $\times$ \variable{GROUPE} ne paraissent pas importantes. Il nous semble que les participants de la condition \{\condition{Groupe 1}, \condition{Téléphone}\}, n'ayant pas encore une bonne image mentale de la grille, vont oublier quel disque était sélectionné ou changer d'avis sur le disque à classer. Enfin, le nombre un peu plus élevé d'erreurs pour \condition{VESAD tactile} nous semble dû à des erreurs involontaires que nous avons parfois observées, le suivi de la main par le Leap Motion n'étant pas toujours bon.

\subsection{Opérations durant les essais}
\label{subsec:experiment_results_operations}

Les comportements des utilisateurs durant les essais nous permettent de mieux comprendre ces différences entre les techniques.

\figureETS[0.65]{navigation_count}{
  Nombre total moyen par essai de défilements et de zooms pour chaque \variable{TECHNIQUE}.
}

\figureETS[0.85]{navigation_distance}{
  La distance parcourue par l'index (en haut à gauche) pendant qu'un disque était sélectionné, (en haut à droite) pendant les défilements, (en bas à gauche) pendant les zooms, ainsi que (en bas à droite) la distance des mouvements de la tête par rapport au téléphone. Toutes les mesures sont des moyennes par essai pour chaque \variable{TECHNIQUE}.
}

Tout d'abord, nous comparons navigations virtuelles et physiques. La \figref{navigation_count} nous indique que la navigation virtuelle a été principalement utilisée avec les techniques \condition{Téléphone} et \condition{VESAD tactile} avec en moyenne plus de 25 défilements et cinq zooms par essai. Autrement dit, chaque disque a demandé en moyenne plus d'un défilement et au moins un zoom pour être classé avec ces techniques. En revanche, les participants ont peu utilisé les techniques de défilement et de zoom virtuels avec le \condition{VESAD}, mais privilégié une navigation physique \figrefp{navigation_distance} ; nous avons observé des déplacements bi-manuels pour placer au même endroit la main virtuelle et un disque à sélectionner. Des participants ont, par ailleurs, fait la remarque que le suivi du téléphone était plus stable que celui de la main. La navigation physique reste importante pour les deux premières techniques \figrefp{navigation_distance} : nous avons fréquement observé des mouvements de \textquote{rapides zooms physiques} dans toutes les conditions, où le participant rapprochait le téléphone de son visage, pour pouvoir lire une lettre d'un disque.

A second question is: What was the main weakness of the \condition{VESAD} technique? This technique performed well, compared to the others, in terms of panning and zooming, requiring few of these operations as measured by distance, time, and count. However, \condition{VESAD} also has the worst selection distance \figrefp{navigation_distance} (upper left), indicating the users moved their dominant more when performing pick-and-drop operations to move items to containers. This is an inherent problem with direct input techniques: the user's arm must perform larger motions to touch content directly. User feedback indicates that motions requiring them to cross there arms, to drop an item on the other side of the non-dominant arm, were tiring or awkward. An added problem is the lack of a physical surface that is touched to stabilize the finger's motion during dragging and to provide non-visual feedback. The use of a Leap Motion was also not as reliable for sensing finger position as the phone's touchscreen.

A third question: what explains the smaller TCT with the \condition{VESAD tactile} technique compared to \condition{Téléphone}? \figrefp{navigation_time} shows that \condition{VESAD tactile} required somewhat less time for zooming and slightly less for panning, but the differences are insufficient to explain the difference in total time. We also see that \condition{VESAD tactile} resulted in much less selection time than \condition{Téléphone}. Since most of the difference in time was not spent panning nor zooming, we suspect it was simply easier to find each target container in the \condition{VESAD tactile} because of the increased display area.


- Both for *PhoneInArOut* and *PhoneOnly*, participants used pans more than zooms : in count, in time and in distance.
- Participants were the most effective in **selection time** for *PhoneInArOut* (38.98±19.21 s) rather than for *PhoneOnly* (55.74±27.54 s). We observed that the screen size in *PhoneInArOut* helped to make decisions on items to select or where to drop the selected items.
- Participants used as much **pans** in *PhoneInArOut* as in *PhoneOnly* (~30±19). But it seems they were slightly more effective with in *PhoneInArOut* rather than *PhoneOnly* both in time (14.53±8.10 s / 17.12±10.66 s) and distance (1.09±0.76 m / 1.50±1.31 m). 
- Participants used less **zooms** in *PhoneInArOut* (7.14±6.19) rather than *PhoneOnly* (15.53±8.63). They were also more effective with zooms in *PhoneInArOut* rather than *PhoneOnly* both in time (6.70±6.83 s / 15.18±9.00 s) and distance (0.69±0.74 m / 2.11±1.99 m).
- In terms of **physical navigation**, the head-phone distance is the lowest for *PhoneInArOut* (1.57±1.37), the greatest for *MidAirInArOut* (6.12±5.05). *PhoneOnly* is between the two (3.18±3.55). In *MidAirInArOut*, participants moved in conjunction the hand and the phone to select the item: for items at the grid's extremities, it could be easier to rotate the phone to bring the item closer to the head. It seemed that people using both their hands were more effective. Also, both for *PhoneOnly* and *MidAirInArOut*, participants preferred to bring closer the phone if they had trouble to read an item's letter. *PhoneInArOut* required less head-phone movement because participants could let the grid zoomed in and do only pans and drag'n'drop with items to complete the task without many virtual zoom nor physical zoom.

\figureETS[0.8]{navigation_time}{
  The total time (per trial) spent with an item selected, or panning, or zooming. Note that these times could overlap.
}

\subsection{Évaluations des participants}
\label{subsec:experiment_results_evaluations}

A Kruskal-Wallis test (Benjamini–Hochberg correction) on each criterion checked for significant differences due to \variable{TECHNIQUE}. Five of the criteria were significantly affected by \variable{TECHNIQUE}: Easy to Understand ($p<0.01$), Mentally Easy to Use ($p<0.01$), Subjective Speed ($p<0.05$), Subjective Performance ($p<0.01$), and overall Preference ($p<0.01$), whereas Physically Easy to Use and Frustration were not significantly affected.

We then used pairwise Mann-Whitney test (with Benjamini–Hochberg correction) for the appropriate criteria, finding the following:
\begin{itemize}
 \item Easy to Understand: \condition{Téléphone} is significantly better than \condition{VESAD} ($p<0.01$). This is not surprising, since the conditionvariable{Téléphone} technique is more familiar to users.
 \item Mentally Easy to Use: \condition{Téléphone} is significantly worse than \condition{VESAD tactile} ($p<0.01$) and \condition{VESAD} ($p<0.05$). This may be due to the limited screen size of the phone.
 \item Subjective Speed: \condition{VESAD tactile} was judged to be significantly faster than \condition{VESAD} ($p=0.05$). This may be due to the precision of the touch gestures and the extended view of the VESAD (so the gestures are more important that the size of the view, because it's not better that the PhoneOnly.
 \item Subjective Performance: \condition{VESAD tactile} is significantly better than \condition{Téléphone} ($p<0.01$) and \condition{VESAD} ($p<0.01$).
 \item Overall Preference: \condition{VESAD tactile} is significantly preferred over \condition{Téléphone} ($p<0.005$) and over \condition{VESAD} ($p<0.05$). 
\end{itemize}

\figureETS[0.9]{ranks_distributions}{
  Distributions des notes données par les participants à chaque technique. Une note élevée est meilleure ($5$ correspond à une faible frustration).
}

\figureETS[0.9]{ranks}{
  Notes moyennes des participants à chaque technique (les barres d'erreurs montrent l'intervalle de confiance à 95\%).
}

\figureETS[0.6]{preferences}{
  Distribution du classement donné par chaque participants aux techniques.
}

Users were also asked their opinion on various concept applications for VESADs. More than half the participants thought the extended map application \figrefp{HandheldVESADMap} would be useful, and all of them thought the multi-tasking support \figrefp{HandheldVESADApp} would be valuable.
%gave also their opinions about the following applications of the VESAD: an app with an extended view like a map (\autoref{fig:map}); multiple screens around the phone  (\autoref{fig:apps}); and notifications on top of the phone. Participants found in majority that the map app could benefit from the extended view. All of them said that the multiple screens could be very interesting, especially for multi-tasking. %But almost none of them found the notifications concept useful. Michael says: they were not shown the latest version of this.
