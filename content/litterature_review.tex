\section*{Introduction}
Après quelques années de développement, nous pensons que le marché de la réalité virtuelle (RV) est amené à exploser dans l'année 2016, avec la sortie des versions publiques des visiocasques Oculus Rift et HTC Vive. En outre, Microsoft, l'une des plus grandes entreprises en technologies de l'information, s'est lancée dans la conception d'un casque de réalité augmentée (RA), le HoloLens, dont il livrera une première version destinée aux développeurs dans le courant de cette même année 2016, remettant ainsi sur scène la RA dans la suite de l'expérimentation, en 2013, des lunettes de RA Google Glass. Dans un rapport de janvier 2016, Goldman Sachs Research estime que les marchés de la RV et de la RA pèseront, ensemble, entre 23 milliards et 80 milliards de dollars de revenus par an d'ici 2025 \citep{BelliniChenSugiyamaEtAl2016}. De plus, malgré son retard technologique sur la RV, la RA semble promise à un meilleur avenir. \citep{BelliniChenSugiyamaEtAl2016} En effet, si la RV immerge totalement l'utilisateur dans un environnement virtuel, la RA introduit des éléments virtuels dans l'environnement réel. Ainsi, la RA peut émuler la RV, et permet de construire des interfaces humain-machines (IHM) autour d'un utilisateur dans sa vie quotidienne et augmenter les interactions possibles qu'il peut avoir avec son environnement.

L'émergence de la RA nous permet de rêver à la réalisation d'IHM qui n'étaient encore présentent que dans les imaginaires. On peut citer par exemple les IHM vues dans les films Minority Report \reffig{Spielberg2002-Hologram} ou ceux de la trilogie The Matrix \reffig{WachowskiSilver2003-ZionUI}. Si ces exemples montrent des IHM fixées à des bureaux de travail, les lunettes de RA Google Glass ont montré que les interactions en RA avec un téléphone intelligent étaient prometteuses. Les téléphones intelligents et tablettes étant massivement répandus depuis ces dernières années, et la future révolution promise des lunettes de RA nous fait imaginer des interactions conjointes à explorer entre ces appareils mobiles et ces lunettes. Nous souhaitons savoir dans quelle mesure la RA pourrait augmenter les interactions possibles avec un téléphone intelligent ?

\figureETS{figures/Spielberg2002-Hologram.png}{IHM de l'hologramme du film \foreignlanguage{english}{Minority Report}.\\ Tiré de \citet{Spielberg2002}}{Spielberg2002-Hologram}

\figureETS{figures/WachowskiSilver2003-ZionUI.jpg}{IHM d'une tour de contrôle du film \foreignlanguage{english}{The Matrix Reloaded}.\\ Tiré de \citet{WachowskiSilver2003}}{WachowskiSilver2003-ZionUI}

La RA peut toucher tous les sens humains, cependant, elle est souvent désignée par ce terme comme s'adressant au sens visuel. C'est sous cette signification qu'elle sera aussi employée dans cette revue de littérature. En outre, nous nous intéressons ici à la conception d'IHM pour la RA~: les considérations techniques ne seront pas abordées directement, ni les problématiques d'acceptation sociale de la RA. Les problématiques de travail collaboratif ne seront pas non plus abordées.

Cette revue de littérature s'organisera en plusieurs sections allant du plus général au plus spécifique, partant d'une définition du contexte du sujet et aboutissant aux questions de recherche que nous pensons nécessaire d'explorer pour répondre au problème énoncé plus haut dans cette introduction. La première partie donnera le contexte du sujet, en définissant la RA et en dressant son historique. La seconde partie explora les recherches réalisées dans la conception d'IHM pour des RA mobiles et portable et décrira les futurs travaux nécessaires.



\section*{Définitions}
\subsection*{Définition de la réalité augmentée}
La réalité augmentée (RA) est, selon l'Office québécois de la langue française, une «~technique d'imagerie numérique […] permettant, grâce à un dispositif d'affichage transparent, de superposer à une image réelle des informations provenant d'une source numérique~» \citep{OfficeQuebecoisLangueFrancaiseRA2015}. La RA consiste donc à combiner du contenu virtuel, généré par un système informatique, à l'environnement réel d'un utilisateur, et cela en temps réel. Ainsi la RA permet d'\emph{augmenter la perception} du réel par les sens humains et permet d'\emph{augmenter les interactions} possibles d'un utilisateur avec l'environnement. \citep{Azuma1997}


\subsection*{Les techniques de réalité augmentée}
% TODO~: est-ce à la bonne place ? Faire plus de contenu pour faire le point pas seulement en output, mais aussi en input ? Relire \cite{BimberRaskar2005}
Il existe aujourd'hui plusieurs techniques de RA, classées en trois catégories \reffig{BimberRaskar2005-Figure31}. La catégorie dominant actuellement le marché est celle des visiocasques (en anglais~: \foreignlanguage{english}{Head-Mounted Display} ou foreignlanguage{english}{Head-Worn Display}) \citep{VanKrevelenPoelman2010}~: on le voit par la présence médiatique des visiocasques grand public récents tels que l'Oculus Rift, le HTC Vive ou le Microsoft HoloLens. Les techniques de cette catégorie consistent à placer un casque devant les yeux de l'utilisateur pour y diffuser la RA. Un premier type de ces techniques, dites \foreignlanguage{english}{video see-through}, vont remplacer l'environnement visible par une image filmée et augmentée de cet environnement. Cela va se faire en utilisant des caméras à l'avant du casque, en modifiant les images filmées, pour les renvoyer à l'écran du casque. Un second type de ces techniques, dites \foreignlanguage{english}{optical see-through}, vont laisser voir à l'utilisateur directement l'environnement, et, par un jeu de miroirs et de lentilles, vont y superposer les images de RA.

\figureETS{figures/BimberRaskar2005-Figure31.png}{Catégories des techniques d'affichages de RA.\\ Tiré de \citet[p. 72]{BimberRaskar2005}}{BimberRaskar2005-Figure31}

Seule la catégorie des visiocasques sera explorée dans cette revue de littérature. Elle est en effet celle qui est la plus utilisée en recherche actuellement et est la plus prometteuse pour réaliser de la RA utilisable au quotidien. \cite{CarmignianiFurhtAnisettiEtAl2011} De plus, des visiocasques sous forme de lentilles de contacts sont en développement et pourraient devenir la future technique de RA dominant le marché par la discrétion et la légèreté qu'elles permettent. \citep{VanKrevelenPoelman2010}



\section*{Historique de la réalité augmentée}
\paragraph*{Les débuts du domaine de recherche}
% TODO~: améliorer le contenu avec \cite{Chalon2004}
Le domaine de recherche de la RA débute dans les années 60, mais se développe lentement durant les décennies suivantes. C'est \citet{Sutherland1968} qui développa le premier prototype de RA~: ce visiocasque permettait déjà de visualiser du contenu virtuel en 3D, affiché à l'utilisateur du visiocasque selon sa perspective visible depuis la position de sa tête, lui donnant ainsi l'illusion d'un contenu virtuel réellement présent dans l'espace. La recherche se développe par la suite lentement dans les décennies suivantes \citep{VanKrevelenPoelman2010} \citep{CarmignianiFurhtAnisettiEtAl2011}.

\paragraph*{L'établissement du domaine de recherche}
C'est dans les années 90 où la RA devient un domaine de recherche à part entière. Cela se voit tout d'abord par la création de plusieurs conférences dédiées, réunies aujourd'hui sous le nom de International Symposium on Mixed and Augmented Reality (ISMAR), une conférence désormais majeure pour la recherche et l'industrie \citep{AzumaBaillotBehringerEtAl2001}.

En outre, \citet{MilgramKishino1994} réalisent une clarification des concepts du domaine, encore en usage aujourd'hui, en proposant une échelle ordonnée nommée \foreignlanguage{english}{Reality-Virtuality Continuum} \reffig{MilgramKishino1994-Figure1}, sur laquelle sont opposés deux extremums~: les environnements réels et les environnements de réalité virtuelle (RV). Un environnement de RV est alors entendu comme immergeant totalement l'utilisateur dans un monde virtuel. Ainsi, tout environnement mélangeant à la fois des éléments réels et virtuels, tel que la RA, se situe donc entre ces deux extremums est nommé, de façon générale, réalité mixte (RM) \citep{MilgramKishino1994}.

Enfin, \citet{Azuma1997} propose une première définition formelle de la RA~: il indique qu'un environnement RA doit 
\begin{enumerate*}[label=\emph{\arabic*})]
	\item combiner des éléments réels et virtuels
	\item être interactif en temps réel
	\item les éléments virtuels et réels doivent être alignés dans l'environnement
\end{enumerate*}. 
\citeauthor{Azuma1997} réalise dans ce même article le premier état de l'art du domaine en détaillant les avancées de la RA et en analysant les défis à relever. Il relève en particulier que peu de prototypes de RA ont pu maturer jusqu'à un stade commercialisable, les raisons étant principalement d'ordre technologiques~: les capteurs ne sont pas assez précis pour aligner les éléments réels et virtuels, et le temps réel est difficilement atteignable par le manque de puissance des face aux calculs nécessaires.

\figureETS{figures/MilgramKishino1994-Figure1.png}{L'échelle \foreignlanguage{english}{Reality-Virtuality Continuum} de Milgram.\\ Tiré de \citet[p. 3]{MilgramKishino1994}}{MilgramKishino1994-Figure1}

\paragraph*{Développement du domaine de recherche vers des réalités augmentées mobiles et portables}
À partir des années 2000, avec la révolution des téléphones intelligents, le RA est amenée à devenir mobile et portable pour pouvoir s'émanciper des simples prototypes des laboratoires. Tout d'abord, dans un second état de l'art complétant le premier, le domaine s'étant développé rapidement depuis 1997, \citet{AzumaBaillotBehringerEtAl2001} notent que les progrès techniques sur les capteurs et sur les capacités de calculs permet désormais de concevoir des RA mobiles. Cela pouvait se réaliser, par exemple, des PC portables embarqués avec les capteurs dans un sac à dos~: mais ce genre d'équipement était lourd et encombrant. \citep{DeSaChurchill2013}

Pour réaliser de telles RA mobiles, il a alors été intéressant d'utiliser les téléphones intelligents. En effet, leur puissance, leur légèreté, ainsi que leurs capacités ont explosés et ils ont permis de concevoir des capteurs bons marchés et efficaces~: les téléphones intelligents peuvent donc être utilisés pour créer des systèmes RA léger et facilement portable par un utilisateur. \citep{ZhouDuhBillinghurst2008} \citep{DeSaChurchill2013} Pour \citet{VanKrevelenPoelman2010}, l'un des plus grands potentiels de la RA pourrait être dans sous une forme mobile. En effet, la RA pourrait être ainsi utilisée de manière transparente, naturelle et légère. En outre, \citet{CarmignianiFurhtAnisettiEtAl2011} constatent dans leur état de l'art de la RA, qu'entre les années 2002 et 2010, de plus en plus de prototypes de RA sont réalisés sur des systèmes mobiles, car c'est sous cette forme que la RA a le plus de chance de réussir auprès du grand public. Enfin, dans un état de l'art récent plus spécifique à la RA mobile, \citet{HuangHuiPeyloEtAl2013} concluent que malgré les challenges techniques encore non résolus de performances, de coûts, d'efficacité énergétique ou de poids, la RA mobile a déjà montré qu'elle fonctionne et qu'elle peut devenir, pour ses utilisateurs, un moyen important d’interaction avec leur environnement. Ainsi, si la recherche dans la RA s'est beaucoup développée depuis 25 ans, elle s'est surtout consacrée à la résolution de problèmes techniques dans le but de la rendre possible.



\section*{Conception d'interfaces humain-machine pour une réalité augmentée mobile, portable et spatiale}
\subsection*{La recherche en interfaces humain-machine pour la réalité augmentée}
Si la RA est techniquement réalisable sur des appareils mobiles, elle n'est pas encore mature dans les IHMs qu'elle utilise. \citet{ZhouDuhBillinghurst2008} et \citet{DeSaChurchill2013} indiquent que trop peu de travaux ont été consacrés aux IHM et à l'expérience utilisateur en RA. C'est un challenge pourtant important, et cela reste un problème ouvert, car \citet{VanKrevelenPoelman2010} rappelle qu'aucun paradigme d'IHM fonctionnant bien n'a encore été trouvé pour la RA. En effet, la métaphore du bureau WIMP (pour \foreignlanguage{english}{windows}, \foreignlanguage{english}{icons}, \foreignlanguage{english}{menus} et \foreignlanguage{english}{pointing device}) utilisé par les IHMs des systèmes d'exploitations des ordinateurs ne fonctionne pas en RA, tout comme les dispositifs d'entrées en 2D tels que la souris~: ils fonctionnent sous la contrainte d'un plan 2D et restreignent alors l'expérience de la RA. \citep{VanKrevelenPoelman2010} A l'inverse, les dispositifs d'interactions dit naturels, sans aucune contraintes dans l'espace, c'est-à-dire avec six degrés de libertés (6 DoF), sont, en réalité, difficiles à manipuler avec dans un environnement virtuel. \citet{ChanKaoChenEtAl2010} ont en particulier montré que sans retour tactile il est difficile d'estimer la profondeur. Un paradigme différent, approprié pour la RA, est donc à déterminer.

Plusieurs types d'IHM pour la RA sont à explorer comme futures pistes de recherches. \citet{AzumaBaillotBehringerEtAl2001} en suggèrent deux~; premièrement, ils proposent d'utiliser conjointement plusieurs dispositifs d'entrée ou de sortie pour exploiter les avantages de chacun d'entre eux~: ainsi, il est possible pour l'utilisateur d'interagir selon la tache avec le(s) dispositif(s) présentant la meilleure interaction. Ce sont des \emph{IHM hybrides}. \citep{ZhouDuhBillinghurst2008}  Cette idée rejoint celle des \emph{IHMs multimodales}, développée par \citet{Oviatt2003} qui propose de créer des systèmes réagissant à plusieurs modes d'entrées différents de l'utilisateur qui peut agir par la voix, le doigt, les yeux, avec un stylet, par des mouvements de main ou du corps. Chaque mode peut alors être utilisé en fonction de la tache, ou du contexte de manière flexible. \citep{CarmignianiFurhtAnisettiEtAl2011} Deuxièmement, \citet{AzumaBaillotBehringerEtAl2001} proposent d'utiliser les outils et objets de l'environnement réel pour interagir avec l'environnement virtuel, permettant ainsi de créer des \emph{IHMs tangibles} (en anglais~: \foreignlanguage{english}{Tangible User Interfaces (TUIs)}). Les objets physiques ont l'avantage d'êtres familiers, facile à utiliser et de présenter des contraintes physiques sur lesquelles l'IHM peut s'appuyer \citep{ZhouDuhBillinghurst2008}. Cependant, \citeauthor{ZhouDuhBillinghurst2008} soulignent que leur utilisation pose le défi de faire comprendre à l'utilisateur les actions possibles et les conséquences de ses actions. 


\subsection*{Le problème de recherche~: l'utilisation conjointe des visiocasques et des téléphones intelligents pour la conception d'une interface humain-machine pour une réalité augmentée mobile, portable et spatiale}
L'utilisation de téléphones intelligents pour la RA présente des inconvénients importants \footnote{Cela peut être un facteur expliquant entre autres, la, encore, faible adoption de la RA par le grand public.} pour une bonne utilisabilité au quotidien. On peut noter que leurs écrans sont petits \citep{DeSaChurchill2013} et que le téléphone doit être tenu à bout de bras à la hauteur des yeux pour que la caméra puisse être alignée avec le regard de l'utilisateur, ce qui peut se révéler fatiguant pour l'utilisateur et donc limiter l'usage du système de RA \citep{Hincapie-RamosGuoMoghadasianEtAl2014}. Ce type de système n'est donc pas viable pour une utilisation quotidienne.

Une alternative pourrait se trouver dans l'utilisation de visiocasques pour réaliser une expérience de RA mobile, portable, légère et transparente pour l'utilisateur. \citet{KoelleKranzMoeller2015} rappellent que l'expérimentation de Google Glass a permis de montrer, malgré les problèmes de vie privée et d'acceptation sociale qu'elle a posée, qu'il était intéressant de combiner un visiocasque avec un téléphone intelligent~: le système proposait à l'utilisateur d'interagir avec son téléphone via le visiocasque par des interactions multimodales à la voix ou avec des gestes en l'air lus et décodés par la caméra du visiocasque. Ainsi, pour \citet{HuangHuiPeyloEtAl2013} l'avenir de la RA mobile se trouve dans l'utilisation de visiocasques de ce type. De manière générale, \citet{SerranoEnsYangEtAl2015} soulignent que les visiocasques ont les avantages par rapport aux téléphones intelligents de pouvoir laisser les mains libres et de pouvoir présenter en permanence de l'information aux yeux de l'utilisateur. Pour réaliser un visiocasque portable, les technologies des téléphones mobiles pourraient y être transférées et utilisées pour lui permettre de créer l'expérience de RA en autonomie.

S'ils sont techniquement réalisables, les possibilités des visiocasques ne sont pas pleinement exploitées. Une limite du Google Glass est que son IHM est affichée seulement sur un plan virtuel à une distance fixe des yeux. Ce n'est alors pas totalement de la RA au sens de \citet{AzumaBaillotBehringerEtAl2001}, car les éléments virtuels ne sont pas alignés avec les éléments réels. De plus, \citet{SerranoEnsYangEtAl2015} rappellent que ce plan peut faire occlusion avec l'environnement réel, et gêner la vue de l'utilisateur. En outre, les mains étant libres d'utiliser un autre système tel qu'un ordinateur de bureau ou téléphone intelligent, \citet{SerranoEnsYangEtAl2015b} proposent de faire travailler en synergie le système de RA du visiocasque avec les autres systèmes informatiques de l'utilisateur. Les téléphones intelligents étant actuellement très répandus, et les IHMs pour la RA n'étant pas encore matures, la RA mobile ne va probablement pas remplacer les téléphones intelligents dans les prochaines années. Le téléphone étant tangible, il serait alors intéressant de mettre à profit un visiocasque pour augmenter l'écran du téléphone en RA avec du contenu virtuel et augmenter les interactions possibles avec le téléphone et le contenu virtuel de la RA.


\subsection*{Travaux reliés}
\subsubsection*{Interfaces humain-machine multi-affichages}
%\paragraph*{}
%L'origine de ces IHMs se trouve dans un article de \citet{FeinerMacIntyreHauptEtAl1993}, où il réalise le premier prototype associant le contenu virtuel, dans ce cas des fenêtres 2D, à des objets réels. Ainsi
% 0 c'est du design spatial~: expliquer en donnant l'origine~: ancêtre de ce que l'on veut faire, accroche des fenêtres virtuelles aux objets \cite{FeinerMacIntyreHauptEtAl1993}

\paragraph*{}
\citet{EnsFinneganIrani2014} partent de ce même constat sur les IHMs des visiocasques actuels. Pourtant un visiocasque peut afficher du contenu en 3D dans l'environnement, et permettrait d'exploiter l'espace de la vision périphérique de l'utilisateur. Ainsi, plusieurs fenêtres pourraient être affichées en même temps à des endroits différents dans l'espace de la vision d'un utilisateur.\\
Pour explorer les capacités des visiocasques, \citeauthor{EnsFinneganIrani2014} réalisent un prototype de RA affichant de multiples fenêtres dans les airs \reffig{EnsFinneganIrani2014-Figure8}. Un utilisateur peut alors interagir directement avec les fenêtres par le toucher~; c'est une \emph{interaction directe}. Ils explorent alors plusieurs facteurs de conception du prototype, au travers de quatre expériences~: la taille d'affichage des fenêtres virtuelles, leur distance d'affichage, leur angle de placement par rapport à l'utilisateur, et enfin leur référentiel de placement (fixées au corps ou fixées au monde). Les performances (temps et taux d'erreurs), la fatigue ainsi que les retours des utilisateurs étaient mesurés.\\ 
Leurs résultats ont montré, entre autres, qu'un affichage courbe est important pour que toutes les fenêtres soient à la même distance de l'utilisateur, confirmant les résultats de \citet{ShuppBallYostEtAl2006} pour les affichages virtuels. En outre, leur conception a montré qu'elle permettait un travail 40\% plus rapide qu'avec une fenêtre simple sur une tache multi-applications~: en effet, leur prototype permettant d'afficher plusieurs fenêtres simultanément et \citeauthor{EnsFinneganIrani2014} ont pu réduire le changement d'application à un simple mouvement de tête pour changer de fenêtre. Ce résultat montre également que l'interaction directe est compatible avec du contenu virtuel sous forme de fenêtres. Enfin, le référentiel sur le corps avait de plus grands taux d'erreurs que le référentiel sur le monde, car l'action de sélection entraînait des perturbations involontaires des fenêtres par rapport à l'utilisateur.\\ 
Ce travail présente cependant quelques limites. Tout d'abord, leur IHM requiert des interactions directes, ce qui est à l'origine d'erreurs de sélection et de fatigue du bras~; il serait alors intéressant de savoir si un référentiel sur le corps permettrait d'être précis avec une interaction indirecte. En outre, le champ de vision était très limité~: de 30° à l'horizontal et 40° à la verticale, ce qui biaise les mesures de performances Enfin, le prototype a été réalisé dans un CAVE, c'est-à-dire des projections de l'image sur des écrans entourant l'utilisateur. Ainsi, il faudrait reproduire les expérimentations avec un visiocasque et différentes techniques d'interactions. On peut également se demander si l'utilisation de fenêtres est une représentation adaptée pour la RA, aucune contrainte d'écran n'étant présente, et si une meilleure représentation de l'information virtuelle dans l'espace existe.

\figureETS{figures/EnsFinneganIrani2014-Figure8.jpg}{Conception du \foreignlanguage{english}{Personal Cockpit}.\\ Tiré de \citet[p. 7]{EnsFinneganIrani2014}}{EnsFinneganIrani2014-Figure8}

\paragraph*{}
Dans un article plus récent, \cite{GrubertKranzQuigley2015} constatent qu'il devient commun d'avoir plusieurs appareils mobiles sur soi, tels que les téléphones intelligents, les tablettes ou les montres connectées. Cependant, ces appareils sont conçus pour être utilisés seuls et pas pour qu'un utilisateur puisse interagir en même temps sur leurs multiples affichages.\\
\citeauthor{GrubertKranzQuigley2015} proposent alors d'utiliser les visiocasques pour joindre les affichages et les interactions entre ces différents appareils~: les entrées et les sorties de tous les appareils sont liées \reffig{GrubertHeinischQuigleyEtAl2015}. Ainsi, ce travail prend la suite de celui de \citet{EnsFinneganIrani2014}, en situant les fenêtres virtuelles autour des affichages des appareils de l'utilisateur. L'objectif de leur système est de permettre des actions faciles et rapides dans les tâches qui impliquent de multiples appareils mobiles. Ils explorent alors dans cet article ce nouvel espace de conception créé et mènent des expérimentations auprès d'utilisateurs pour valider leurs propositions de conception par rapport aux appareils utilisés seuls.\\
Un résultat intéressant de leur exploration sont les degrés possibles de couplage des appareils. Dans le premier mode dit \emph{body-aligned}, le contenu virtuel a pour référence le corps de l'utilisateur, les appareils mobiles servant comme fenêtre haute résolution en pointant sur ce contenu~: la technique utilisée est \emph{overview+detail} (Voir \citep{BergeSerranoPerelmanEtAl2014}). Dans le second mode dit \emph{device-aligned}, le contenu a pour référence un appareil mobile, le visiocasque augmentant son écran avec un affichage virtuel~: le visiocasque étant de moins bonne résolution que l'appareil mobile, c'est une technique appelée \emph{focus+context} (Voir \cite{BaudischGoodStewart2001}). Enfin dans mode dit \emph{side-by-side}, les interactions entre les appareils se font sans lien spatial~: par exemple, l'utilisateur se sert du téléphone pour interagir indirectement avec des informations affichées par son visiocasque.\\
Leurs résultats expérimentaux montrent que l'augmentation des appareils en RA par un visiocasque peut permettre des temps plus rapides par rapport aux appareils seuls (visiocasque seul ou téléphone seul), dans les taches de navigation et de sélection, mais au détriment d'un plus grand effort perçu par les utilisateurs. Un second résultat expérimental important est que les préférences des utilisateurs sont variées entre utiliser les appareils seuls, coupler les entrées d'un appareil aux sorties de l'autre sans lien spatial, et coupler spatialement les appareils~: cela montre qu'il est important de proposer tout ce spectre pour que chaque utilisateur organise l'IHM selon ses préférences et selon le contexte.\\
Une limite importante de cet article sont de faibles résultats expérimentaux. En effet, le système testé était lourd, peu mobile, avait une grande latence (150 ms), un champ de vision limité~: ainsi, les résultats ont seulement permis de montrer que coupler les affichages des appareils \emph{pourrait} permettre de meilleures performances que les appareils utilisés seuls. En outre, le système n'a été pensé que pour certaines tâches précises, et non pour un couplage global et constant dans le temps. Il serait donc intéressant de généraliser le concept, et de le répliquer avec un visiocasque plus léger et mobile pour obtenir des résultats avec de meilleures validités internes (en évitant les problèmes techniques des expérimentations de l'article) et externes (plus de taches testés, conception pensée pour un couplage global et constant dans le temps).

\figureETS{figures/GrubertHeinischQuigleyEtAl2015.jpg}{Illustrations du fonctionnement de \foreignlanguage{english}{Multifi}.\\ Tiré de \citet{GrubertHeinischQuigleyEtAl2015}}{GrubertHeinischQuigleyEtAl2015}

\paragraph*{}
Dans un article suivant, \cite{SerranoEnsYangEtAl2015} généralisent le travail de conception réalisé avec MultiFi \citep{GrubertHeinischQuigleyEtAl2015}. Ils proposent pour cela Gluey~: une IHM qui utilise le visiocasque comme affichage pour unifier les entrées et sorties de tous les appareils, qu'ils soient mobiles ou de bureau. \citeauthor{SerranoEnsYangEtAl2015} s'appuient pour cela sur les propriétés de l'affichage permanent aux yeux de l'utilisateur du visiocasque et de sa connaissance de sa position dans les environnements réels et virtuels. Ainsi, c'est un médium idéal de transmission de l'information et de redirection des entrées entre les appareils \reffig{SerranoEnsYangEtAl2015a-Figure1}.
Un utilisateur peut donc interagir sur un appareil, et voir ses actions s'exécuter sur un autre appareil qu'il regarde. Il est intéressant que le système permette que n'importe quel appareil puisse être utilisé de manière transparente et flexible comme un dispositif d'entrée (souris, téléphone, tablette). Le système permet également de transmettre des données, par exemple pour copier des données ou les imprimer.\\
\citeauthor{SerranoEnsYangEtAl2015} présentent avec ce travail un ensemble de pistes de conception pour un tel système. Leur idée était de pouvoir créer des interactions invisibles entre les appareils, pour faciliter les taches demandant d'utiliser plusieurs appareils. Pour cela, l'IHM doit permettre de~: 
\begin{enumerate*}
	\item rediriger les entrées entre les appareils
	\item migrer du contenu entre les appareils
	\item tous les appareils doivent être compatibles
	\item d'enregistrer de nouveaux appareils
	\item de tenir un modèle spatial du système
	\item les retours du système doit toujours être visibles (ici par le visiocasque)
	\item le système doit être mobile
\end{enumerate*}. Ainsi, MultiFi \citep{GrubertHeinischQuigleyEtAl2015} ne satisfait qu'aux critères 1, 5, 6 et 7.\\
Une limite toutefois de l'article relève dans la faiblesse de son évaluation, informelle, qui a seulement pu montrer que le concept et la preuve de concept réalisée étaient enthousiasmantes et intéressantes aux yeux des participants. Une évaluation formelle devrait être reconduite avec un prototype léger et totalement mobile. Le visiocasque présentant en outre des limites de champs de vision et de résolution~: si ces caractéristiques vont s'améliorer dans le futur, nous pensons que leur impact sur la navigation et les performances des interactions des utilisateurs n'est pas encore bien connue.

\figureETS{figures/SerranoEnsYangEtAl2015a-Figure1.jpg}{Illustration du concept de \foreignlanguage{english}{Gluey}.\\ Tiré de \citet[p. 1]{SerranoEnsYangEtAl2015}}{SerranoEnsYangEtAl2015a-Figure1}

\paragraph*{}
\citet{SerranoEnsYangEtAl2015b} ont par la suite complété leur travail, en proposant Desktop-Gluey~: ce concept étend les possibilités de Gluey en permettant à l'utilisateur d'étendre les écrans physiques de ses appareils par des fenêtres virtuelles. Les fenêtres peuvent être arrangés dans l'espace autour des écrans physique par l'utilisateur. Le système autorise donc le travail collaboratif en permettant de partager des fenêtres virtuelles entre plusieurs utilisateurs \reffig{SerranoEnsYangEtAl2015-Figure2}. Enfin, les fenêtres peuvent suivre l'utilisateur dans ses déplacements et lui permettre d'interagir avec en utilisant son téléphone, une tablette ou des gestes de la main ou pour interagir, créant ainsi un concept de bureau mobile \reffig{SerranoEnsYangEtAl2015-Figure4}. La métaphore du bureau sur l'ordinateur personnel est donc reprise et augmentée à "partout" et en "tout temps"~: tout dispositif d'entrée peut être utilisé et tout dispositif d'entrée peut être augmenté dans son affichage.\\
Le concept recoupe celui de MultiFi \citep{GrubertHeinischQuigleyEtAl2015}, et le généralise des appareils mobiles seuls à tous les appareils visibles par l'utilisateur. Une autre différence majeure est que MultiFi a été conçu pour faciliter les taches demandant d'utiliser plusieurs appareils, alors que Desktop-Gluey propose de travailler avec ces fenêtres virtuelles~: on peut dire que c'est une application du Personal Cockpit \citep{EnsFinneganIrani2014} dans une IHM tangible et située autour d'appareils mobiles (comme MultiFi).\\
\citeauthor{SerranoEnsYangEtAl2015b} ne présentent dans cet article que le concept mais n'en réalise aucun prototype, ni aucune évaluation. Nous pensons qu'il serait intéressant de montrer que ce concept fonctionne et d'implémenter ce système de bureau virtuel et mobile, afin d'explorer son espace de conception et d'en ajuster au mieux les paramètres.

\figureETS{figures/SerranoEnsYangEtAl2015-Figure2.jpg}{Illustration de l'utilisation de fenêtres virtuelles pour étendre les écrans physiques dans le concept de \foreignlanguage{english}{Desktop-Gluey}.\\ Tiré de \citet[p. 3]{SerranoEnsYangEtAl2015b}}{SerranoEnsYangEtAl2015-Figure2}

\figureETS{figures/SerranoEnsYangEtAl2015-Figure4.jpg}{Illustration du concept de \foreignlanguage{english}{Desktop-Gluey} en mode mobile.\\ Tiré de \citet[p. 3]{SerranoEnsYangEtAl2015b}}{SerranoEnsYangEtAl2015-Figure4}


% mobile pour entrée, et hmd pour sortie \cite{LeeBudhirajaBillinghurst2013}


% pouvoir naviguer mieux dans les larges «information spaces» fov comparés \cite{RaedleJetterMuellerEtAl2014} (ici le sweet spot va converger vers le 130\textdegree de wide display et le design pour la périphérie ?)

% \paragraph*{}
% explorer tout ce qui lié à \"SideSight: Multi-“touch” Interaction Around Small Devices \"~: interactions avec petits écrans mais sans feedback -> nous ajoutons à ces recherches le feedback qui a la possibilité d'être permanent avec un HMD


\subsubsection*{Taille de l'affichage}
On l'a vu, une des principales problématiques des téléphones intelligent est leur petit écran. Cela peut grandement impacter les performances des utilisateurs quand il s'agit de naviguer dans de grands espaces de contenu, comme, par exemple, des données de navigation.

Une approche est d'avoir recourt à des techniques de visualisation pour montrer à l'utilisateur des indications de la localisation d'objets hors-écran. Une de ces techniques est Halo, conçue par \citet{BaudischRosenholtz2003}, qui propose pour chaque objet hors-écran de tracer un cercle prenant l'objet comme centre et avec un rayon assez grand pour qu'une portion de l'arc soit visible sur l'écran. Ainsi l'utilisateur a des indices pour déduire la direction et la distance de l'objet. Leurs expérimentations ont montré que cette technique permettait des temps 16\% à 33\% plus rapides, et sans augmentation du taux d'erreur, par rapport à une technique plus classique (\emph{scaled arrows}) indiquant par des flèches sur l'écran la distance et la direction des objets hors-écrans. Cette technique a ensuite été perfectionnée par \citet{GustafsonBaudischGutwinEtAl2008} dans une seconde version nommée Wedge, cette seconde version permettant aux utilisateurs d'être significativement plus rapides qu'avec la première version. Enfin, \citet{BurigatChittaro2011} ont réalisé un comparatif de cette technique avec les techniques \foreignlanguage{english}{scaled arrows} et \emph{overview+detail} \reffig{BurigatChittaro2011-Figure1}, cette dernière proposant une carte en miniature dans une vue sur un bord de l'écran montrant où regarde l'utilisateur sur cette carte. Les résultats de ce comparatif confirment que Wedge permet les temps les plus rapides quand les notions de distances sont importantes, mais indiquent que overview+detail est plus adapté quand les notions de structure de l'espace sont importantes, les auteurs concluant que toutes les techniques de visualisation ayant un impact positif sur les performances. Ainsi, il serait intéressant de savoir si un écran d'un appareil mobile augmenté de contenu virtuel permettrait de réaliser de meilleures performances par rapport à l'écran seul utilisé avec ces techniques.

\figureETS{figures/BurigatChittaro2011-Figure1.jpg}{Les trois techniques de visualisation pour les éléments hors écran~: (a) \foreignlanguage{english}{scaled arrows} (b) Wedge (c) overview+detail\\Tiré de \citet[p. 158]{BurigatChittaro2011}}{BurigatChittaro2011-Figure1}

%Cette problématique a également touché les ordinateurs personnels dans les années 2000 quand leurs affichages n'étaient pas très grands (les écrans 15 et 17 pouces étaient courants) ni de très grande résolution. 
%les problématiques du mobile actuellement~: petit écran face à grand contenu = incapacité à gérer de grandes infos 
%+ overview+detail \cite{BergeSerranoPerelmanEtAl2014} et \cite{RashidNacentaQuigley2012}
%concevoir pour la périphérie (focus+context \cite{CockburnKarlsonBederson2009}
%+ illuniroom \cite{JonesBenkoOfekEtAl2013}) 
%avec wedge/halo \cite{BaudischRosenholtz2003} \cite{GustafsonBaudischGutwinEtAl2008} \cite{BurigatChittaro2011} 
%+ potentiel d'augmenter la taille l'affichage avec les travaux comparant le desktop aux murs \cite{LiuChapuisBeaudouin-LafonEtAl2014} \cite{ShuppBallYostEtAl2006} \cite{TanGergleScupelliEtAl2003}


%\subsubsection*{Multi-taches et changement de contexte}
%concernant le multi-tache, c'est une problématique des systèmes RA (\cite{SchmalstiegFuhrmannHesinaEtAl2002} et background de \cite{EnsFinneganIrani2014})~: donc c'est naturel de lier le portable à la RA (TODO trouver un article le disant), surtout si on suit le \"information spaces\" de \cite{EnsHincapie-RamosIrani2014}
%\cite{TanCzerwinski2003}
%\cite{RashidNacentaQuigley2012a}


%\subsubsection*{Interactions multimodales}
%problématique du multimodal : quelle interaction pour quelle tache ?


%\subsubsection*{Synchronisation des environnements réels et virtuels}
%problématique de désynchronisation réel/virtuel peut être comblé avec cette RA mobile~: \cite{Chalon2004} et Gluey qui fait des photos du réels pour les coller sur l'écran


\subsection*{Questions de recherche}
Dès lors, on peut se poser un certains nombre de questions de recherche pour concevoir un tel système combinant un visiocasque avec un téléphone intelligent pour augmenter l'écran physique et les interactions possibles avec le téléphone~:
\begin{enumerate}
	\item Quelles interactions sont les meilleures pour quelles taches ?
	\item Pour quelles taches un utilisateur profiterait-il d'un écran augmenté ? Pour quelles taches un utilisateur profiterait-il de multiples écran organisables dans l'espace du téléphone ?
	\item Quels sont les paramètres de conception d'un tel système et pour quelles valeurs permettent-ils de le rendre le plus utilisable et le plus intéressant ? Est-ce qu'un tel système serait plus performant qu'un écran seul ?
	\item Le téléphone intelligent devrait-il servir comme une fenêtre haute-résolution sur le contenu virtuel (overview+detail), ou serait-il mieux de concevoir l'environnement virtuel comme une extension de l'écran du téléphone (focus+context), et pour quelles taches et quelles interactions ? Dans le second cas, est-ce que les objets virtuels doivent être conçus seulement pour la périphérie du regard ou pourraient-ils être des espaces de travail pour l'utilisateur (zones de focus potentiel de l'utilisateur) ?
	\item Quels sont les impacts de la taille des champs de vision (en anglais~: FoV) et de la résolution d'affichage du visiocasque sur la navigation et les interactions de l'utilisateur du système ? Peuvent-ils être négligés avec le matériel présent aujourd'hui, et qui s'améliorera dans le futur ? Il y a-t-il des valeurs minimum à respecter pour obtenir des résultats valides ? À mesure que le matériel va s'améliorer, est-il qu'un impact négatif existe passé un trop large champs de vision ou une trop haute résolution ?
	\item Les objets virtuels devraient-ils être simplement des fenêtres 2D dans l'espace, ou peut-on leur donner une profondeur (3D) tout en gardant de bonnes performances d'utilisation ? De manière plus générale, quelle est la meilleur ergonomie d'affichage et d'utilisation d'informations virtuelles dans un tel système RA ?
\end{enumerate}

Nous pensons concevoir et réaliser un prototype pour explorer ces questions et ces dimensions de conception, et l'évaluer auprès d'utilisateurs à travers plusieurs expérimentations pour pouvoir réaliser un ensemble de recommandations pour de futurs travaux suivant le concept.



%\section*{Facteurs de conception}
%« However, to date, what is not well understood is which factors inhibit or support the interaction across multiple displays on and around the body i.e. “body proximate” dis-plays. Within this paper we review four key design and tech-nological challenges inherent in body proximate displayecosystems, i.e. combinations of wearable displays (e.g.,smartwatches and smartglasses) and handheld devices(e.g., tablets and smartphones). » \cite{GrubertKranzQuigley2015} 
%TODO~: réviser l'article comme point de départ de cette section + les design factors de Personal Cockpit

%Conception (interfaces, interactions) importants et surtout les non-explorés encore = les sous-problèmes
        %FoV (Czerwinski, 2002) (Patterson, 2006) \cite{KishishitaKiyokawaOrloskyEtAl2014} 

        %Resolution

        %Reference frame for virtual content 
            %World-fixed \cite{EnsFinneganIrani2014} 
            %Body-fixed \cite{EnsFinneganIrani2014} 
                %Head centered vs dominant hand centered 
            %Head-fixed \cite{EnsFinneganIrani2014} 
            %Phone-fixed
            %Movability \cite{EnsHincapie-RamosIrani2014}
            %Spatial consistent interface \cite{LiDearmanTruong2009}

        %Context switching 
            %Number of displays \cite{RashidNacentaQuigley2012} \cite{CauchardLoechtefeldFraserEtAl2012}
            %Design of context vs design with large one app display \cite{BallNorth2008}

        %Content display
            %Size of virtual elements = angular width \cite{ShuppBallYostEtAl2006} \cite{BallNorth2008}
            %Distance of virtual content (Hezel, 1994) (Ankrum, 1999) (Tan, 2003) \cite{ChanKaoChenEtAl2010} \cite{EnsFinneganIrani2014} 
            %Angular separation (Mayer, 1993) \cite{EnsFinneganIrani2014} \cite{KishishitaKiyokawaOrloskyEtAl2014} (Alger, 2015) 
            %Curved layout vs flat layout \cite{ShuppBallYostEtAl2006} 
            %Direction of content (top, bottom, left, right) \cite{EnsFinneganIrani2014} 
            %Display continuity \cite{TanCzerwinski2003} \cite{RashidNacentaQuigley2012}
            %Allocatin space for new elements \cite{BellFeiner2000}

        %Content interactions
        	%Reprendre \cite{Bernatchez2008} et \cite{JankowskiHachet2013}
        	%Technique (interactions spatiales)
	        	%Indirect (\cite{TeatherStuerzlinger2011}) vs direct (revoir ethereal planes)
	            %Mid-hair hand \cite{EnsFinneganIrani2014} \cite{ChanKaoChenEtAl2010} \cite{JonesSodhiForsythEtAl2012}
	            %Gaze + taffi 
	            %Only touch on phone 
	            %Gaze + touch on phone

	        %Tangibilité


        %Evaluating virtual multi-display vs real multi-display 

        %Technique 
            %2D vs 3D virtual content \cite{JansenDragicevicFekete2013} \cite{SerranoHildebrandtSubramanianEtAl2014}
            %Same appareance for a same content accross outputs vs different appareance according to the output \cite{GrubertHeinischQuigleyEtAl2015} 



%\section*{Évaluation d'une réalité augmentée}
%Comment évaluer ? Taches de tests, et taches plus écologiques (proches des usages réels du quotidien) \cite{DuenserGrassetBillinghurst2008} \cite{DeSaChurchill2013}
    %Type
        %Visualisation 
        %Navigation \cite{EnsFinneganIrani2014} (Raschid, 2012) 
        %Selection \cite{EnsFinneganIrani2014}
        %Tri \cite{RobertsonCzerwinskiLarsonEtAl1998}
        %Multitasking 
            %Start, Question, My contacts, Calendar, Map (Cauchar, 2012) \cite{EnsFinneganIrani2014} 
    %Difficulty

    %taches ecologiques en réel avec toutes les problématiques que ça ouvre \cite{KoelleKranzMoeller2015} \cite{DenningDehlawiKohno2014}



%\section*{Synthèse}
