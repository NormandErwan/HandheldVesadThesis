\section*{Introduction}
Après quelques années de développement, nous pensons que le marché de la réalité virtuelle (RV) est amené à prendre de l'ampleur, dans l'année 2016, avec la sortie des versions publiques des visiocasques Oculus Rift et HTC Vive. En outre, Microsoft, l'une des plus grandes entreprises en technologies de l'information, s'est lancée dans la conception d'un casque de réalité augmentée (RA)~: le HoloLens, dont elle livrera une première version destinée aux développeurs dans le courant de cette même année 2016. Microsoft remet ainsi sur scène la RA, dans la suite de l'expérimentation, en 2013, des lunettes de RA Google Glass. En outre, dans un rapport de janvier 2016, Goldman Sachs Research estime que les marchés de la RV et de la RA pèseront, ensemble, entre 23 milliards et 80 milliards de dollars de revenus par an d'ici 2025 \citep{BelliniChenSugiyamaEtAl2016}. De plus, malgré son retard technologique sur la RV, la RA semble promise à un avenir meilleur \citep{BelliniChenSugiyamaEtAl2016}~: en effet, si la RV immerge totalement l'utilisateur dans un environnement virtuel, la RA introduit des éléments virtuels dans l'environnement réel. Ainsi, la RA peut émuler la RV, et, en permettant de construire des interfaces humain-machines (IHM) autour d'un utilisateur dans sa vie quotidienne, augmente les interactions possibles d'une personne avec son environnement.

L'émergence de la RA nous permet de rêver à la réalisation d'IHM qui n'étaient encore présentent que dans les imaginaires. On peut citer par exemple les IHM vues dans les films Minority Report \reffigureETS{Spielberg2002-Hologram} ou ceux de la trilogie The Matrix \reffigureETS{WachowskiSilver2003-ZionUI}. Si ces exemples montrent des IHM fixées à des bureaux de travail, les lunettes de RA Google Glass ont montré que les interactions en RA avec un téléphone intelligent étaient prometteuses. Les téléphones intelligents et tablettes étant massivement répandus depuis ces dernières années, et la future révolution promise des lunettes de RA nous fait imaginer des interactions conjointes à explorer entre ces appareils mobiles et des lunettes de RA. Ainsi, nous souhaitons savoir dans quelle mesure la RA pourrait augmenter les interactions possibles avec un téléphone intelligent ? Et dans quelle mesure ces interactions pourraient être pertinentes dans un usage quotidien ?

\figureETS{figures/Spielberg2002-Hologram.png}{IHM de l'hologramme du film \foreignlanguage{english}{Minority Report}.\\ Tiré de \citet{Spielberg2002}}{Spielberg2002-Hologram}

\figureETS{figures/WachowskiSilver2003-ZionUI.jpg}{IHM d'une tour de contrôle du film \foreignlanguage{english}{The Matrix Reloaded}.\\ Tiré de \citet{WachowskiSilver2003}}{WachowskiSilver2003-ZionUI}

La RA peut toucher tous les sens humains, cependant, elle est souvent désignée dans ce terme comme s'adressant au sens visuel. C'est sous cette signification qu'elle sera aussi employée dans cette revue de littérature. En outre, nous nous intéressons ici à la conception d'IHM pour la RA~: les considérations techniques ne seront pas abordées directement, ni les problématiques d'acceptation sociale de la RA. Les problématiques de travail collaboratif ne seront pas non plus abordées.

Cette revue de littérature s'organisera en plusieurs sections allant du plus général au plus spécifique, partant d'une définition du contexte du sujet et aboutissant aux questions de recherche que nous pensons nécessaire d'explorer pour répondre au problème énoncé plus haut dans cette introduction. La première partie donnera le contexte du sujet, en définissant la RA et en dressant son historique. La deuxième partie explora les recherches réalisées dans la conception d'IHM pour des RA mobiles et portable pour aboutir à un ensemble de question de recherches pour ce sujet. La troisième partie décrira les facteurs de conception les plus pertinents pour concevoir des solutions à ces question de recherche. Enfin, la quatrième partie explorera les différentes méthodes d'évaluation d'IHM et proposera quelques expérimentations permettant d'apporter une réponse aux questions de recherches énoncées plus tôt.



\section*{Définitions}
\subsection*{Définition de la réalité augmentée}
La réalité augmentée (RA) est, selon l'Office québécois de la langue française, une «~technique d'imagerie numérique […] permettant, grâce à un dispositif d'affichage transparent, de superposer à une image réelle des informations provenant d'une source numérique~» \citep{OfficeQuebecoisLangueFrancaiseRA2015}. La RA consiste donc à combiner du contenu virtuel, généré par un système informatique, à l'environnement réel d'un utilisateur, et cela en temps réel. Ainsi la RA permet d'\emph{augmenter la perception} du réel par les sens humains et permet d'\emph{augmenter les interactions} possibles d'un utilisateur avec l'environnement. \citep{Azuma1997}


\subsection*{Les techniques de réalité augmentée}
% TODO~: est-ce à la bonne place ? Faire plus de contenu pour faire le point pas seulement en output, mais aussi en input ? Relire \cite{BimberRaskar2005}

Il existe aujourd'hui plusieurs techniques de RA, classées en trois catégories \reffigureETS{BimberRaskar2005-Figure31}. La catégorie dominant actuellement le marché est celle des visiocasques (en anglais~: \foreignlanguage{english}{Head-Mounted Display} ou foreignlanguage{english}{Head-Worn Display}) \citep{VanKrevelenPoelman2010}~: on le voit par la présence médiatique des visiocasques grand public récents tels que l'Oculus Rift, le HTC Vive ou le Microsoft HoloLens. Les techniques de cette catégorie consistent à placer un casque devant les yeux de l'utilisateur pour y diffuser la RA. Un premier type de ces techniques, dites \foreignlanguage{english}{video see-through}, vont remplacer l'environnement visible par une image filmée et augmentée de cet environnement. Cela va se faire en utilisant des caméras à l'avant du casque, en modifiant les images filmées, pour les renvoyer à l'écran du casque. Un second type de ces techniques, dites \foreignlanguage{english}{optical see-through}, vont laisser voir à l'utilisateur directement l'environnement, et, par un jeu de miroirs et de lentilles, vont y superposer les images de RA.

\figureETS{figures/BimberRaskar2005-Figure31.png}{Catégories des techniques d'affichages de RA.\\ Tiré de \citet[p. 72]{BimberRaskar2005}}{BimberRaskar2005-Figure31}

Seule la catégorie des visiocasques sera explorée dans cette revue de littérature. Elle est en effet celle qui est la plus utilisée en recherche actuellement et est la plus prometteuse pour réaliser de la RA utilisable au quotidien. \cite{CarmignianiFurhtAnisettiEtAl2011} De plus, des visiocasques sous forme de lentilles de contacts sont en développement et pourraient devenir la future technique de RA dominant le marché par la discrétion et la légèreté qu'elles permettent. \citep{VanKrevelenPoelman2010}



\section*{Historique de la réalité augmentée}
\paragraph*{Les débuts du domaine de recherche}
% TODO~: améliorer le contenu avec \cite{Chalon2004}

Le domaine de recherche de la RA débute doucement dans les années 60. C'est \citet{Sutherland1968} qui développa le premier prototype de RA~: ce visiocasque permettait déjà de visualiser du contenu virtuel en 3D, affiché face à l'utilisateur du visiocasque selon sa perspective de l'espace virtuel donc depuis la position de sa tête, lui donnant ainsi l'illusion d'un contenu virtuel réellement présent dans l'espace. La recherche se développe cependant par la suite lentement dans les décennies suivantes \citep{VanKrevelenPoelman2010} \citep{CarmignianiFurhtAnisettiEtAl2011}.

\paragraph*{L'établissement du domaine de recherche}
C'est dans les années 90 où la RA devient un domaine de recherche à part entière. Cela se voit tout d'abord par la création de plusieurs conférences dédiées, réunies aujourd'hui sous le nom de International Symposium on Mixed and Augmented Reality (ISMAR), une conférence désormais majeure pour la recherche et l'industrie \citep{AzumaBaillotBehringerEtAl2001}.

En outre, \citet{MilgramKishino1994} réalisent une clarification des concepts du domaine, encore en usage aujourd'hui, en proposant une échelle ordonnée nommée \foreignlanguage{english}{Reality-Virtuality Continuum} \reffigureETS{MilgramKishino1994-Figure1}, sur laquelle sont opposés deux extremums~: les environnements réels et les environnements de réalité virtuelle (RV). Un environnement de RV est alors entendu comme immergeant totalement l'utilisateur dans un monde virtuel. Ainsi, tout environnement, tel que la RA, mélangeant à la fois des éléments réels et virtuels se situe donc entre ces deux extremums et est considéré comme de la réalité mixte (RM) \citep{MilgramKishino1994}.

Enfin, \citet{Azuma1997} propose une première définition formelle de la RA~: il indique qu'un environnement RA doit 
\begin{enumerate*}[label=\emph{\arabic*})]
	\item combiner des éléments réels et virtuels
	\item être interactif en temps réel
	\item les éléments virtuels et réels doivent être alignés dans l'environnement
\end{enumerate*}. 
\citeauthor{Azuma1997} réalise dans ce même article le premier état de l'art du domaine en détaillant les avancées de la RA et en analysant les défis à relever. Il relève en particulier que peu de prototypes de RA ont pu maturer jusqu'à un stade commercialisable, les raisons étant principalement d'ordre technologiques~: les capteurs ne sont pas assez précis pour aligner les éléments réels et virtuels, et le temps réel est difficilement atteignable par le manque de puissance des face aux calculs nécessaires.

\figureETS{figures/MilgramKishino1994-Figure1.png}{L'échelle \foreignlanguage{english}{Reality-Virtuality Continuum} de Milgram.\\ Tiré de \citet[p. 3]{MilgramKishino1994}}{MilgramKishino1994-Figure1}

\paragraph*{Développement du domaine de recherche vers des réalités augmentées mobiles et portables}
À partir des années 2000, avec la révolution des téléphones intelligents, le RA est amenée à devenir mobile et portable pour pouvoir s'émanciper des simples prototypes des laboratoires. Dans un second état de l'art complétant le premier, le domaine s'étant développé rapidement depuis 1997, \citet{AzumaBaillotBehringerEtAl2001} notent que les progrès techniques sur les capteurs et sur les capacités de calculs permet désormais de concevoir des RA mobiles. Cela pouvait se réaliser, par exemple, par un PC portable embarqué avec des capteurs dans un sac à dos. Cependant, ce genre d'équipement était présentait les inconvénient d'être lourd et encombrant. \citep{DeSaChurchill2013}

Pour réaliser de telles RA mobiles, il a alors été intéressant d'utiliser les téléphones intelligents. En effet, leur puissance, leur légèreté, ainsi que leurs capacités ont explosés et leur utilisation massive a permis de concevoir des capteurs bons marchés et efficaces~: les téléphones intelligents ont donc toutes les capacités pour pour créer des systèmes RA légers, et facilement portables par un utilisateur. \citep{ZhouDuhBillinghurst2008} \citep{DeSaChurchill2013} Pour \citet{VanKrevelenPoelman2010}, l'un des plus grands potentiels de la RA est sous une forme mobile. En effet, la RA pourrait être ainsi utilisée au quotidien de manière transparente, naturelle et légère. En outre, \citet{CarmignianiFurhtAnisettiEtAl2011} constatent dans leur état de l'art de la RA, qu'entre les années 2002 et 2010, de plus en plus de prototypes de RA sont réalisés sur des systèmes mobiles~: car, c'est sous cette forme que la RA a le plus de chance de réussir auprès du grand public. Enfin, dans un état de l'art récent plus spécifique à la RA mobile, \citet{HuangHuiPeyloEtAl2013} concluent que malgré les challenges techniques encore non résolus de performances, de coûts, d'efficacité énergétique, ou de poids, la RA mobile a déjà montré qu'elle fonctionne et qu'elle peut devenir, pour ses utilisateurs, un moyen important d’interaction avec leur environnement. Ainsi, si la recherche dans la RA s'est beaucoup développée depuis 25 ans, elle s'est surtout consacrée et se consacre toujours à la résolution de problèmes techniques dans le but de la rendre réalisable.



\section*{Conception d'interfaces humain-machine pour une réalité augmentée mobile, portable et spatiale}
\subsection*{La recherche en interfaces humain-machine pour la réalité augmentée}
Si la RA est techniquement réalisable sur des appareils mobiles, les IHM proposés pour son utilisation ne sont pas encore matures. \citet{ZhouDuhBillinghurst2008} et \citet{DeSaChurchill2013} indiquent que trop peu de travaux ont été consacrés aux IHM et à l'expérience utilisateur en RA. C'est un challenge pourtant important, et cela reste un problème ouvert, car \citet{VanKrevelenPoelman2010} rappellent qu'aucun paradigme d'IHM pertinent n'a encore été trouvé pour la RA. En effet, la métaphore du bureau WIMP (pour \foreignlanguage{english}{windows}, \foreignlanguage{english}{icons}, \foreignlanguage{english}{menus} et \foreignlanguage{english}{pointing device}) utilisé par les IHM des systèmes d'exploitations des ordinateurs ne fonctionne pas en RA, tout comme les dispositifs d'entrées en 2D tels que la souris~: ils sont fait pour fonctionner sous la contrainte d'un plan 2D et restreignent alors l'expérience de la RA. \citep{VanKrevelenPoelman2010} A l'inverse, les dispositifs d'interactions dit naturels, sans aucune contraintes dans l'espace, c'est-à-dire avec six degrés de libertés (6 DoF), sont, en réalité, difficiles à manipuler avec dans un environnement virtuel. \citet{ChanKaoChenEtAl2010} ont en particulier montré que sans retour tactile il est difficile pour une personne d'estimer sans erreur la profondeur. Un paradigme d'IHM différent et approprié pour la RA, est donc à déterminer.

Plusieurs types d'IHM pour la RA sont à explorer comme futures pistes de recherches. \citet{AzumaBaillotBehringerEtAl2001} en suggèrent deux~; premièrement, ils proposent d'utiliser conjointement plusieurs dispositifs d'entrée ou de sortie pour exploiter les avantages de chacun d'entre eux~: ainsi il est possible pour l'utilisateur d'interagir, selon la tache, avec le ou les dispositif(s) présentant la meilleure interaction~: ce sont des \emph{IHM hybrides}. \citep{ZhouDuhBillinghurst2008}  Cette idée rejoint celle des \emph{IHM multimodales}, développée par \citet{Oviatt2003}, qui propose de créer des systèmes réagissant à plusieurs modes d'entrées différents. Ainsi l'utilisateur peut agir sur le système par la voix, avec un ou des doigts, par des mouvements de main, avec les yeux, avec un stylet ou par des mouvements du corps. L'idée est que l'utilisateur peut choisir le mode d'entrée qu'il désire, ou en utiliser plusieurs à la fois. Chaque mode peut être ainsi utilisé en fonction de la tache, ou du contexte, et ce de manière totalement flexible. \citep{CarmignianiFurhtAnisettiEtAl2011} \\
Deuxièmement, \citet{AzumaBaillotBehringerEtAl2001} proposent d'utiliser les outils et objets de l'environnement réel pour interagir avec l'environnement virtuel, permettant ainsi de créer des \emph{IHM tangibles} (en anglais~: \foreignlanguage{english}{Tangible User Interfaces (TUIs)}). Les objets physiques ont l'avantage d'êtres familiers, facile à utiliser et de présenter des contraintes physiques sur lesquelles l'IHM peut s'appuyer \citep{ZhouDuhBillinghurst2008}. La voie de recherche de la RA tangible a été initiée par \citet{FeinerMacIntyreHauptEtAl1993} qui ont proposé un prototype accrochant des fenêtres virtuelles aux objets~; \citeauthor{FeinerMacIntyreHauptEtAl1993} parlaient alors, à juste titre, de \emph{design spatial}. Cependant, \citeauthor{ZhouDuhBillinghurst2008} soulignent que l'utilisation de telle IHM pose le défi de faire comprendre à l'utilisateur les commandes possibles avec les objets physiques et les conséquences de ces actions.


\subsection*{Le problème de recherche~: l'utilisation conjointe des visiocasques et des téléphones intelligents pour la conception d'une interface humain-machine pour une réalité augmentée mobile, portable et spatiale}
L'utilisation de téléphones intelligents pour la RA présente des inconvénients importants \footnote{Cela pourrait être un facteur expliquant, entre autres, la encore faible adoption de la RA par le grand public.} pour une bonne utilisabilité au quotidien. On peut noter que leurs écrans sont petits \citep{DeSaChurchill2013} et que le téléphone doit être tenu à bout de bras à la hauteur des yeux pour que la caméra puisse être alignée avec le regard de l'utilisateur, ce qui peut se révéler fatiguant pour l'utilisateur et donc limiter l'usage du système de RA \citep{Hincapie-RamosGuoMoghadasianEtAl2014}. Ce type de système n'est donc pas viable pour une utilisation quotidienne.

Une alternative pourrait se trouver dans l'utilisation de visiocasques pour réaliser une expérience de RA mobile, portable, légère et transparente pour l'utilisateur. \citet{KoelleKranzMoeller2015} rappellent que l'expérimentation de Google Glass a permis de montrer, malgré les problèmes de vie privée et d'acceptation sociale qu'elle a posée, qu'il était intéressant de combiner un visiocasque avec un téléphone intelligent~: le système proposait à l'utilisateur d'interagir avec son téléphone via le visiocasque par des interactions multimodales à la voix ou avec des gestes en l'air lus et décodés par la caméra du visiocasque. Ainsi, pour \citet{HuangHuiPeyloEtAl2013} l'avenir de la RA mobile se trouve dans l'utilisation de visiocasques de ce type. Ce point de vue est également défendu par \citet{SwanGabbard2005} pour qui l'information va se trouver révolutionnée dans l'utilisation d'ordinateurs mobiles, embarqués et portés par l'utilisateur, la RA étant une composante importante de ces nouveaux ordinateurs. De manière générale, \citet{SerranoEnsYangEtAl2015} soulignent que les visiocasques présentent les avantages, par rapport aux téléphones intelligents, de pouvoir laisser les mains libres et de pouvoir présenter en permanence de l'information aux yeux de l'utilisateur. Pour réaliser un tel visiocasque portable, les technologies des téléphones mobiles pourraient y être transférées et utilisées pour permettre à de tels visiocasques de créer une expérience de RA en autonomie.

S'ils sont techniquement réalisables, les possibilités des visiocasques ne sont pas pleinement exploitées. Une limite du Google Glass est que son IHM est affichée seulement sur un plan virtuel à une distance fixe des yeux. Ce n'est alors pas totalement de la RA au sens de la définition de \citet{AzumaBaillotBehringerEtAl2001}, car les éléments virtuels ne sont pas alignés avec les éléments réels. De plus, \citet{SerranoEnsYangEtAl2015} rappellent que ce plan peut faire occlusion avec l'environnement réel, et gêner la vue de l'utilisateur. En outre, les mains étant libres d'utiliser un autre système tel qu'un ordinateur de bureau ou téléphone intelligent, \citet{SerranoEnsYangEtAl2015b} proposent de faire travailler en synergie un système de RA d'un visiocasque avec les autres systèmes informatiques de l'utilisateur. Les téléphones intelligents étant actuellement très répandus, et les IHM pour la RA n'étant pas encore matures, la RA mobile ne va probablement pas remplacer les téléphones intelligents dans les prochaines années. Enfin, le téléphone étant tangible, il serait alors intéressant de mettre à profit un visiocasque pour augmenter l'écran du téléphone en RA avec du contenu virtuel et augmenter les interactions possibles avec le téléphone et le contenu virtuel de la RA. 

Certaines études \citep{EnsFinneganIrani2014} \citep{GrubertHeinischQuigleyEtAl2015} \citep{SerranoEnsYangEtAl2015} \citep{SerranoEnsYangEtAl2015b} ont proposé quelques solutions d'IHM pour une RA utilisant un téléphone intelligent, mais la première étude de cette liste n'a produit qu'une évaluation informelle tandis que les autres n'ont pas réalisé d'évaluation expérimentales. Nous souhaitons savoir quelle IHM serait la plus pertinente pour une telle RA. Pour cela nous souhaitons mener des évaluations pour comparer les différentes IHM possibles.
% TODO~: « We believe that novel devices will not replace mouse/keyboard and touchscreens in the following decade. » \cite{JankowskiHachet2013} donc de manière générale le mobile va pas être remplacé. Ceci dit est-ce qu'on peut infirmer cette affirmation pour un tel système ? cad existe-t-il des "nouvelles" interactions qui fonctionneraient mieux dans ce système que simplement le touch (souris inaplicable pour cellulaire) ?


\subsection*{Travaux reliés}
\subsubsection*{Interfaces humain-machine multi-affichages}
\paragraph*{\foreignlanguage{english}{The Personal Cockpit: A Spatial Interface for Effective Task Switching on Head-Worn Displays}}
\citet{EnsFinneganIrani2014} partent de ce même constat sur les IHM des visiocasques actuels~: un visiocasque peut afficher du contenu en 3D dans l'environnement, et pourrait permettre d'exploiter l'espace de la vision périphérique de l'utilisateur. Ainsi, plusieurs fenêtres pourraient être affichées en même temps à des endroits différents dans l'espace de la vision d'un utilisateur.\\
Pour explorer les capacités des visiocasques, \citeauthor{EnsFinneganIrani2014} réalisent un prototype de RA affichant de multiples fenêtres dans les airs \reffigureETS{EnsFinneganIrani2014-Figure8}. Un utilisateur peut alors interagir directement avec les fenêtres par le toucher (c'est donc une \emph{interaction directe}). Ils explorent alors plusieurs facteurs de conception du prototype, au travers de quatre expériences~: la taille d'affichage des fenêtres virtuelles, leur distance d'affichage, leur angle de placement par rapport à l'utilisateur, et enfin leur référentiel de placement des fenêtres virtuelle (fixées au corps ou fixées au monde). Les performances (temps et taux d'erreurs), la fatigue ainsi que les retours des utilisateurs étaient mesurés.\\ 
Leurs résultats ont montrés, entre autres, qu'un affichage courbe est important pour que toutes les fenêtres soient affichées à la même distance de l'utilisateur~; ce qui confirme les résultats de \citet{ShuppBallYostEtAl2006} pour les affichages virtuels. En outre, leur conception a montré qu'elle permettait un travail 40\% plus rapide qu'avec une fenêtre simple sur une tache multi-applications~: en effet, leur prototype permet d'afficher plusieurs fenêtres simultanément et ainsi réduit le changement de fenêtre, donc d'application pour du multi-tâches, à un simple mouvement de tête. Ce résultat montre également que l'interaction directe est compatible avec du contenu virtuel sous forme de fenêtres. Enfin, le référentiel sur le corps avait de plus grands taux d'erreurs que le référentiel sur le monde, car l'action de sélection entraînait des perturbations involontaires des fenêtres par rapport à l'utilisateur.\\ 
Ce travail présente cependant quelques limites. Tout d'abord, leur IHM requiert des interactions directes, ce qui est à l'origine d'erreurs de sélection et de fatigue du bras des utilisateurs~: il serait alors intéressant de savoir si un référentiel sur le corps permettrait d'être précis avec une interaction indirecte. En outre, le champ de vision était très limité~: 30° à l'horizontal et 40° à la verticale, ce qui biaise les mesures de performances Enfin, le prototype a été réalisé dans un CAVE, c'est-à-dire des projections de l'image sur des écrans entourant l'utilisateur. Ainsi, il faudrait reproduire les expérimentations avec un visiocasque et différentes techniques d'interactions. On peut également se demander si l'utilisation de fenêtres est une représentation adaptée pour la RA, aucune contrainte d'écrans physiques n'étant présente, ou s'il existe une meilleure représentation de l'information virtuelle dans un espace de RA.

\figureETS{figures/EnsFinneganIrani2014-Figure8.jpg}{Conception du \foreignlanguage{english}{Personal Cockpit}.\\ Tiré de \citet[p. 7]{EnsFinneganIrani2014}}{EnsFinneganIrani2014-Figure8}

\paragraph*{\foreignlanguage{english}{MultiFi: Multi-Fidelity Interaction with Displays On and Around the Body}}
Dans un article plus récent, \cite{GrubertKranzQuigley2015} constatent qu'il devient commun d'avoir plusieurs appareils mobiles sur soi, tels que les téléphones intelligents, les tablettes ou les montres connectées. Cependant, ces appareils sont conçus pour être utilisés seuls et pas pour qu'un utilisateur puisse interagir en même temps sur leurs multiples affichages.\\
\citeauthor{GrubertKranzQuigley2015} proposent alors d'utiliser les visiocasques pour joindre les affichages et les interactions entre ces différents appareils~: les entrées et les sorties de tous les appareils sont liées \reffigureETS{GrubertHeinischQuigleyEtAl2015}. Ainsi, ce travail prend la suite de celui de \citet{EnsFinneganIrani2014}, en situant les fenêtres virtuelles autour des affichages des appareils de l'utilisateur. L'objectif de leur système est de permettre des actions faciles et rapides dans les tâches qui impliquent de multiples appareils mobiles. Ils explorent alors dans cet article ce nouvel espace de conception créé et mènent des expérimentations auprès d'utilisateurs pour valider leurs propositions de conception par rapport aux appareils utilisés seuls.\\
Un résultat intéressant de leur exploration sont les degrés possibles de couplage des appareils. Dans le premier mode dit \emph{body-aligned}, le contenu virtuel a pour référence le corps de l'utilisateur, les appareils mobiles servant comme fenêtre haute résolution en pointant sur ce contenu~: la technique utilisée est \emph{overview+detail} (Voir \citep{BergeSerranoPerelmanEtAl2014}). Dans le second mode dit \emph{device-aligned}, le contenu a pour référence un appareil mobile, le visiocasque augmentant son écran avec un affichage virtuel~: le visiocasque étant de moins bonne résolution que l'appareil mobile, c'est une technique appelée \emph{focus+context} (Voir \cite{BaudischGoodStewart2001}). Enfin dans mode dit \emph{side-by-side}, les interactions entre les appareils se font sans lien spatial~: par exemple, l'utilisateur se sert du téléphone pour interagir indirectement avec des informations affichées par son visiocasque.\\
Leurs résultats expérimentaux montrent que l'augmentation des appareils en RA par un visiocasque peut permettre des temps plus rapides par rapport aux appareils seuls (visiocasque seul ou téléphone seul), dans les taches de navigation et de sélection, mais au détriment d'un plus grand effort perçu par les utilisateurs. Un second résultat expérimental important est que les préférences des utilisateurs sont variées entre utiliser les appareils seuls, coupler les entrées d'un appareil aux sorties de l'autre sans lien spatial, et coupler spatialement les appareils~: cela montre qu'il est important de proposer tout ce spectre pour que chaque utilisateur organise l'IHM selon ses préférences et selon le contexte.\\
Une limite importante de cet article sont de faibles résultats expérimentaux. En effet, le système testé était lourd, peu mobile, avait une grande latence (150 ms), un champ de vision limité~: ainsi, les résultats ont seulement permis de montrer que coupler les affichages des appareils \emph{pourrait} permettre de meilleures performances que les appareils utilisés seuls. En outre, le système n'a été pensé que pour certaines tâches précises, et non pour un couplage global et constant dans le temps. Il serait donc intéressant de généraliser le concept, et de le répliquer avec un visiocasque plus léger et mobile pour obtenir des résultats avec de meilleures validités internes (en évitant les problèmes techniques des expérimentations de l'article) et externes (plus de taches testés, conception pensée pour un couplage global et constant dans le temps).

\figureETS{figures/GrubertHeinischQuigleyEtAl2015.jpg}{Illustrations du fonctionnement de \foreignlanguage{english}{Multifi}.\\ Tiré de \citet{GrubertHeinischQuigleyEtAl2015}}{GrubertHeinischQuigleyEtAl2015}

\paragraph*{\foreignlanguage{english}{Gluey: Developing a Head-Worn Display Interface to Unify the Interaction Experience in Distributed Display Environments}}
Dans un article suivant, \cite{SerranoEnsYangEtAl2015} généralisent le travail de conception réalisé avec MultiFi \citep{GrubertHeinischQuigleyEtAl2015}. Ils proposent pour cela Gluey~: une IHM qui utilise le visiocasque comme affichage pour unifier les entrées et sorties de tous les appareils, qu'ils soient mobiles ou de bureau. \citeauthor{SerranoEnsYangEtAl2015} s'appuient pour cela sur les propriétés de l'affichage permanent aux yeux de l'utilisateur du visiocasque et de sa connaissance de sa position dans les environnements réels et virtuels. Ainsi, c'est un médium idéal de transmission de l'information et de redirection des entrées entre les appareils \reffigureETS{SerranoEnsYangEtAl2015a-Figure1}.
Un utilisateur peut donc interagir sur un appareil, et voir ses actions s'exécuter sur un autre appareil qu'il regarde. Il est intéressant que le système permette que n'importe quel appareil puisse être utilisé de manière transparente et flexible comme un dispositif d'entrée (souris, téléphone, tablette). Le système permet également de transmettre des données, par exemple pour copier des données ou les imprimer.\\
\citeauthor{SerranoEnsYangEtAl2015} présentent avec ce travail un ensemble de pistes de conception pour un tel système. Leur idée était de pouvoir créer des interactions invisibles entre les appareils, pour faciliter les taches demandant d'utiliser plusieurs appareils. Pour cela, l'IHM doit permettre de~: 
\begin{enumerate*}
	\item rediriger les entrées entre les appareils
	\item migrer du contenu entre les appareils
	\item tous les appareils doivent être compatibles
	\item d'enregistrer de nouveaux appareils
	\item de tenir un modèle spatial du système
	\item les retours du système doit toujours être visibles (ici par le visiocasque)
	\item le système doit être mobile
\end{enumerate*}. Ainsi, MultiFi \citep{GrubertHeinischQuigleyEtAl2015} ne satisfait qu'aux critères 1, 5, 6 et 7.\\
Une limite toutefois de l'article relève dans la faiblesse de son évaluation, informelle, qui a seulement pu montrer que le concept et la preuve de concept réalisée étaient enthousiasmantes et intéressantes aux yeux des participants. Une évaluation formelle devrait être reconduite avec un prototype léger et totalement mobile. Le visiocasque présentant en outre des limites de champs de vision et de résolution~: si ces caractéristiques vont s'améliorer dans le futur, nous pensons que leur impact sur la navigation et les performances des interactions des utilisateurs n'est pas encore bien connue.

\figureETS{figures/SerranoEnsYangEtAl2015a-Figure1.jpg}{Illustration du concept de \foreignlanguage{english}{Gluey}.\\ Tiré de \citet[p. 1]{SerranoEnsYangEtAl2015}}{SerranoEnsYangEtAl2015a-Figure1}

\paragraph*{\foreignlanguage{english}{Desktop-Gluey: Augmenting Desktop Environments with Wearable Devices}}
\citet{SerranoEnsYangEtAl2015b} ont par la suite complété leur travail, en proposant Desktop-Gluey~: ce concept étend les possibilités de Gluey en permettant à l'utilisateur d'étendre les écrans physiques de ses appareils par des fenêtres virtuelles. Les fenêtres peuvent être arrangés dans l'espace autour des écrans physique par l'utilisateur. Le système autorise donc le travail collaboratif en permettant de partager des fenêtres virtuelles entre plusieurs utilisateurs \reffigureETS{SerranoEnsYangEtAl2015-Figure2}. Enfin, les fenêtres peuvent suivre l'utilisateur dans ses déplacements et lui permettre d'interagir avec en utilisant son téléphone, une tablette ou des gestes de la main ou pour interagir, créant ainsi un concept de bureau mobile \reffigureETS{SerranoEnsYangEtAl2015-Figure4}. La métaphore du bureau sur l'ordinateur personnel est donc reprise et augmentée à "partout" et en "tout temps"~: tout dispositif d'entrée peut être utilisé et tout dispositif d'entrée peut être augmenté dans son affichage.\\
Le concept recoupe celui de MultiFi \citep{GrubertHeinischQuigleyEtAl2015}, et le généralise des appareils mobiles seuls à tous les appareils visibles par l'utilisateur. Une autre différence majeure est que MultiFi a été conçu pour faciliter les taches demandant d'utiliser plusieurs appareils, alors que Desktop-Gluey propose de travailler avec ces fenêtres virtuelles~: on peut dire que c'est une application du Personal Cockpit \citep{EnsFinneganIrani2014} dans une IHM tangible et située autour d'appareils mobiles (comme MultiFi).\\
\citeauthor{SerranoEnsYangEtAl2015b} ne présentent dans cet article que le concept mais n'en réalise aucun prototype, ni aucune évaluation. Nous pensons qu'il serait intéressant de montrer que ce concept fonctionne et d'implémenter ce système de bureau virtuel et mobile, afin d'explorer son espace de conception et d'en ajuster au mieux les paramètres.

\figureETS{figures/SerranoEnsYangEtAl2015-Figure2.jpg}{Illustration de l'utilisation de fenêtres virtuelles pour étendre les écrans physiques dans le concept de \foreignlanguage{english}{Desktop-Gluey}.\\ Tiré de \citet[p. 3]{SerranoEnsYangEtAl2015b}}{SerranoEnsYangEtAl2015-Figure2}

\figureETS{figures/SerranoEnsYangEtAl2015-Figure4.jpg}{Illustration du concept de \foreignlanguage{english}{Desktop-Gluey} en mode mobile.\\ Tiré de \citet[p. 3]{SerranoEnsYangEtAl2015b}}{SerranoEnsYangEtAl2015-Figure4}


\iffalse
\subsubsection*{IHM autres que du IHM multiaffichage}
\paragraph*{}
IHM hybride~: mobile pour entrée, et hmd pour sortie \cite{LeeBudhirajaBillinghurst2013}
\fi


\subsubsection*{Taille de l'affichage}
Une des principales problématiques des téléphones intelligent est leur petit écran. Cela peut grandement impacter les performances des utilisateurs quand il s'agit de naviguer dans de grands espaces de contenu, comme, par exemple, des données de navigation.

\paragraph*{}
Une approche est d'avoir recourt à des techniques de visualisation pour montrer à l'utilisateur des indications de la localisation d'objets hors-écran. Une de ces techniques est Halo, conçue par \citet{BaudischRosenholtz2003}, qui propose pour chaque objet hors-écran de tracer un cercle prenant l'objet comme centre et avec un rayon assez grand pour qu'une portion de l'arc soit visible sur l'écran. Ainsi l'utilisateur a des indices pour déduire la direction et la distance de l'objet. Leurs expérimentations ont montré que cette technique permettait des temps 16\% à 33\% plus rapides, et sans augmentation du taux d'erreur, par rapport à une technique plus classique (\emph{scaled arrows}) indiquant par des flèches sur l'écran la distance et la direction des objets hors-écrans. Cette technique a ensuite été perfectionnée par \citet{GustafsonBaudischGutwinEtAl2008} dans une seconde version nommée Wedge, cette seconde version permettant aux utilisateurs d'être significativement plus rapides qu'avec la première version. Enfin, \citet{BurigatChittaro2011} ont réalisé un comparatif de cette technique avec les techniques \foreignlanguage{english}{scaled arrows} et \emph{overview+detail} \reffigureETS{BurigatChittaro2011-Figure1}, cette dernière proposant une carte en miniature dans une vue sur un bord de l'écran montrant où regarde l'utilisateur sur cette carte. Les résultats de ce comparatif confirment que Wedge permet les temps les plus rapides quand les notions de distances sont importantes, mais indiquent que overview+detail est plus adapté quand les notions de structure de l'espace sont importantes, les auteurs concluant que toutes les techniques de visualisation ayant un impact positif sur les performances. Ainsi, il serait intéressant de savoir si un écran d'un appareil mobile augmenté de contenu virtuel permettrait de réaliser de meilleures performances par rapport à l'écran seul utilisé avec ces techniques.

\figureETS{figures/BurigatChittaro2011-Figure1.jpg}{Les trois techniques de visualisation pour les éléments hors écran~: (a) \foreignlanguage{english}{scaled arrows} (b) Wedge (c) overview+detail\\Tiré de \citet[p. 158]{BurigatChittaro2011}}{BurigatChittaro2011-Figure1}

\paragraph*{}
Cette problématique a également touché les ordinateurs personnels dans les années 2000 quand leurs affichages n'étaient pas très grands (les écrans 15 et 17 pouces étaient courants) ni de très grande résolution. \\
les problématiques du mobile actuellement~: petit écran face à grand contenu = incapacité à gérer de grandes infos \\
+ overview+detail \cite{BergeSerranoPerelmanEtAl2014} et \cite{RashidNacentaQuigley2012}\\
concevoir pour la périphérie (focus+context \cite{CockburnKarlsonBederson2009}

+ illumiroom \cite{JonesBenkoOfekEtAl2013}) \\
avec wedge/halo \cite{BaudischRosenholtz2003} \cite{GustafsonBaudischGutwinEtAl2008} \cite{BurigatChittaro2011} \\

\paragraph*{}
potentiel d'augmenter la taille l'affichage avec les travaux comparant le desktop aux murs \cite{LiuChapuisBeaudouin-LafonEtAl2014} \cite{ShuppBallYostEtAl2006} \cite{TanGergleScupelliEtAl2003}

\paragraph*{}
pouvoir naviguer mieux dans les larges «information spaces» fov comparés \cite{RaedleJetterMuellerEtAl2014} (ici le sweet spot va converger vers le 130\textdegree de wide display et le design pour la périphérie ?)

\paragraph*{}
explorer tout ce qui lié à \"SideSight: Multi-“touch” Interaction Around Small Devices \"~: interactions avec petits écrans mais sans feedback -> nous ajoutons à ces recherches le feedback qui a la possibilité d'être permanent avec un HMD


\subsubsection*{Multi-taches et changement de contexte}
concernant le multi-tache, c'est une problématique des systèmes RA (\cite{SchmalstiegFuhrmannHesinaEtAl2002} et background de \cite{EnsFinneganIrani2014})~: donc c'est naturel de lier le portable à la RA (TODO trouver un article le disant), surtout si on suit le \"information spaces\" de \cite{EnsHincapie-RamosIrani2014} \\
\cite{TanCzerwinski2003} \\
\cite{RashidNacentaQuigley2012a}


\subsubsection*{Interactions multimodales}
problématique du multimodal~: quelle interaction pour quelle tache ?

+ interactions directes (main)

+ interactions indirectes avec le regard

+ apprentissages interactions touch avec un smartphone


\subsubsection*{Synchronisation des environnements réels et virtuels}
problématique de désynchronisation réel/virtuel peut être comblé avec cette RA mobile~: \cite{Chalon2004} et Gluey qui fait des photos du réels pour les coller sur l'écran


\subsection*{Questions de recherche}
Dès lors, à la lecture de la littérature, on peut poser un certains nombre de questions de recherche pour concevoir un tel système de RA combinant un visiocasque avec un téléphone intelligent dans le but augmenter l'écran physique du téléphone et chercher l'IHM la plus pertinente pour un tel système~:
\begin{enumerate}
	\item Quelles IHM sont les plus intéressantes pour quelles tâches ?
	\item Pour quelles taches un utilisateur profiterait-il d'un écran augmenté ? Pour quelles taches un utilisateur profiterait-il de multiples écran organisables dans l'espace du téléphone ?
	\item Quels sont les paramètres de conception d'un tel système et pour quelles valeurs permettent-ils de le rendre le plus utilisable et le plus intéressant ? Est-ce qu'un tel système serait plus performant qu'un écran seul ?
	\item Le téléphone intelligent devrait-il servir comme une fenêtre haute-résolution sur le contenu virtuel (peephole ou focus+context), ou serait-il mieux de concevoir l'environnement virtuel comme une extension de l'écran du téléphone. Dans chacun des deux modes, quelles taches et quelles interactions sont les plus intéressantes et les plus performantes ? Dans le second cas, est-ce que les objets virtuels doivent être conçus seulement pour la périphérie du regard ou pourraient-ils être des espaces de travail pour l'utilisateur (zones de focus potentiel de l'utilisateur) ?
	\item Quels sont les impacts de la taille des champs de vision (en anglais~: FoV) et de la résolution d'affichage du visiocasque sur la navigation et les interactions de l'utilisateur du système ? Peuvent-ils être négligés avec le matériel présent aujourd'hui, et qui s'améliorera dans le futur ? Il y a-t-il des valeurs minimum à respecter pour obtenir des résultats valides ? À mesure que le matériel va s'améliorer, est-il qu'un impact négatif existe passé un trop large champs de vision ou une trop haute résolution ?
	\item Les objets virtuels devraient-ils être simplement des fenêtres 2D dans l'espace, ou peut-on leur donner une profondeur (3D) tout en gardant de bonnes performances d'utilisation ? De manière plus générale, quelle est la meilleur ergonomie d'affichage et d'utilisation d'informations virtuelles dans un tel système RA ?
\end{enumerate}

Nous pensons concevoir et réaliser un prototype comme solution pour explorer ces questions et ces paramètres de conception, et par une ou plusieurs études expérimentale évaluer auprès d'utilisateurs différentes IHM et différents paramètres de conception pour pouvoir réaliser un ensemble de recommandations pour de futurs travaux pour un tel système de RA.

\iffalse
TODO Maîtrise~:
1. Lire et cerner 
   [a] la problématique -> DONE
   [b] les sous-problèmes + objectifs
2. Lister et classer les facteurs de design possibles -> DONE
3. Définir les paramètres (design factors) d'interfaces et d'interactions -> DONE
4. Lister les tâches possibles de 
   [a] test 
   et [b] d'application 
   + [c] schémas de résumé
5. Concevoir les interfaces et les interactions pour chaque tâche~:
   [a] navigation, 
   [b] sélection et manipulation
6. Concevoir les expérimentations 
   + Déterminer quelles mesures possibles pour chaque interface x interaction
7. Préparer les expérimentations 
   + Réaliser le prototype pour répondre à(aux) expérimentation(s)
8. Réaliser les expérimentations
9. Apprendre à analyser les données d'expérimentations
   + Analyser les données des expérimentations
10. Écrire l'article et l'envoyer
11. Déterminer ce qui est nécessaire pour terminer le mémoire
12. Écrire le mémoire et le faire valider
13. Passer la soutenance
\fi



\section*{Facteurs de conception}
« However, to date, what is not well understood is which factors inhibit or support the interaction across multiple displays on and around the body i.e. “body proximate” displays. Within this paper we review four key design and technological challenges inherent in body proximate displayecosystems, i.e. combinations of wearable displays (e.g.,smartwatches and smartglasses) and handheld devices(e.g., tablets and smartphones). » \cite{GrubertKranzQuigley2015} \\
TODO~: réviser l'article comme point de départ de cette section + les design factors de Personal Cockpit \\

Une solution pour un tel système de RA demande au préalable une connaissance des facteurs de conceptions
Conception (interfaces, interactions) importants et surtout les non-explorés encore = les sous-problèmes


\subsection*{Matériel}
        FoV (Czerwinski, 2002) (Patterson, 2006) \cite{KishishitaKiyokawaOrloskyEtAl2014} \\

        Resolution \\


\subsection*{Visualisation, interface design}
        Reference frame for virtual content \\
            World-fixed \cite{EnsFinneganIrani2014} \\
            Body-fixed \cite{EnsFinneganIrani2014} \\
                + Head centered vs dominant hand centered \\
            Head-fixed \cite{EnsFinneganIrani2014} \\
            Phone-fixed \\
        	Movability \cite{EnsHincapie-RamosIrani2014} \\
            Spatial consistent interface \cite{LiDearmanTruong2009} \\

        Context switching \\
            Number of displays \cite{RashidNacentaQuigley2012} \cite{CauchardLoechtefeldFraserEtAl2012}
            Design of context vs design with large one app display \cite{BallNorth2008}

        Content display \\
            Size of virtual elements = angular width \cite{ShuppBallYostEtAl2006} \cite{BallNorth2008} \\
            Distance of virtual content (Hezel, 1994) (Ankrum, 1999) (Tan, 2003) \cite{ChanKaoChenEtAl2010} \cite{EnsFinneganIrani2014} 
            Angular separation (Mayer, 1993) \cite{EnsFinneganIrani2014} \cite{KishishitaKiyokawaOrloskyEtAl2014} (Alger, 2015) \\ 
            Curved layout vs flat layout \cite{ShuppBallYostEtAl2006} 
            Direction of content (top, bottom, left, right) \cite{EnsFinneganIrani2014} \\
            Display continuity \cite{TanCzerwinski2003} \cite{RashidNacentaQuigley2012} \\
            Allocating space for new elements \cite{BellFeiner2000} \\

            2D vs 3D virtual content \cite{JansenDragicevicFekete2013} \cite{SerranoHildebrandtSubramanianEtAl2014} \\
            Same appareance for a same content accross outputs vs different appareance according to the output \cite{GrubertHeinischQuigleyEtAl2015} \\


\subsection*{Interaction design}
    	« tasks that occur in 3D applications, which are independent of the input device » \cite{JankowskiHachet2013} \\
    	Reprendre \cite{Bernatchez2008} et \cite{JankowskiHachet2013}
    	Technique (interactions spatiales) \\
            Mid-hair hand \cite{EnsFinneganIrani2014} \cite{ChanKaoChenEtAl2010} \cite{JonesSodhiForsythEtAl2012} + Blog de Leap Motion
            Gaze + taffi (HoloLens) \\
            Just touch on phone \\
            Gaze + touch on phone \\
            Baselines
            	Phone without AR
            	Phone without AR and without the HMD, but with the HMD-latency
            	Phone without AR and without the HMD nor the HMD-latency

        Indirect (\cite{TeatherStuerzlinger2011}) vs direct (revoir ethereal planes) \\
        Tangibilité vs intangible, dans les techniques \\



\section*{Évaluation d'une solution au problème de recherche}
\subsection*{Évaluations des systèmes de Réalité Augmentée}
La conception de solution aux problèmes d'IHM pour la RA demande d'évaluer, formellement ou non, ces solutions. Pour cela, les méthodes d'évaluation des IHM traditionnelles peuvent être utilisées, en particulier des expérimentations utilisateurs (en anglais~: \foreignlanguage{english}{user studies} ou \foreignlanguage{english}{user-based experimentations}). \citep{SwanGabbard2005}
Comment évaluer ? Taches de tests, et taches plus écologiques (proches des usages réels du quotidien) \cite{DeSaChurchill2013}
\cite{SwanGabbard2005} \cite{DuenserGrassetBillinghurst2008}

\subsubsection*{Types d'évaluations}
Perception~: taches de bas-niveau pour comprendre comment la perception et la cognition humaine fonctionne dans les contextes de RA

Performance utilisateur~: examine les performances dans les taches utilisateurs en RA, dans des applications spécifiques, pour déterminer comment la technologie peut impacter ces taches (\textbf{limite} de notre étude ici~: on ne fait que ça dans nos taches d'évaluation

Collaboration~: examine des interactions et communications utilisateurs entre plusieurs personnes

Utilisabilité~: idem au type `Performance` mais sans mesure, plutôt identifier les problèmes avec l'utilisabilité du système

\subsubsection*{Méthodes d'évaluations}
Mesures objectives \\
	Surtout temps de complétion et taux d'erreur, ou encore score, position, nombre d'actions, mouvements \cite{DuenserGrassetBillinghurst2008}

Mesures subjectives \\
	Questionnaires, notes utilisateurs, retours utilisateurs \cite{DuenserGrassetBillinghurst2008}

Analyses qualitatives \\
	Observations, interviews formelles, classification des comportements utilisateurs \cite{DuenserGrassetBillinghurst2008}

Techniques d'évaluation d'utilisabilité \\
	Évaluations experts, évaluations heuristiques, analyse de tache, description à haute voix, méthode magicien d'Oz \cite{DuenserGrassetBillinghurst2008}

Évaluations informelles \\
	Observations utilisateurs, retours utilisateurs \cite{DuenserGrassetBillinghurst2008}


\subsection*{Propositions d'expérimentations utilisateurs}
\subsubsection*{Tâche de navigation}
Conjunction Search~: l'espace est partagé en deux, avec un objet cible à gauche et une grille d'objets à droite. Le participant doit compter dans la grille le nombre d'objets similaire à la cible. Les participants doivent être le plus rapide et le plus précis possible. Cela a permis de déterminer la meilleur distance et la meilleure taille pour le contenu virtuel dans l'espace. L'effort perçu (7 points) et le temps d'essais ont été pris en mesure. Il y a eu 10 essais pour chaque condition et 10 participants. \cite{EnsFinneganIrani2014} \\
\cite{RashidNacentaQuigley2012} \\
Recherche d'un objet avec certaines propriétés. Ici, les participants devaient déterminer l'item avec le plus bas prix, parmi cinq items. 10 essais par 5 interaction possible (Handled: écran mobile seul ; Smarwatch: écran smartwatch seul ; HMD: HMD seul + entrée indirecte sur la SW ; BodyRef: contenu body-ref + entrée sur l'écran SW ; SWRef: contenu SW-ref + entrée sur l'écran SW). 23 participants. Mesure du temps de complétion de la tâche (TCT), du taux d'erreurs, charge mentale (subjectif). Handled et BodyRef étaient les plus rapides, pas de différence dans les erreurs. Handled demandait moins de charge. \cite{GrubertHeinischQuigleyEtAl2015}

\subsubsection*{Tâche de sélection}
Les participants doivent toucher une cible (ici avec leur doigt). La cible peut se trouver dans cinq emplacements~: haut, bas, gauche, droite ou centre. Cela a permis de tester la distance du contenu, et le reference frame. Il y a eu 5 essais pour chaque condition et 12 participants. Ont été mesurés le temps de complétion, les erreurs de pointage, et la fatigue perçue (échelle de Borg à 12 points). \cite{EnsFinneganIrani2014} \\
Deux fenêtres sont affichées, de direction (haut, bas, gauche, droite) et d'angle (le layout est courbe~: 15\textdegree, 25\textdegree, 35\textdegree, 45\textdegree, 55\textdegree) variables. La première fenêtre contient un bouton de démarrage (placée à hauteur d'yeux du participant) et la deuxième une cible à déclencher après le démarrage. Chaque condition est répétée 10 fois, et il y a eu 8 participants. Ont été mesurés le temps de complétion, les erreurs de pointage, et la fatigue perçue (échelle de Borg à 12 points) pour le bras et pour la tête. \cite{EnsFinneganIrani2014} \\
Le long d'une bande à faire scroller, les participants doivent sélectionner une cible. 10 essais pour chacune des 5 interactions (Handled, Smartwatch, HMD, BodyRef, SWRef). BodyRef demandait à déplacer la sw vers la cible, pas scroller. Un bouton start était à toucher, puis la cible était à atteindre. 2 distances ont été testées (15 cm et 30 cm). 2 directions à tester. 23 participants. Mesure TCT, erreur, charge mentale et préférence utilisateur. BodyRef a été le plus rapide, mais génère beaucoup d'erreurs. SWRef génère peu d'erreurs. Handled le moins de charge. Frustration pour SW et SWRef. \cite{}

\subsubsection*{Tâche de classification}
Tri \cite{RobertsonCzerwinskiLarsonEtAl1998}, ou classification \cite{LiuChapuisBeaudouin-LafonEtAl2014} \\

\subsubsection*{Tâche spatiale}
\cite{BurigatChittaro2011}
\cite{BergeSerranoPerelmanEtAl2014}

\subsubsection*{Tâche de commutation d'affichages}
4 applications sur mobile~: Question, My contacts, Calendar, Map. Étudie différentes façons de switcher entre des application. Pris des applications connues et habituelles. Il n'y a besoin d'aucune interaction dans les taches, mais simplement de switcher entre elles et de lire les indices qu'elles contiennent. Tache faite non pas en mouvement, mais faite quand utilisateur s'arrête pour chercher infos. Le but est que les utilisateurs répondent à la question posée. Designs factors~: 6 questions et 4 types (=24 questions), et 3 conditions (ici 3 façons de switcher). Les mesures prisent ont été le temps de complétion (MT) et le taux d'erreurs (ER) + un questionnaire NASA TLX. 12 participants, qui ont pu essayer les tâches jusqu'à ce qu'ils se sentent prêts. \cite{CauchardLoechtefeldFraserEtAl2012} \\
La même tache que Cauchard (2012) a été reprise. Les fenêtres sont à 50 cm de l'utilisateur, de taille 22 cm, sur un layout courbe, séparée de 27,5\textdegree, toujours orientée vers l'utilisateur et fixées au monde (pas à l'utilisateur). Les fenêtres des applications à utiliser ont été placées aléatoirement dans une grille de 9 ou 16 emplacements. Pour ajuster la difficulté il y a avait 4 ou 5 applications. Enfin, deux techniques étaient présente, une directe (avec une assistance visuelle de la distance du doigt à la fenêtre) et une indirecte sur une tablette permettant de switcher entre les applications (toujours affichées sur le HMD). \cite{EnsFinneganIrani2014} \\
Les deux sont des tâches ecologiquement plus valides, car utilisant des applications familières et quotidiennes pour les utilisateurs. + discuter  des taches écologiques en réel avec toutes les problématiques que ça ouvre \cite{KoelleKranzMoeller2015} \cite{DenningDehlawiKohno2014}



\section*{Synthèse}
