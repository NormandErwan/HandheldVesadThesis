% Encoding: UTF-8

@InProceedings{Wobbrock2009,
  author    = {Jacob O. Wobbrock and Meredith Ringel Morris and Andrew D. Wilson},
  title     = {User-defined gestures for surface computing},
  booktitle = {Proceedings of the 27th international conference on Human factors in computing systems - {CHI} 09},
  year      = {2009},
  publisher = {{ACM} Press},
  doi       = {10.1145/1518701.1518866},
}

@InProceedings{Markussen2014,
  author    = {Anders Markussen and Mikkel R{\o}nne Jakobsen and Kasper Hornb{\ae}k},
  title     = {Vulture},
  booktitle = {Proceedings of the 32nd annual {ACM} conference on Human factors in computing systems - {CHI} {\textquotesingle}14},
  year      = {2014},
  publisher = {{ACM} Press},
  doi       = {10.1145/2556288.2556964},
}

@InProceedings{Piumsomboon2013,
  author    = {Thammathip Piumsomboon and Adrian Clark and Mark Billinghurst and Andy Cockburn},
  title     = {User-defined gestures for augmented reality},
  booktitle = {{CHI} {\textquotesingle}13 Extended Abstracts on Human Factors in Computing Systems on - {CHI} {EA} {\textquotesingle}13},
  year      = {2013},
  publisher = {{ACM} Press},
  doi       = {10.1145/2468356.2468527},
}

@InProceedings{Mei2007,
  author    = {Christopher Mei and Patrick Rives},
  title     = {Single View Point Omnidirectional Camera Calibration from Planar Grids},
  booktitle = {Proceedings 2007 {IEEE} International Conference on Robotics and Automation},
  year      = {2007},
  month     = {apr},
  publisher = {{IEEE}},
  doi       = {10.1109/robot.2007.364084},
}

@InProceedings{Piumsomboon2014,
  author    = {Thammathip Piumsomboon and David Altimira and Hyungon Kim and Adrian Clark and Gun Lee and Mark Billinghurst},
  title     = {Grasp-Shell vs gesture-speech: A comparison of direct and indirect natural interaction techniques in augmented reality},
  booktitle = {2014 {IEEE} International Symposium on Mixed and Augmented Reality ({ISMAR})},
  year      = {2014},
  month     = {sep},
  publisher = {{IEEE}},
  doi       = {10.1109/ismar.2014.6948411},
}

@Misc{OpenCV3.3.0-CcalibModule,
  author = {OpenCV},
  title  = {Custom Calibration Pattern for 3D reconstruction},
  month  = jul,
  year   = {2017},
  url    = {https://docs.opencv.org/3.3.1/d3/ddc/group__ccalib.html},
}

@InProceedings{LiuChapuisBeaudouin-LafonEtAl2014,
  author       = {Liu, Can and Chapuis, Olivier and Beaudouin-Lafon, Michel and Lecolinet, Eric and Mackay, Wendy E},
  title        = {Effects of display size and navigation type on a classification task},
  booktitle    = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year         = {2014},
  pages        = {4147--4156},
  organization = {ACM},
  doi          = {10.1145/2556288.2557020},
  keywords     = {relevant},
  review       = {[Problème de recherche] 
Les affichages d'écran de la taile d'un mur se font de plus en plus présent. Une question générale existe alors : est-ce que les connaissances sur les écrans de taille d'un ordinateur s'appliquent à ces nouveaux écrans ? Ces nouveaux écrans ont la même haute densité que les écrans de bureau, mais leur résolution est généralement 10 fois élevée en nombre de pixels : un utilisateur doit donc s'approcher physiquement pour pouvoir voir le détail et reculer pour avoir une vue d'ensemble.

[Solution] 

[Méthodologie] 

[Résultats] 

[Limites] 

[Concepts-clés] 

[Futurs travaux] 

[Références centrales]},
  timestamp    = {2016-03-15 21:40},
}

@InProceedings{EnsFinneganIrani2014,
  author       = {Ens, Barrett M and Finnegan, Rory and Irani, Pourang P},
  title        = {The personal cockpit: a spatial interface for effective task switching on head-worn displays},
  booktitle    = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year         = {2014},
  pages        = {3171--3180},
  organization = {ACM},
  doi          = {10.1145/2556288.2557058},
  keywords     = {relevant, rank4},
  review       = {[Problème de recherche] 
Il y a une prolifération de HMD peu cher, qui permettent d'interagir avec du contenu en permanence, mais qui m'affiche que des interface en 2D à distance fixe de l'utilisateur. Il n'y a pas d'exploitation de la périphérie de l'utilisateur et peut créer des problèmes d'occlusion avec le monde réel. De plus, on retrouve le même problème que les smartphone où le multitache demande de switcher entre des applications, ce qui coûte cher. Pourtant un HMD n'a pas de limites physiques et peut créer des IHM dans l'espace (en 3D et non plus sur un écran 2D), et composées de plusieurs fenêtres.

[Solution] 
Explorer la conception d'interfaces spatiale mobiles, avec de multiples affichages flottants dans les airs à l'aide un prototype. Pour cela, déterminer quels sont les meilleurs facteurs de design pour concevoir un tel prototype, et les valider avec expérimentations empiriques. Enfin, faire des recommendations pour al conception d'IHM dans l'espace.
Les facteurs explorés sont : 
- le FOV : un humain a 200° en horizontal, 130° en vertical, fovea est 3°h8°v, un fov mini pour un hmd est 40°h (si pour fovea) ou 60°h (pour immersion) 
- le changement de contexte : nombre d'écran et multitache, les mvt de têtes doivent être minisé pour pas impacter perfs, et certaines taches valent le coup d'un écran étendu, consitance spatiale est bonne pour les perfs
- la séparation angulaire (angle de placement du contenu dans l'espace) : meilleur perfs si petits angles, jusqu'à 85° de rot h et 50° rot haut et 60-70° rot bas
- la taille d'affichage (ou résoluton) : plus haute meilleur pour navigation, certaines taches (par ex: recherche mais pas tracé de route) profitent d'un plus grand affichage, mais souvent le fait de pouvoir se déplacer dans l'espace est plus important que d'avoir un grand affichage
- la distance d'affichage des fenêtres : 0.25m minimum mais 1m recommandé pour écrans physiques, impacts sur perfs si affichages à distances différentes, en VR la prof est mal estimée
- méthode d'entrée : directe est plus naturelle mais pose des problémes car vr intangible et problèmes d'estimation de distances
- placement des affichages : sur le monde ou les objets, sur la tête, sur le corps, sur les mains

[Méthodologie] 
Réaliser quatre expérimentation pour déterminer et valider ces paramètres : 
1 Tache de recherche visuelle d'objet
VI : angle de placement (50,75,100,125,150% du FoV) et distance placement (40,60,80,100 cm)
VC : FoV (40°x30°)
VD : temps d'essai, effort perçu

2 Tache de sélection d'une cible
VI : placement (world-, body-, view-fixed), distance placement (40, 50, 60 cm), location cible (centre, haut, bas, gauche, droite)
VC : FoV (40°x30°), 70% du FoV, input direct
VD : temps d'essai, erreurs sélection, effort perçu

3 Tache de recherche visuelle d'objet
VI : angle de placement (50,75,100,125,150% du FoV), distance placement (40,60,80,100 cm)
VC : FoV (40°x30°), 70% du FoV, input direct, world-fixed, 50 cm, curved windows
VD : temps d'essai, erreurs sélection, effort perçu

4 

[Résultats] 
1 75% pour temps, et inconfort à 40 cm malgré pas de diff donc 60 cm min
2 world-fixed le plus précis (pour les autres le manque de précision de l'outil de sélection contrebalançait la proprioception), mais pas de diff de temps + précision meilleure quand distance proche = plus le bras s'allonge, moins c'est précis
3
4 

Autres : Les fenêtres VR sont compatibles avec input direct même si FoV limité. Un layout courbe fonctionne bien et limite les erreurs. 

[Limites] 
Simplement testé l'input direct. Que de l'intangible. FoV très limité et fixe. Il faudrait tester sur plus de taches pour voir si les résultats sont généralisables.

[Concepts-clés] 
Head-worn display; head-mounted display; task switching; spatial input; spatial user interface; virtual window management; multi-display environment

[Futurs travaux] 
Répliquer sur un vrai HMD, pas un CAVE comme dans les expériences. Mieux supporter l'input direct et tester d'autres techniques d'input. Mieux comprendre les limitations de la proprioception et de la fatigue utilisateur, donc permettre une pus grand stabilisation quand en mode body-fixed ou changer de mode en fonction du contexte.

[Références centrales] 
[12] Steven Feiner , Blair MacIntyre , Marcus Haupt , Eliot Solomon, Windows on the world: 2D windows for 3D augmented reality, Proceedings of the 6th annual ACM symposium on User interface software and technology, p.145-155, December 1993, Atlanta, Georgia, USA
[13] George W. Fitzmaurice, Situated information spaces and spatially aware palmtop computers, Communications of the ACM, v.36 n.7, p.39-49, July 1993
[22] Frank Chun Yat Li , David Dearman , Khai N. Truong, Virtual shelves: interactions with orientation aware devices, Proceedings of the 22nd annual ACM symposium on User interface software and technology, October 04-07, 2009, Victoria, BC, Canada
[34] Lauren Shupp , Robert Ball , Beth Yost , John Booker , Chris North, Evaluation of viewport size and curvature of large, high-resolution displays, Proceedings of Graphics Interface 2006, June 07-09, 2006, Quebec, Canada},
}

@InProceedings{GrubertHeinischQuigleyEtAl2015,
  author       = {Grubert, Jens and Heinisch, Matthias and Quigley, Aaron and Schmalstieg, Dieter},
  title        = {Multifi: Multi fidelity interaction with displays on and around the body},
  booktitle    = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
  year         = {2015},
  pages        = {3933--3942},
  organization = {ACM},
  doi          = {10.1145/2702123.2702331},
  keywords     = {relevant, rank3},
  review       = {[Problème de recherche] 
Les écrans se multiplient dans notre espace, qu'ils soient publics ou personnels ; une personne va même souvent transporter plusieurs appareils sur soi. Mais ces appareils ne prennent pas en compte la présence les uns des autres. Pourtant, le travail sur ordinateur avec plusieurs écrans, l'accès à distance d'un ordinateur, ou le screen mirroring montrent que la coordination d'appareil est intéressante.

[Solution] 
Créer une plateforme pour implémenter une IHM entre différents écrans d'affichage : et ainsi permettre d'utiliser de manière fluide différents appareils conjointement. Il faut pour cela s'accomoder de résolution et de FoV différents pour les écrans de chaque appareil, et de variations de méthodes d'entrées de chaque appareil.

[Méthodologie] 

[Résultats] 

[Limites] 

[Concepts-clés] 

[Futurs travaux] 

[Références centrales]},
  timestamp    = {2016-03-22 20:18},
}

@Misc{LeapMotionAlignmentCameraAR2015,
  author = {Alex Colgan},
  title  = {The Alignment Problem: How to Position Cameras for Augmented Reality},
  month  = jun,
  year   = {2015},
  url    = {http://blog.leapmotion.com/alignment-problem-position-cameras-augmented-reality/},
}

@Misc{SteptoeAR-Rift2014,
  author = {William Steptoe},
  title  = {AR-Rift},
  year   = {2014},
  url    = {http://willsteptoe.com/post/66968953089/ar-rift-part-1},
}

@Misc{UnityFutureMRPartII2017,
  author    = {Dioselin Gonzalez and Colin Alleyne and and Sylvio Drouin},
  title     = {Looking to the future of mixed reality (Part II)},
  month     = sep,
  year      = {2017},
  timestamp = {2017-11-01},
  url       = {https://blogs.unity3d.com/2017/09/21/looking-to-the-future-of-mixed-reality-part-ii/},
}

@Misc{LeapMotionARWorkspace2015,
  author = {Raffi Bedikian},
  title  = {Under the Hood: The Leap Motion Hackathon’s Augmented Reality Workspace},
  month  = jul,
  year   = {2015},
  url    = {http://blog.leapmotion.com/hood-leap-motion-hackathons-augmented-reality-workspace/},
}

@InProceedings{Berge2014,
  author    = {Louis-Pierre Berg{\'{e}} and Marcos Serrano and Gary Perelman and Emmanuel Dubois},
  title     = {Exploring smartphone-based interaction with overview$\mathplus$detail interfaces on 3D public displays},
  booktitle = {Proceedings of the 16th international conference on Human-computer interaction with mobile devices {\&} services - {MobileHCI} {\textquotesingle}14},
  year      = {2014},
  publisher = {{ACM} Press},
  doi       = {10.1145/2628363.2628374},
}

@InCollection{Berard2009,
  author    = {Fran{\c{c}}ois B{\'{e}}rard and Jessica Ip and Mitchel Benovoy and Dalia El-Shimy and Jeffrey R. Blum and Jeremy R. Cooperstock},
  title     = {Did {\textquotedblleft}Minority Report{\textquotedblright} Get It Wrong? Superiority of the Mouse over 3D Input Devices in a 3D Placement Task},
  booktitle = {Human-Computer Interaction {\textendash} {INTERACT} 2009},
  publisher = {Springer Berlin Heidelberg},
  year      = {2009},
  pages     = {400--414},
  doi       = {10.1007/978-3-642-03658-3_45},
}

@InProceedings{Robertson1998,
  author    = {George Robertson and Mary Czerwinski and Kevin Larson and Daniel C. Robbins and David Thiel and Maarten van Dantzich},
  title     = {Data mountain},
  booktitle = {Proceedings of the 11th annual {ACM} symposium on User interface software and technology - {UIST} {\textquotesingle}98},
  year      = {1998},
  publisher = {{ACM} Press},
  doi       = {10.1145/288392.288596},
}

@InProceedings{Esteves2017,
  author    = {Augusto Esteves and David Verweij and Liza Suraiya and Rasel Islam and Youryang Lee and Ian Oakley},
  title     = {{SmoothMoves}},
  booktitle = {Proceedings of the 30th Annual {ACM} Symposium on User Interface Software and Technology - {UIST} {\textquotesingle}17},
  year      = {2017},
  publisher = {{ACM} Press},
  doi       = {10.1145/3126594.3126616},
}

@Article{Burigat2011,
  author    = {Stefano Burigat and Luca Chittaro},
  title     = {On the effectiveness of Overview$\mathplus$Detail visualization on mobile devices},
  journal   = {Personal and Ubiquitous Computing},
  year      = {2011},
  volume    = {17},
  number    = {2},
  pages     = {371--385},
  month     = {dec},
  doi       = {10.1007/s00779-011-0500-3},
  publisher = {Springer Nature},
}

@InProceedings{Huerst2010,
  author    = {Wolfgang Hürst and Tair Bilyalov},
  title     = {Dynamic versus static peephole navigation of {VR} panoramas on handheld devices},
  booktitle = {Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia - {MUM} {\textquotesingle}10},
  year      = {2010},
  publisher = {{ACM} Press},
  doi       = {10.1145/1899475.1899500},
}

@Article{Mehra2006,
  author    = {Sumit Mehra and Peter Werkhoven and Marcel Worring},
  title     = {Navigating on handheld displays},
  journal   = {{ACM} Transactions on Computer-Human Interaction},
  year      = {2006},
  volume    = {13},
  number    = {4},
  pages     = {448--457},
  month     = {dec},
  doi       = {10.1145/1188816.1188818},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Book{AdrianKaehler2017,
  title     = {Learning OpenCV 3},
  publisher = {O'Reilly UK Ltd.},
  year      = {2017},
  author    = {Adrian Kaehler, Gary Bradski},
  isbn      = {1491937998},
  date      = {2017-02-11},
  ean       = {9781491937990},
  url       = {http://www.ebook.de/de/product/24777502/adrian_kaehler_gary_bradski_learning_opencv_3.html},
}

@Misc{OpenCV3.3.0-Calib3dModule,
  author = {OpenCV},
  title  = {Camera Calibration and 3D Reconstruction},
  month  = jul,
  year   = {2017},
  url    = {https://docs.opencv.org/3.3.0/d9/d0c/group__calib3d.html},
}

@Misc{OpenCV3.3.0-ArUcoModule,
  author = {OpenCV},
  title  = {ArUco Marker Detection},
  month  = jul,
  year   = {2017},
  url    = {https://docs.opencv.org/3.3.0/d9/d6a/group__aruco.html},
}

@Comment{jabref-meta: databaseType:bibtex;}
